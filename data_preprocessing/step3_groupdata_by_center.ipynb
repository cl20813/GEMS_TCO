{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# work environment: jl2815\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import sys\n",
    "import os\n",
    "gems_tco_path = \"/Users/joonwonlee/Documents/GEMS_TCO-1/src\"\n",
    "sys.path.append(gems_tco_path)\n",
    "#  sys.path\n",
    "# !pip install numpy==2.0\n",
    "\n",
    "from GEMS_TCO import data_map_by_hour\n",
    "\n",
    "\n",
    "# work with jl2815 environment\n",
    "import xarray as xr # for netCDF4 \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from netCDF4 import Dataset\n",
    "\n",
    "# Ignore warnings due to duplicated dimension names\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"xarray\")\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "from GEMS_TCO import configuration as config\n",
    "from GEMS_TCO import data_map_by_hour\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make orbit maps:\n",
    "\n",
    "year =2024 or 2023   \n",
    "for month in range(start,end+1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file: /Users/joonwonlee/Documents/GEMS_DATA/data_2024/data_24_07_0131_N4.9910.01_E113.49123.01.csv\n",
      "Successfully processed and saved data for year 24 month 07.\n"
     ]
    }
   ],
   "source": [
    "# Base file path and settings\n",
    "# input_base = \"/Volumes/Backup Plus/Extracted_data/\"       MAC: working from portable disk requires permission, figure out later\n",
    "# base_path = \"C:\\\\Users\\\\joonw\\\\TCO\\\\GEMS_data\"    MSI notebook\n",
    "base_path = config.mac_data_load_path   \n",
    "output_path = base_path\n",
    "#lat_start, lat_end, lon_start, lon_end = 5, 10, 110, 120\n",
    "\n",
    "lat_start, lat_end, lon_start, lon_end = 4.99, 10.01, 113.49, 123.01\n",
    "lat_start, lat_end, lon_start, lon_end = 0, 5, 123, 133\n",
    "\n",
    "\n",
    "# years = [2023,2024]\n",
    "years = [2024] \n",
    "months = list( range(7,8))\n",
    "# Loop through months\n",
    "for year in years:\n",
    "    for month in months:  \n",
    "        try:\n",
    "            # Construct filenames dynamically\n",
    "            month_str = f\"{month:02d}\"  # Ensure month is zero-padded\n",
    "            if month == 2 and year==2023:\n",
    "                day_str = \"0128\"  # Handle February specifically\n",
    "            elif month ==2 and year==2024:\n",
    "                day_str = \"0129\"\n",
    "            else:\n",
    "                day_str = \"0131\" if (month in [1, 3, 5, 7, 8, 10, 12]) else \"0130\"\n",
    "    \n",
    "            input_filename = f\"data_{year}/data_{str(year)[2:]}_{month_str}_{day_str}_N{lat_start}{lat_end}_E{lon_start}{lon_end}.csv\"\n",
    "            \n",
    "            input_filepath = os.path.join(base_path, input_filename)\n",
    "            \n",
    "            # Read data\n",
    "            print(f\"Reading file: {input_filepath}\")\n",
    "            df = pd.read_csv(input_filepath)\n",
    "\n",
    "            # Process data\n",
    "            instance = data_map_by_hour.center_matching_hour(df, lat_start, lat_end, lon_start, lon_end)\n",
    "            orbit_map = instance.group_data_by_orbits()\n",
    "            \n",
    "            output_path = os.path.join(base_path, f'pickle_{year}')\n",
    "\n",
    "            # Ensure output directory exists\n",
    "            if not os.path.exists(output_path):\n",
    "                os.makedirs(output_path)\n",
    "            # Save pickle\n",
    "            output_filename = f\"orbit_map{str(year)[2:]}_{month_str}.pkl\"\n",
    "            output_filepath = os.path.join(output_path, output_filename)\n",
    "            with open(output_filepath, 'wb') as pickle_file:\n",
    "                pickle.dump(orbit_map, pickle_file)\n",
    "            \n",
    "            print(f\"Successfully processed and saved data for year {str(year)[2:]} month {month_str}.\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Warning: File {input_filename} not found. Skipping.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {input_filename}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/joonwonlee/Documents/GEMS_DATA/pickle_2024/orbit_map24_07.pkl'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_filepath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(output_filepath, 'rb') as pickle_file:\n",
    "    data_map_hour = pickle.load(pickle_file)\n",
    "\n",
    "\n",
    "# /Users/joonwonlee/Documents/GEMS_DATA/pickle_2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make consistent map matching by centers\n",
    "\n",
    "year =2024 or 2023   \n",
    "for month in range(start,end+1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed and saved data for year 23 month 01.\n",
      "Successfully processed and saved data for year 23 month 02.\n",
      "Successfully processed and saved data for year 23 month 03.\n",
      "Successfully processed and saved data for year 23 month 04.\n",
      "Successfully processed and saved data for year 23 month 05.\n",
      "Successfully processed and saved data for year 23 month 06.\n",
      "Successfully processed and saved data for year 23 month 07.\n",
      "Successfully processed and saved data for year 23 month 08.\n",
      "Successfully processed and saved data for year 23 month 09.\n",
      "Successfully processed and saved data for year 23 month 10.\n",
      "Successfully processed and saved data for year 23 month 11.\n",
      "Successfully processed and saved data for year 23 month 12.\n",
      "Successfully processed and saved data for year 24 month 01.\n",
      "Successfully processed and saved data for year 24 month 02.\n",
      "Successfully processed and saved data for year 24 month 03.\n",
      "Successfully processed and saved data for year 24 month 04.\n",
      "Successfully processed and saved data for year 24 month 05.\n",
      "Successfully processed and saved data for year 24 month 06.\n",
      "Successfully processed and saved data for year 24 month 07.\n",
      "Successfully processed and saved data for year 24 month 08.\n",
      "Successfully processed and saved data for year 24 month 09.\n",
      "Successfully processed and saved data for year 24 month 10.\n",
      "Successfully processed and saved data for year 24 month 11.\n",
      "Successfully processed and saved data for year 24 month 12.\n"
     ]
    }
   ],
   "source": [
    "# Base file path and settings\n",
    "# base_path = \"C:\\\\Users\\\\joonw\\\\TCO\\\\GEMS_data\"    MSI notebook\n",
    "base_path = config.mac_data_load_path\n",
    "output_path = base_path\n",
    "lat_start, lat_end, lon_start, lon_end = 5, 10, 110, 120\n",
    "\n",
    "# df = pd.read_csv(\"C:\\\\Users\\\\joonw\\\\TCO\\\\GEMS_data\\\\data_2024\\\\data_24_07_0131_N510_E110120.csv\")  MSI notebook\n",
    "df = pd.read_csv(\"/Users/joonwonlee/Documents/GEMS_DATA/data_2024/data_24_07_0131_N510_E110120.csv\")  # MAC\n",
    "instance = data_map_by_hour.center_matching_hour(df, lat_start, lat_end, lon_start, lon_end)  \n",
    "\n",
    "for year in years:        # years = [2023,2024]\n",
    "    for month in range(1, 13):  \n",
    "        try:\n",
    "            # Construct filenames dynamically\n",
    "            month_str = f\"{month:02d}\"  # Ensure month is zero-padded\n",
    "            if month == 2 and year==2023:\n",
    "                day_str = \"0128\"  # Handle February specifically\n",
    "            elif month ==2 and year==2024:\n",
    "                day_str = \"0129\"\n",
    "            else:\n",
    "                day_str = \"0131\" if (month in [1, 3, 5, 7, 8, 10, 12]) else \"0130\"\n",
    "\n",
    "            # load pickle\n",
    "            output_path = os.path.join(base_path, f'pickle_{year}')\n",
    "            input_filename = f\"orbit_map{str(year)[2:]}_{month_str}.pkl\"\n",
    "            input_filepath = os.path.join(output_path, input_filename)\n",
    "            with open(input_filepath, 'rb') as pickle_file:\n",
    "                loaded_map = pickle.load(pickle_file)\n",
    "            center_points = instance.make_center_points(step=0.05)\n",
    "            coarse_cen_map = instance.coarse_by_center(loaded_map, center_points)\n",
    "\n",
    "            # Save pickle\n",
    "            output_filename = f\"coarse_cen_map{str(year)[2:]}_{month_str}.pkl\"\n",
    "            output_filepath = os.path.join(output_path, output_filename)\n",
    "            with open(output_filepath, 'wb') as pickle_file:\n",
    "                pickle.dump(coarse_cen_map, pickle_file)\n",
    "            \n",
    "            print(f\"Successfully processed and saved data for year {str(year)[2:]} month {month_str}.\")\n",
    "        \n",
    "        except FileNotFoundError\n",
    "            print(f\"Warning: File {input_filename} not found. Skipping.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {input_filename}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original code below: use for debugging errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:\\\\Users\\\\joonw\\\\TCO\\\\data_engineering\\\\data_24_07_0131_N510_E110120.csv\")\n",
    "\n",
    "instance = orbitmap.MakeOrbitdata(df, 5,10,110,120)   # lat_s,lat_e, lon_s, lon_e\n",
    "with open('C:\\\\Users\\\\joonw\\\\TCO\\\\data_engineering\\\\orbit_map24_7.pkl', 'rb') as pickle_file:\n",
    "    orbit_map24_7 = pickle.load(pickle_file)\n",
    "\n",
    "center_points = instance.make_center_points(step=0.05)\n",
    "coarse_cen_map = instance.coarse_by_center(orbit_map24_7, center_points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's save dictionary map "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dictionary to a pickle file\n",
    "with open('C:\\\\Users\\\\joonw\\\\TCO\\\\data_engineering\\\\coarse_cen_map24_7.pkl', 'wb') as pickle_file:\n",
    "    pickle.dump(coarse_cen_map, pickle_file)\n",
    "\n",
    "# Load the dictionary from the pickle file\n",
    "with open('C:\\\\Users\\\\joonw\\\\TCO\\\\data_engineering\\\\coarse_cen_map24_7.pkl', 'rb') as pickle_file:\n",
    "    loaded_dict = pickle.load(pickle_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "faiss_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
