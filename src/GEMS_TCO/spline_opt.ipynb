{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "631d9529",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "# when python interpreter is different, add path\n",
    "gems_tco_path = \"/Users/joonwonlee/Documents/GEMS_TCO-1/src\"\n",
    "sys.path.append(gems_tco_path)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle \n",
    "from collections import defaultdict\n",
    "\n",
    "from pathlib import Path\n",
    "import time\n",
    "import json\n",
    "from json import JSONEncoder\n",
    "\n",
    "# Special functions and optimizations\n",
    "from typing import Callable, Union, Tuple\n",
    "from scipy.spatial.distance import cdist  # For space and time distance\n",
    "from scipy.special import gamma, kv  # Bessel function and gamma function\n",
    "from scipy.interpolate import splrep, splev\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torchcubicspline import natural_cubic_spline_coeffs, NaturalCubicSpline\n",
    "\n",
    "import GEMS_TCO\n",
    "from GEMS_TCO import kernels \n",
    "from GEMS_TCO import orderings as _orderings\n",
    "from GEMS_TCO import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a1b70ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Day 12 data size per day: 200.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "lat_lon_resolution = [10,10]\n",
    "years = ['2024']\n",
    "month_range =[7,8]\n",
    "nheads = 200\n",
    "\n",
    "# input_path = \"/Users/joonwonlee/Documents/GEMS_TCO-1/Exercises/st_model/estimates\"\n",
    "input_path = \"C:\\\\Users\\\\joonw\\\\tco\\\\GEMS_TCO-2\\\\Exercises\\\\st_model\\\\estimates\\\\\"   # window\n",
    "input_path = \"/Users/joonwonlee/Documents/GEMS_TCO-1/Exercises/st_model/estimates/save/Apirl_16_24smooth_0.5\"   # mac\n",
    "# input_filename = \"vecc_extra_estimates_50_july24.pkl\"\n",
    "# input_filename = \"vecc_inter_estimates_1250_july24.pkl\"\n",
    "\n",
    "# input_filename = \"vecc_inter_estimates_5000_july24.pkl\"\n",
    "# input_filename = \"estimation_200_july24.pkl\"\n",
    "input_filename = \"full_estimates_1250_july24.pkl\"\n",
    "input_filepath = os.path.join(input_path, input_filename)\n",
    "# Load pickle\n",
    "with open(input_filepath, 'rb') as pickle_file:\n",
    "    amarel_map1250= pickle.load(pickle_file)\n",
    "\n",
    "# Assuming df_1250 is your DataFrame\n",
    "df_1250 = pd.DataFrame()\n",
    "for key in amarel_map1250:\n",
    "    tmp = pd.DataFrame(amarel_map1250[key][0].reshape(1, -1), columns=['sigmasq', 'range_lat', 'range_lon', 'advec_lat', 'advec_lon', 'beta', 'nugget'])\n",
    "    tmp['loss'] = amarel_map1250[key][1]\n",
    "    df_1250 = pd.concat((df_1250, tmp), axis=0)\n",
    "\n",
    "# Generate date range\n",
    "date_range = pd.date_range(start='07-01-24', end='07-31-24')\n",
    "\n",
    "# Ensure the number of dates matches the number of rows in df_1250\n",
    "if len(date_range) == len(df_1250):\n",
    "    df_1250.index = date_range\n",
    "else:\n",
    "    print(\"The number of dates does not match the number of rows in the DataFrame.\")\n",
    "\n",
    "df = df_1250\n",
    "# Save DataFrame to CSV\n",
    "output_filename = 'full_estimates_1250_july24.csv'\n",
    "output_csv_path = os.path.join(input_path, output_filename)\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "for day in range(12,13):\n",
    "    print(f'\\n Day {day} data size per day: { (200/lat_lon_resolution[0])*(100/lat_lon_resolution[0])  } \\n')\n",
    "\n",
    "    # parameters\n",
    "    mm_cond_number = 10 \n",
    "    idx_for_datamap= [ 8*(day),8*(day+1)]\n",
    "    # params = [ 27.25, 2.18, 2.294, 4.099e-4, -0.07915, 0.0999, 3.65]   #200\n",
    "    params = list(df.iloc[day-1][:-1])\n",
    "    params = torch.tensor(params, dtype=torch.float64, requires_grad=True)\n",
    "\n",
    "    # data\n",
    "    # input_path = Path(\"C:\\\\Users\\\\joonw\\\\tco\\\\Extracted_data\")  # window\n",
    "    input_path = Path(\"/Users/joonwonlee/Documents/GEMS_DATA\")\n",
    "    instance = load_data(input_path)\n",
    "    map, ord_mm, nns_map= instance.load_mm20k_data_bymonthyear( lat_lon_resolution= lat_lon_resolution, mm_cond_number=mm_cond_number,years_=years, months_=month_range)\n",
    "    analysis_data_map, aggregated_data = instance.load_working_data_byday( map, ord_mm, nns_map, idx_for_datamap= idx_for_datamap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7194b220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2130.5818, dtype=torch.float64, grad_fn=<MulBackward0>) tensor(2130.5819, dtype=torch.float64, grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "spline_instance = kernels.spline(epsilon = 1e-17, coarse_factor=5, k=3, smooth = 0.5, input_map= analysis_data_map, aggregated_data= aggregated_data, nns_map=nns_map, mm_cond_number=10)\n",
    "distances, non_zero_indices = spline_instance.precompute_coords_anisotropy(params, spline_instance.aggregated_data[:,:4], spline_instance.aggregated_data[:,:4])\n",
    "flat_distances = distances.flatten()\n",
    "spline_instance.max_distance = torch.max(distances).clone().detach()\n",
    "spline_instance.max_distance_len = len(flat_distances)\n",
    "\n",
    "spline_instance.spline_object = spline_instance.fit_cubic_spline(params)\n",
    "# cov_matrix = cov_matrix.clone().detach()\n",
    "full_ll = spline_instance.full_likelihood_using_spline( params, distances)\n",
    "full_ll\n",
    "\n",
    "instance_2 = kernels.vecchia_experiment(1.0, analysis_data_map, aggregated_data,nns_map,mm_cond_number, nheads)\n",
    "excat_ll = instance_2.full_likelihood(params, aggregated_data[:,:4], aggregated_data[:,2], instance_2.matern_cov_anisotropy_v05)\n",
    "\n",
    "print(excat_ll, full_ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9acc1f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([23.0360,  2.3000,  3.3470, -0.0543,  0.1150,  0.1102,  1.6049],\n",
      "       dtype=torch.float64, requires_grad=True)\n",
      "Epoch 1, Gradients: [ 3.82639586e-02 -1.92827436e+01 -1.59901149e+01  1.04869849e+02\n",
      " -3.59306731e+01 -5.23839481e+02 -4.87966575e+00]\n",
      " Loss: 2130.5818587448402, Parameters: [23.03603363  2.29999757  3.3469553  -0.0542808   0.11497638  0.11015477\n",
      "  1.6048981 ]\n",
      "Epoch 11, Gradients: [  0.33259296  -0.92272583  -6.70887273  60.62392948 -52.047816\n",
      " 124.08680837   1.10535847]\n",
      " Loss: 2124.926963801744, Parameters: [22.79929384  2.49067737  3.53241376 -0.03799972  0.05550861  0.1508821\n",
      "  1.50868145]\n",
      "Epoch 21, Gradients: [ -0.38195001  -6.23950696  -7.69074182 -24.11834231 -11.39735428\n",
      "  -4.2476962   -3.9836226 ]\n",
      " Loss: 2119.2663028113416, Parameters: [22.70140339  2.56525392  3.61445456 -0.12826187  0.11650132  0.12723796\n",
      "  1.53477179]\n",
      "Epoch 31, Gradients: [-3.80219061e-02  1.68876690e+00 -7.37630521e+00 -2.09568200e+01\n",
      "  1.82972606e+01 -5.56132062e+01  8.17135687e-01]\n",
      " Loss: 2119.0056819744445, Parameters: [22.76601898  2.60656619  3.6712337  -0.12270083  0.15284393  0.12273894\n",
      "  1.66439492]\n",
      "Epoch 41, Gradients: [ -0.13411801  -1.34955122  -4.63358918  26.34305057  -6.8896976\n",
      " -11.4455939   -0.68374092]\n",
      " Loss: 2118.5583134831727, Parameters: [22.77794611  2.62566371  3.71821524 -0.08526133  0.13201884  0.12602033\n",
      "  1.64420071]\n",
      "Epoch 51, Gradients: [-0.20457026 -3.54803023 -7.66050952 -6.39701195 14.62373569 11.52108953\n",
      " -1.0347863 ]\n",
      " Loss: 2118.2024931627916, Parameters: [22.82888136  2.63769633  3.76104058 -0.11481107  0.13612522  0.12438903\n",
      "  1.64175148]\n",
      "Epoch 61, Gradients: [-0.0703435   0.13078123 -3.14702597  8.11294794 -9.25075421 -5.86464494\n",
      "  0.36197064]\n",
      " Loss: 2117.932837640999, Parameters: [22.94683916  2.65281393  3.81096859 -0.10540194  0.12744254  0.12312255\n",
      "  1.68491103]\n",
      "Epoch 71, Gradients: [ -0.2035074   -0.76076087  -5.31182826  12.47876605  -3.18007513\n",
      " -27.24225356  -0.97200037]\n",
      " Loss: 2117.7417797331136, Parameters: [23.04091922  2.66840794  3.85964784 -0.1036296   0.13355154  0.12134526\n",
      "  1.67377638]\n",
      "Epoch 81, Gradients: [-0.0992255  -4.77306033  3.01232692  0.826344    1.14375047 18.10687045\n",
      "  0.09672304]\n",
      " Loss: 2117.524261735476, Parameters: [23.16957789  2.67651969  3.90911885 -0.10364181  0.13613222  0.12235532\n",
      "  1.68847764]\n",
      "Epoch 91, Gradients: [-0.12143182 -1.28844467 -6.86556045 16.96235959  5.37761419  7.04307091\n",
      " -0.06061952]\n",
      " Loss: 2117.3095980883854, Parameters: [23.30881508  2.70398815  3.96069128 -0.10282935  0.13190878  0.12060455\n",
      "  1.70016663]\n",
      "FINAL STATE: Epoch 100, Loss: 2117.086251042193, \n",
      " vecc Parameters: [23.46279966  2.7387748   4.01873266 -0.10335029  0.13203405  0.11936854\n",
      "  1.71139018]\n"
     ]
    }
   ],
   "source": [
    "print(params)\n",
    "\n",
    "# optimizer, scheduler =  instance.optimizer_fun(params, lr= 0.01 , betas=(0.9, 0.99), eps=1e-8, step_size= 5, gamma=0.1)    \n",
    "optimizer, scheduler = spline_instance.optimizer_fun(params, lr=0.03, betas=(0.9, 0.99), eps=1e-8, step_size=100, gamma=0.9)  \n",
    "\n",
    "\n",
    "out, epoch = spline_instance.run_full(params, optimizer,scheduler, epochs=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce1e4e2",
   "metadata": {},
   "source": [
    "# Saved files below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81cd5e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class spline:\n",
    "    def __init__(self, epsilon, coarse_factor, k, smooth):\n",
    "        self.smooth = torch.tensor(smooth, dtype= torch.float64)\n",
    "        self.k = k\n",
    "        self.coarse_factor = coarse_factor\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def compute_cov(self, params) :\n",
    "         # fit_distances and flat_distances both 1d\n",
    "        sigmasq, range_lat, range_lon, advec_lat, advec_lon, beta, nugget = params\n",
    "        distances, non_zero_indices = instance_2.precompute_coords_anisotropy(params, aggregated_data[:,:4],aggregated_data[:,:4])\n",
    "        \n",
    "        flat_distances = distances.flatten()\n",
    "        fit_distances = torch.linspace(self.epsilon, torch.max(flat_distances), len(flat_distances) // self.coarse_factor)\n",
    "\n",
    "        # fit_distances = torch.zeros_like(distances)\n",
    "        # print(fit_distances.shape)\n",
    "        # Compute the covariance for non-zero distances\n",
    "        non_zero_indices = fit_distances != 0\n",
    "        out = torch.zeros_like(fit_distances, dtype= torch.float64)\n",
    "\n",
    "        if torch.any(non_zero_indices):\n",
    "            tmp = kv(self.smooth, torch.sqrt(fit_distances[non_zero_indices])).double().clone()\n",
    "            out[non_zero_indices] = (sigmasq * (2**(1-self.smooth)) / gamma(self.smooth) *\n",
    "                                    (torch.sqrt(fit_distances[non_zero_indices]) ) ** self.smooth *\n",
    "                                    tmp)\n",
    "        out[~non_zero_indices] = sigmasq\n",
    "\n",
    "        # print(out.shape)\n",
    "        #         \n",
    "        # Compute spline coefficients\n",
    "        coeffs = natural_cubic_spline_coeffs(fit_distances, out.unsqueeze(1))\n",
    "\n",
    "        # Create spline object\n",
    "        spline = NaturalCubicSpline(coeffs)\n",
    "        # Interpolate using the spline\n",
    "        out = spline.evaluate(distances)\n",
    "        out = out.reshape(distances.shape)\n",
    "        out += torch.eye(out.shape[0], dtype=torch.float64) * nugget \n",
    "        return out\n",
    "     \n",
    "    def full_likelihood(self,params: torch.Tensor, input_np: torch.Tensor, y: torch.Tensor, cov_matrix) -> torch.Tensor:\n",
    "        input_arr = input_np[:, :4]  ## input_np is aggregated data over a day.\n",
    "        y_arr = y\n",
    "\n",
    "        # Compute the covariance matrix\n",
    "        # cov_matrix = covariance_function(params=params, y=input_arr, x=input_arr)\n",
    "        \n",
    "        # Compute the log determinant of the covariance matrix\n",
    "        sign, log_det = torch.slogdet(cov_matrix)\n",
    "        # if sign <= 0:\n",
    "        #     raise ValueError(\"Covariance matrix is not positive definite\")\n",
    "        \n",
    "        # Extract locations\n",
    "        locs = input_arr[:, :2]\n",
    "\n",
    "        # Compute beta\n",
    "        tmp1 = torch.matmul(locs.T, torch.linalg.solve(cov_matrix, locs))\n",
    "        tmp2 = torch.matmul(locs.T, torch.linalg.solve(cov_matrix, y_arr))\n",
    "        beta = torch.linalg.solve(tmp1, tmp2)\n",
    "\n",
    "        # Compute the mean\n",
    "        mu = torch.matmul(locs, beta)\n",
    "        y_mu = y_arr - mu\n",
    "\n",
    "        # Compute the quadratic form\n",
    "        quad_form = torch.matmul(y_mu, torch.linalg.solve(cov_matrix, y_mu))\n",
    "\n",
    "        # Compute the negative log likelihood\n",
    "        neg_log_lik = 0.5 * (log_det + quad_form)\n",
    "     \n",
    "        return  neg_log_lik\n",
    "    \n",
    "    def compute_full_nll(self, params, covariance_function):\n",
    "        cov_mat = covariance_function(params) \n",
    "        nll = self.full_likelihood( params,aggregated_data[:,:4], aggregated_data[:,2], cov_mat)\n",
    "        return nll\n",
    "\n",
    "    def optimizer_fun(self, params, lr=0.01, betas=(0.9, 0.8), eps=1e-8, step_size=40, gamma=0.5):\n",
    "        optimizer = torch.optim.Adam([params], lr=lr, betas=betas, eps=eps)\n",
    "        scheduler = StepLR(optimizer, step_size=step_size, gamma=gamma)  # Decrease LR by a factor of 0.1 every 10 epochs\n",
    "        return optimizer, scheduler\n",
    "\n",
    "   # use adpating lr\n",
    "    def run_full(self, params, optimizer, scheduler,  covariance_function, epochs=10 ):\n",
    "        prev_loss= float('inf')\n",
    "\n",
    "        tol = 1e-4  # Convergence tolerance\n",
    "        for epoch in range(epochs):  # Number of epochs\n",
    "            optimizer.zero_grad()  # Zero the gradients \n",
    "            \n",
    "            loss = self.compute_full_nll(params, covariance_function)\n",
    "            loss.backward()  # Backpropagate the loss\n",
    "            \n",
    "            # Print gradients and parameters every 10th epoch\n",
    "            if epoch % 10 == 0:\n",
    "                print(f'Epoch {epoch+1}, Gradients: {params.grad.numpy()}\\n Loss: {loss.item()}, Parameters: {params.detach().numpy()}')\n",
    "            \n",
    "            # if epoch % 500 == 0:\n",
    "            #     print(f'Epoch {epoch+1}, Gradients: {params.grad.numpy()}\\n Loss: {loss.item()}, Parameters: {params.detach().numpy()}')\n",
    "            \n",
    "            optimizer.step()  # Update the parameters\n",
    "            scheduler.step()  # Update the learning rate\n",
    "            # Check for convergence\n",
    "            if abs(prev_loss - loss.item()) < tol:\n",
    "                print(f\"Converged at epoch {epoch}\")\n",
    "                print(f'Epoch {epoch+1}, : Loss: {loss.item()}, \\n vecc Parameters: {params.detach().numpy()}')\n",
    "                break\n",
    "\n",
    "            prev_loss = loss.item()\n",
    "        print(f'FINAL STATE: Epoch {epoch+1}, Loss: {loss.item()}, \\n vecc Parameters: {params.detach().numpy()}')\n",
    "        return params.detach().numpy().tolist() + [ loss.item()], epoch\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bf7ade",
   "metadata": {},
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de089b77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "719e5ea7",
   "metadata": {},
   "source": [
    "# Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426935a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(params)\n",
    "\n",
    "instance_2 = kernels.vecchia_experiment(1.0, analysis_data_map, aggregated_data,nns_map,mm_cond_number, nheads)\n",
    "instance = spline( epsilon = 1e-8, coarse_factor = 4, k=3, smooth= 0.5)\n",
    "# optimizer, scheduler =  instance.optimizer_fun(params, lr= 0.01 , betas=(0.9, 0.99), eps=1e-8, step_size= 5, gamma=0.1)    \n",
    "optimizer, scheduler = instance.optimizer_fun(params, lr=0.03, betas=(0.9, 0.99), eps=1e-8, step_size=100, gamma=0.9)  \n",
    "out, epoch = instance.run_full(params, optimizer,scheduler, instance.compute_cov, epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d69fb24e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 2.8198, 2.0805,  ..., 1.4813, 0.5896, 1.7424],\n",
       "        [2.8198, 0.0000, 9.7185,  ..., 3.6351, 3.4548, 4.7177],\n",
       "        [2.0805, 9.7185, 0.0000,  ..., 4.4068, 2.6395, 4.0108],\n",
       "        ...,\n",
       "        [1.4813, 3.6351, 4.4068,  ..., 0.0000, 0.8485, 0.0821],\n",
       "        [0.5896, 3.4548, 2.6395,  ..., 0.8485, 0.0000, 1.0949],\n",
       "        [1.7424, 4.7177, 4.0108,  ..., 0.0821, 1.0949, 0.0000]],\n",
       "       dtype=torch.float64, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out1 = splinenn.evaluate(distances)\n",
    "out1 = out1.reshape(distances.shape)\n",
    "\n",
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41c5a49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000])\n",
      "torch.Size([40000])\n",
      "tensor([[24.8247,  4.3205,  5.4749,  ...,  6.8587, 10.7482,  6.1878],\n",
      "        [ 4.3205, 24.8247,  1.0255,  ...,  3.4418,  3.6106,  2.6395],\n",
      "        [ 5.4749,  1.0255, 24.8247,  ...,  2.8387,  4.5628,  3.1264],\n",
      "        ...,\n",
      "        [ 6.8587,  3.4418,  2.8387,  ..., 24.8247,  9.2207, 17.3917],\n",
      "        [10.7482,  3.6106,  4.5628,  ...,  9.2207, 24.8247,  8.1353],\n",
      "        [ 6.1878,  2.6395,  3.1264,  ..., 17.3917,  8.1353, 24.8247]],\n",
      "       dtype=torch.float64, grad_fn=<AsStridedBackward0>)\n",
      "tensor([[24.8270,  4.3205,  5.4749,  ...,  6.8587, 10.7482,  6.1878],\n",
      "        [ 4.3205, 24.8270,  1.0255,  ...,  3.4418,  3.6106,  2.6395],\n",
      "        [ 5.4749,  1.0255, 24.8270,  ...,  2.8387,  4.5628,  3.1264],\n",
      "        ...,\n",
      "        [ 6.8587,  3.4418,  2.8387,  ..., 24.8270,  9.2207, 17.3917],\n",
      "        [10.7482,  3.6106,  4.5628,  ...,  9.2207, 24.8270,  8.1353],\n",
      "        [ 6.1878,  2.6395,  3.1264,  ..., 17.3917,  8.1353, 24.8270]],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(601.6160, dtype=torch.float64, grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smooth = 0.5\n",
    "\n",
    "instance_2 = kernels.vecchia_experiment(smooth, analysis_data_map, aggregated_data,nns_map,mm_cond_number, nheads)\n",
    "instance = spline( epsilon = 1e-15, coarse_factor = 2, k=3, smooth= smooth)\n",
    "\n",
    "distances, non_zero_indices = instance_2.precompute_coords_anisotropy(params, aggregated_data[:,:4],aggregated_data[:,:4])\n",
    "\n",
    "flat_distances = distances.flatten()\n",
    "sigmasq, range_lat, range_lon, advec_lat, advec_lon, beta, nugget = params\n",
    "epsilon = 1e-8\n",
    "coarse_factor = 4\n",
    "\n",
    "fit_distances = torch.linspace(epsilon, torch.max(flat_distances), len(flat_distances) // coarse_factor)\n",
    "print(fit_distances.shape)\n",
    "# Compute the covariance for non-zero distances\n",
    "non_zero_indices = fit_distances != 0\n",
    "out = torch.zeros_like(fit_distances, dtype= torch.float64)\n",
    "\n",
    "if torch.any(non_zero_indices):\n",
    "    tmp = kv(smooth, torch.sqrt(fit_distances[non_zero_indices])).double().clone()\n",
    "    out[non_zero_indices] = (sigmasq * (2**(1-smooth)) / gamma(smooth) *\n",
    "                            (torch.sqrt(fit_distances[non_zero_indices]) ) ** smooth *\n",
    "                            tmp)\n",
    "    \n",
    "out[~non_zero_indices] = sigmasq\n",
    "\n",
    "print(out.shape)\n",
    "\n",
    "# Compute spline coefficients\n",
    "coeffs = natural_cubic_spline_coeffs(fit_distances, out.unsqueeze(1))\n",
    "\n",
    "# Create spline object\n",
    "splinenn = NaturalCubicSpline(coeffs)\n",
    "\n",
    "# Interpolate using the spline\n",
    "out1 = splinenn.evaluate(distances)\n",
    "out1 = out1.reshape(distances.shape)\n",
    "out1 += torch.eye(out1.shape[0], dtype=torch.float64) * nugget \n",
    "\n",
    "print(out1)\n",
    "out2 = instance_2.matern_cov_anisotropy_kv(params, aggregated_data[:,:4],aggregated_data[:,:4])\n",
    "\n",
    "\n",
    "print(out2)\n",
    "instance.full_likelihood( params,aggregated_data[:,:4], aggregated_data[:,2], out1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "faiss_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
