{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# work environment: jl2815\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sys\n",
    "import os\n",
    "gems_tco_path = \"/Users/joonwonlee/Documents/GEMS_TCO-1/src\"\n",
    "sys.path.append(gems_tco_path)\n",
    "\n",
    "\n",
    "# work with jl2815 environment\n",
    "\n",
    "# Ignore warnings due to duplicated dimension names\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"xarray\")\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "from GEMS_TCO import configuration as config\n",
    "from GEMS_TCO import data_preprocess as dmbh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load ORI pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/joonwonlee/Documents/GEMS_DATA/pickle_2024/orbit_map24_07.pkl\n"
     ]
    }
   ],
   "source": [
    "mac_data_path = config.mac_data_load_path\n",
    "years = [2024]  # years = [2023,2024]\n",
    "months = list( range(7,8))\n",
    "year = years[0]\n",
    "month = months[0]\n",
    "month_str = f\"{month:02d}\"  \n",
    "filename = f\"pickle_2024/orbit_map{str(year)[2:]}_{month_str}.pkl\"\n",
    "picklefile_path = Path(mac_data_path) / filename\n",
    "print(picklefile_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(picklefile_path, 'rb') as pickle_file:\n",
    "    data_map_hour = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Time</th>\n",
       "      <th>ColumnAmountO3</th>\n",
       "      <th>FinalAlgorithmFlags</th>\n",
       "      <th>Hours_elapsed</th>\n",
       "      <th>Orbit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
<<<<<<< HEAD
<<<<<<< HEAD
       "      <td>4.995398</td>\n",
       "      <td>134.99959</td>\n",
       "      <td>2024-07-01 00:52:00</td>\n",
       "      <td>261.60358</td>\n",
=======
=======
>>>>>>> 0a418ac421c02a3cd32b6e4c97b2bdc92cdb79b7
       "      <td>4.998375</td>\n",
       "      <td>132.98442</td>\n",
       "      <td>2024-07-01 00:52:00</td>\n",
       "      <td>260.68182</td>\n",
<<<<<<< HEAD
>>>>>>> 98fc71c474ddced6792e89e9ab27c07529da5b48
=======
>>>>>>> 0a418ac421c02a3cd32b6e4c97b2bdc92cdb79b7
       "      <td>2.0</td>\n",
       "      <td>477720.866667</td>\n",
       "      <td>2024-07-01 00:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
<<<<<<< HEAD
<<<<<<< HEAD
       "      <td>4.995464</td>\n",
       "      <td>134.93628</td>\n",
       "      <td>2024-07-01 00:52:00</td>\n",
       "      <td>261.10318</td>\n",
=======
=======
>>>>>>> 0a418ac421c02a3cd32b6e4c97b2bdc92cdb79b7
       "      <td>4.998421</td>\n",
       "      <td>132.92055</td>\n",
       "      <td>2024-07-01 00:52:00</td>\n",
       "      <td>262.34076</td>\n",
<<<<<<< HEAD
>>>>>>> 98fc71c474ddced6792e89e9ab27c07529da5b48
=======
>>>>>>> 0a418ac421c02a3cd32b6e4c97b2bdc92cdb79b7
       "      <td>2.0</td>\n",
       "      <td>477720.866667</td>\n",
       "      <td>2024-07-01 00:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
<<<<<<< HEAD
<<<<<<< HEAD
       "      <td>4.995531</td>\n",
       "      <td>134.87337</td>\n",
       "      <td>2024-07-01 00:52:00</td>\n",
       "      <td>261.95117</td>\n",
=======
=======
>>>>>>> 0a418ac421c02a3cd32b6e4c97b2bdc92cdb79b7
       "      <td>4.998329</td>\n",
       "      <td>132.85893</td>\n",
       "      <td>2024-07-01 00:52:00</td>\n",
       "      <td>262.01970</td>\n",
<<<<<<< HEAD
>>>>>>> 98fc71c474ddced6792e89e9ab27c07529da5b48
=======
>>>>>>> 0a418ac421c02a3cd32b6e4c97b2bdc92cdb79b7
       "      <td>2.0</td>\n",
       "      <td>477720.866667</td>\n",
       "      <td>2024-07-01 00:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
<<<<<<< HEAD
<<<<<<< HEAD
       "      <td>4.995568</td>\n",
       "      <td>134.80946</td>\n",
       "      <td>2024-07-01 00:52:00</td>\n",
       "      <td>263.50323</td>\n",
=======
=======
>>>>>>> 0a418ac421c02a3cd32b6e4c97b2bdc92cdb79b7
       "      <td>4.998335</td>\n",
       "      <td>132.79536</td>\n",
       "      <td>2024-07-01 00:52:00</td>\n",
       "      <td>264.06370</td>\n",
<<<<<<< HEAD
>>>>>>> 98fc71c474ddced6792e89e9ab27c07529da5b48
=======
>>>>>>> 0a418ac421c02a3cd32b6e4c97b2bdc92cdb79b7
       "      <td>2.0</td>\n",
       "      <td>477720.866667</td>\n",
       "      <td>2024-07-01 00:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
<<<<<<< HEAD
<<<<<<< HEAD
       "      <td>4.995701</td>\n",
       "      <td>134.74683</td>\n",
       "      <td>2024-07-01 00:52:00</td>\n",
       "      <td>264.14905</td>\n",
=======
=======
>>>>>>> 0a418ac421c02a3cd32b6e4c97b2bdc92cdb79b7
       "      <td>4.998388</td>\n",
       "      <td>132.73280</td>\n",
       "      <td>2024-07-01 00:52:00</td>\n",
       "      <td>262.72656</td>\n",
<<<<<<< HEAD
>>>>>>> 98fc71c474ddced6792e89e9ab27c07529da5b48
=======
>>>>>>> 0a418ac421c02a3cd32b6e4c97b2bdc92cdb79b7
       "      <td>2.0</td>\n",
       "      <td>477720.866667</td>\n",
       "      <td>2024-07-01 00:52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Latitude  Longitude                 Time  ColumnAmountO3  \\\n",
<<<<<<< HEAD
<<<<<<< HEAD
       "0  4.995398  134.99959  2024-07-01 00:52:00       261.60358   \n",
       "1  4.995464  134.93628  2024-07-01 00:52:00       261.10318   \n",
       "2  4.995531  134.87337  2024-07-01 00:52:00       261.95117   \n",
       "3  4.995568  134.80946  2024-07-01 00:52:00       263.50323   \n",
       "4  4.995701  134.74683  2024-07-01 00:52:00       264.14905   \n",
=======
=======
>>>>>>> 0a418ac421c02a3cd32b6e4c97b2bdc92cdb79b7
       "0  4.998375  132.98442  2024-07-01 00:52:00       260.68182   \n",
       "1  4.998421  132.92055  2024-07-01 00:52:00       262.34076   \n",
       "2  4.998329  132.85893  2024-07-01 00:52:00       262.01970   \n",
       "3  4.998335  132.79536  2024-07-01 00:52:00       264.06370   \n",
       "4  4.998388  132.73280  2024-07-01 00:52:00       262.72656   \n",
<<<<<<< HEAD
>>>>>>> 98fc71c474ddced6792e89e9ab27c07529da5b48
=======
>>>>>>> 0a418ac421c02a3cd32b6e4c97b2bdc92cdb79b7
       "\n",
       "   FinalAlgorithmFlags  Hours_elapsed             Orbit  \n",
       "0                  2.0  477720.866667  2024-07-01 00:52  \n",
       "1                  2.0  477720.866667  2024-07-01 00:52  \n",
       "2                  2.0  477720.866667  2024-07-01 00:52  \n",
       "3                  2.0  477720.866667  2024-07-01 00:52  \n",
       "4                  2.0  477720.866667  2024-07-01 00:52  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_map_hour['y24m07day01_hm00:52'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
<<<<<<< HEAD
    "### 2. Make consistent map matching by centers and latitude adjustment\n",
=======
    "### Make consistent map matching by centers\n",
>>>>>>> 98fc71c474ddced6792e89e9ab27c07529da5b48
=======
    "### Make consistent map matching by centers\n",
>>>>>>> 0a418ac421c02a3cd32b6e4c97b2bdc92cdb79b7
    "\n",
    "year =2024 or 2023   \n",
    "for month in range(start,end+1)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed and saved data for year 24 month 07.\n"
     ]
    }
   ],
   "source": [
    "# Base file path and settings\n",
    "# base_path = \"C:\\\\Users\\\\joonw\\\\TCO\\\\GEMS_data\"    MSI notebook\n",
    "\n",
    "mac_data_path = config.mac_data_load_path\n",
<<<<<<< HEAD
<<<<<<< HEAD
    "#lat_start, lat_end, lon_start, lon_end = 0, 5, 123, 133\n",
    "lat_start, lat_end, lon_start, lon_end = -5, 7, 118, 135\n",
    "step_lat, step_lon = 0.044, 0.063\n",
    "\n",
    "# df = pd.read_csv(\"C:\\\\Users\\\\joonw\\\\TCO\\\\GEMS_data\\\\data_2024\\\\data_24_07_0131_N510_E110120.csv\")  MSI notebook\n",
    "#df = pd.read_csv(\"/Users/joonwonlee/Documents/GEMS_DATA/data_2024/data_24_07_0131_N05_E123133.csv\")  # MAC\n",
    "df = pd.read_csv(\"/Users/joonwonlee/Documents/GEMS_DATA/data_2024/data_24_07_0131_N-57_E118135.csv\")  # MAC\n",
=======
=======
>>>>>>> 0a418ac421c02a3cd32b6e4c97b2bdc92cdb79b7
    "lat_start, lat_end, lon_start, lon_end = 0, 5, 123, 133\n",
    "step_lat, step_lon = 0.044, 0.063\n",
    "\n",
    "# df = pd.read_csv(\"C:\\\\Users\\\\joonw\\\\TCO\\\\GEMS_data\\\\data_2024\\\\data_24_07_0131_N510_E110120.csv\")  MSI notebook\n",
    "df = pd.read_csv(\"/Users/joonwonlee/Documents/GEMS_DATA/data_2024/data_24_07_0131_N05_E123133.csv\")  # MAC\n",
<<<<<<< HEAD
>>>>>>> 98fc71c474ddced6792e89e9ab27c07529da5b48
=======
>>>>>>> 0a418ac421c02a3cd32b6e4c97b2bdc92cdb79b7
    "instance = dmbh.center_matching_hour(df, lat_start, lat_end, lon_start, lon_end)  \n",
    "\n",
    "for year in years:        # years = [2023,2024]\n",
    "    for month in months:  \n",
    "        try:\n",
    "            # load pickle (dense ORI data)\n",
    "            pickle_path = os.path.join(mac_data_path, f'pickle_{year}')\n",
    "            input_filename = f\"orbit_map{str(year)[2:]}_{month_str}.pkl\"\n",
    "            input_filepath = os.path.join(pickle_path, input_filename)\n",
    "            with open(input_filepath, 'rb') as pickle_file:\n",
    "                loaded_map = pickle.load(pickle_file)\n",
    "            center_points = instance.make_center_points(step_lat = step_lat, step_lon= step_lon)\n",
    "            coarse_cen_map = instance.coarse_by_center(loaded_map, center_points)\n",
    "\n",
    "            # Save pickle (coarse data)\n",
    "            output_filename = f\"coarse_cen_map{str(year)[2:]}_{month_str}.pkl\"\n",
    "            output_filepath = os.path.join(pickle_path, output_filename)\n",
    "            with open(output_filepath, 'wb') as pickle_file:\n",
    "                pickle.dump(coarse_cen_map, pickle_file)\n",
    "            \n",
    "            print(f\"Successfully processed and saved data for year {str(year)[2:]} month {month_str}.\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Warning: File {input_filename} not found. Skipping.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {input_filename}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original code below: use for debugging errors"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 6,
=======
   "execution_count": 11,
>>>>>>> 98fc71c474ddced6792e89e9ab27c07529da5b48
=======
   "execution_count": 11,
>>>>>>> 0a418ac421c02a3cd32b6e4c97b2bdc92cdb79b7
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_path = os.path.join(mac_data_path, f'pickle_{year}')\n",
    "output_filename = f\"coarse_cen_map{str(year)[2:]}_{month_str}.pkl\"\n",
    "output_filepath = os.path.join(pickle_path, output_filename)\n",
    "\n",
    "with open(output_filepath, 'rb') as pickle_file:\n",
    "    cbmap = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
=======
>>>>>>> 0a418ac421c02a3cd32b6e4c97b2bdc92cdb79b7
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n",
      "(18126, 7)\n"
     ]
    }
   ],
<<<<<<< HEAD
>>>>>>> 98fc71c474ddced6792e89e9ab27c07529da5b48
=======
>>>>>>> 0a418ac421c02a3cd32b6e4c97b2bdc92cdb79b7
   "source": [
    "keys = list(cbmap.keys())\n",
    "for key in keys:\n",
    "    print(cbmap[key].shape)"
   ]
<<<<<<< HEAD
<<<<<<< HEAD
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. without adjusting latitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Data Coarsening Process ---\n",
      "Loading base dataframe from: /Users/joonwonlee/Documents/GEMS_DATA/data_2024/data_24_07_0131_N-57_E118135.csv\n",
      "\n",
      "Processing: Year 2024, Month 07\n",
      "  Loading: orbit_map24_07.pkl\n",
      "  Generating center points (without calibration)...\n",
      "  Coarsening data by center...\n",
      "  Saving: coarse_cen_map_without_decrement_latitude24_07.pkl\n",
      "  Successfully processed and saved data for 2024-07.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# Assume your custom modules 'dmbh' and 'config' are available\n",
    "# import dmbh\n",
    "# import config\n",
    "\n",
    "def process_and_save_coarse_data(base_path, years, months, lat_lon_bounds, step_sizes, base_csv_path):\n",
    "    \"\"\"\n",
    "    Loads orbit map data, processes it to a coarse grid without calibration,\n",
    "    and saves the result as a pickle file for specified years and months.\n",
    "    \"\"\"\n",
    "    print(\"--- Starting Data Coarsening Process ---\")\n",
    "    \n",
    "    # Unpack settings\n",
    "    lat_start, lat_end, lon_start, lon_end = lat_lon_bounds\n",
    "    step_lat, step_lon = step_sizes\n",
    "    \n",
    "    # --- Initial Setup ---\n",
    "    # Create the processing instance using the provided base dataframe\n",
    "    try:\n",
    "        print(f\"Loading base dataframe from: {base_csv_path}\")\n",
    "        df = pd.read_csv(base_csv_path)\n",
    "        instance = dmbh.center_matching_hour(df, lat_start, lat_end, lon_start, lon_end)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Base CSV file not found at {base_csv_path}. Aborting.\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing dmbh instance: {e}\")\n",
    "        return\n",
    "\n",
    "    # --- Main Processing Loop ---\n",
    "    for year in years:\n",
    "        for month in months:\n",
    "            month_str = f\"{month:02d}\"\n",
    "            print(f\"\\nProcessing: Year {year}, Month {month_str}\")\n",
    "            \n",
    "            try:\n",
    "                pickle_path = os.path.join(base_path, f'pickle_{year}')\n",
    "                \n",
    "                # Define input and output filenames\n",
    "                input_filename = f\"orbit_map{str(year)[2:]}_{month_str}.pkl\"\n",
    "                output_filename = f\"coarse_cen_map_without_decrement_latitude{str(year)[2:]}_{month_str}.pkl\"\n",
    "                \n",
    "                input_filepath = os.path.join(pickle_path, input_filename)\n",
    "                output_filepath = os.path.join(pickle_path, output_filename)\n",
    "                \n",
    "                # 1. Load dense ORI data\n",
    "                print(f\"  Loading: {input_filename}\")\n",
    "                with open(input_filepath, 'rb') as pickle_file:\n",
    "                    loaded_map = pickle.load(pickle_file)\n",
    "                \n",
    "                # 2. Process data using the specified methods from your second block\n",
    "                print(\"  Generating center points (without calibration)...\")\n",
    "                center_points = instance.make_center_points_wo_calibration(step_lat=step_lat, step_lon=step_lon)\n",
    "                \n",
    "                print(\"  Coarsening data by center...\")\n",
    "                coarse_cen_map = instance.coarse_by_center(loaded_map, center_points)\n",
    "\n",
    "                # 3. Save coarse data\n",
    "                os.makedirs(pickle_path, exist_ok=True)\n",
    "                print(f\"  Saving: {output_filename}\")\n",
    "                with open(output_filepath, 'wb') as pickle_file:\n",
    "                    pickle.dump(coarse_cen_map, pickle_file)\n",
    "                \n",
    "                print(f\"  Successfully processed and saved data for {year}-{month_str}.\")\n",
    "\n",
    "            except FileNotFoundError:\n",
    "                print(f\"  Warning: Input file not found, skipping {year}-{month_str}. Path: {input_filepath}\")\n",
    "            except Exception as e:\n",
    "                print(f\"  An error occurred while processing {year}-{month_str}: {e}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # =================================================================\n",
    "    # CONFIGURATION - Adjust all settings here\n",
    "    # =================================================================\n",
    "    \n",
    "    # Assume 'config' object with 'mac_data_load_path' is defined.\n",
    "    # If not, replace config.mac_data_load_path with the actual string path.\n",
    "    BASE_PATH = config.mac_data_load_path \n",
    "    \n",
    "    # Base CSV file needed to initialize the dmbh instance\n",
    "    BASE_CSV_PATH = \"/Users/joonwonlee/Documents/GEMS_DATA/data_2024/data_24_07_0131_N-57_E118135.csv\"\n",
    "    \n",
    "    YEARS_TO_PROCESS = [2024]\n",
    "    MONTHS_TO_PROCESS = [7] # Example: Process July\n",
    "    \n",
    "    LAT_LON_BOUNDS = (-5, 7, 118, 135)\n",
    "    STEP_SIZES = (0.044, 0.063)\n",
    "    \n",
    "    # =================================================================\n",
    "    # EXECUTION - No changes needed below this line\n",
    "    # =================================================================\n",
    "    process_and_save_coarse_data(\n",
    "        base_path=BASE_PATH,\n",
    "        years=YEARS_TO_PROCESS,\n",
    "        months=MONTHS_TO_PROCESS,\n",
    "        lat_lon_bounds=LAT_LON_BOUNDS,\n",
    "        step_sizes=STEP_SIZES,\n",
    "        base_csv_path=BASE_CSV_PATH\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# how to load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load data from: /Users/joonwonlee/Documents/GEMS_DATA/pickle_2024/coarse_cen_map_without_decrement_latitude24_07.pkl\n",
      "\n",
      "Data loaded successfully! ✅\n",
      "Type of loaded data: <class 'dict'>\n",
      "Number of entries (hours) in the map: 248\n",
      "Example keys: ['y24m07day01_hm00:53', 'y24m07day01_hm01:53', 'y24m07day01_hm02:53', 'y24m07day01_hm03:53', 'y24m07day01_hm04:49']\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "# Assume your 'config' object is available\n",
    "# import config\n",
    "\n",
    "# --- 1. Configuration ---\n",
    "# Specify the year and month you want to load\n",
    "YEAR_TO_LOAD = 2024\n",
    "MONTH_TO_LOAD = 7\n",
    "\n",
    "# Use the same base path as your saving script\n",
    "BASE_PATH = config.mac_data_load_path\n",
    "\n",
    "# --- 2. Construct the File Path ---\n",
    "# This must exactly match the naming convention from your saving script\n",
    "month_str = f\"{MONTH_TO_LOAD:02d}\"\n",
    "pickle_path = os.path.join(BASE_PATH, f'pickle_{YEAR_TO_LOAD}')\n",
    "filename = f\"coarse_cen_map_without_decrement_latitude{str(YEAR_TO_LOAD)[2:]}_{month_str}.pkl\"\n",
    "filepath_to_load = os.path.join(pickle_path, filename)\n",
    "\n",
    "print(f\"Attempting to load data from: {filepath_to_load}\")\n",
    "\n",
    "# --- 3. Load the Data ---\n",
    "try:\n",
    "    with open(filepath_to_load, 'rb') as pickle_file:\n",
    "        # Use pickle.load() to read the data from the file\n",
    "        loaded_coarse_map = pickle.load(pickle_file)\n",
    "    \n",
    "    print(\"\\nData loaded successfully! ✅\")\n",
    "    \n",
    "    # --- 4. Verify the Loaded Data ---\n",
    "    # The loaded data is a dictionary. Let's inspect it.\n",
    "    print(f\"Type of loaded data: {type(loaded_coarse_map)}\")\n",
    "    if isinstance(loaded_coarse_map, dict):\n",
    "        print(f\"Number of entries (hours) in the map: {len(loaded_coarse_map)}\")\n",
    "        # Print the first 5 keys to see what they look like\n",
    "        first_five_keys = list(loaded_coarse_map.keys())[:5]\n",
    "        print(f\"Example keys: {first_five_keys}\")\n",
    "        \n",
    "        # You can now access the data for a specific hour, for example:\n",
    "        # first_hour_data = loaded_coarse_map[first_five_keys[0]]\n",
    "        # print(f\"\\nData for first hour is a tensor of shape: {first_hour_data.shape}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"\\nError: File not found. Please check if the file exists at the specified path.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn error occurred: {e}\")\n",
    "\n",
    "\n",
    "print(loaded_coarse_map['y24m07day01_hm00:53']['Longitude'].nunique())\n",
    "print(loaded_coarse_map['y24m07day01_hm00:53']['Latitude'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GEMS_TCO\n",
    "load_data_instance = GEMS_TCO.load_data('')\n",
    "\n",
    "df_day_aggregated_list = []\n",
    "df_day_map_list = []\n",
    "for i in range(31):\n",
    "    cur_map, cur_df =load_data_instance.load_working_data_byday_wo_mm(loaded_coarse_map,[i*8, (i+1)*8])\n",
    "    df_day_aggregated_list.append( cur_df )\n",
    "    df_day_map_list.append( cur_map )"
   ]
=======
>>>>>>> 98fc71c474ddced6792e89e9ab27c07529da5b48
=======
>>>>>>> 0a418ac421c02a3cd32b6e4c97b2bdc92cdb79b7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "faiss_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
