{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "284d6bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Pickle: /Users/joonwonlee/Documents/GEMS_DATA/pickle_2024/orbit_map24_07.pkl\n",
      "--- Data Head Check ---\n",
      "   Latitude  Longitude                 Time  ColumnAmountO3  \\\n",
      "0  6.988798  134.98330  2024-07-01 00:53:00       263.67792   \n",
      "1  6.988811  134.92009  2024-07-01 00:53:00       269.09198   \n",
      "2  6.988795  134.85590  2024-07-01 00:53:00       270.52588   \n",
      "3  6.988876  134.79294  2024-07-01 00:53:00       271.30637   \n",
      "4  6.988755  134.72989  2024-07-01 00:53:00       271.05127   \n",
      "\n",
      "   FinalAlgorithmFlags  Hours_elapsed             Orbit  \n",
      "0                  2.0  477720.883333  2024-07-01 00:53  \n",
      "1                  2.0  477720.883333  2024-07-01 00:53  \n",
      "2                  2.0  477720.883333  2024-07-01 00:53  \n",
      "3                  2.0  477720.883333  2024-07-01 00:53  \n",
      "4                  2.0  477720.883333  2024-07-01 00:53  \n",
      "Loading Base CSV: /Users/joonwonlee/Documents/GEMS_DATA/data_2024/data_24_07_0131_N-57_E118135.csv\n",
      "Successfully processed and saved data for year 24 month 07.\n",
      "\n",
      "--- Starting Data Coarsening Process ---\n",
      "Loading base dataframe from: /Users/joonwonlee/Documents/GEMS_DATA/data_2024/data_24_07_0131_N05_E123133.csv\n",
      "Processing: Year 2024, Month 07\n",
      "  Loading: orbit_map24_07.pkl\n",
      "  Generating center points (without calibration)...\n",
      "  Coarsening data by center...\n",
      "  Saving: coarse_cen_map_without_decrement_latitude24_07.pkl\n",
      "  Successfully processed and saved data for 2024-07.\n"
     ]
    }
   ],
   "source": [
    "# work environment: faiss_env\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "# 경로 설정\n",
    "gems_tco_path = \"/Users/joonwonlee/Documents/GEMS_TCO-1/src\"\n",
    "sys.path.append(gems_tco_path)\n",
    "\n",
    "# Warnings 무시 설정\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"xarray\")\n",
    "\n",
    "# 커스텀 모듈 로드\n",
    "from GEMS_TCO import configuration as config\n",
    "from GEMS_TCO import data_preprocess as dmbh\n",
    "\n",
    "# ==========================================\n",
    "# 1. ORI Pickle 파일 로드 확인\n",
    "# ==========================================\n",
    "mac_data_path = config.mac_data_load_path\n",
    "years = [2024]\n",
    "months = list(range(7, 8))\n",
    "year = years[0]\n",
    "month = months[0]\n",
    "month_str = f\"{month:02d}\"\n",
    "\n",
    "filename = f\"pickle_2024/orbit_map{str(year)[2:]}_{month_str}.pkl\"\n",
    "picklefile_path = Path(mac_data_path) / filename\n",
    "print(f\"Loading Pickle: {picklefile_path}\")\n",
    "\n",
    "with open(picklefile_path, 'rb') as pickle_file:\n",
    "    data_map_hour = pickle.load(pickle_file)\n",
    "\n",
    "# 데이터 확인 (Head)\n",
    "# 충돌 코드 중 N05 버전에 해당하는 데이터 확인\n",
    "print(\"--- Data Head Check ---\")\n",
    "try:\n",
    "    print(data_map_hour['y24m07day01_hm00:52'].head())\n",
    "except KeyError:\n",
    "    # 키 값이 다를 경우를 대비해 첫 번째 키 출력\n",
    "    first_key = list(data_map_hour.keys())[0]\n",
    "    print(data_map_hour[first_key].head())\n",
    "\n",
    "# ==========================================\n",
    "# 2. Coarse Map 생성 (Center Matching)\n",
    "# ==========================================\n",
    "# [설정] 요청하신 N05_E123133 버전 (위도 0~5, 경도 123~133)\n",
    "#lat_start, lat_end, lon_start, lon_end = 0, 5, 123, 133\n",
    "lat_start, lat_end, lon_start, lon_end = -5, 7, 118, 135\n",
    "step_lat, step_lon = 0.044, 0.063\n",
    "\n",
    "# Base CSV 파일 로드 (N05 버전)\n",
    "#df_path = \"/Users/joonwonlee/Documents/GEMS_DATA/data_2024/data_24_07_0131_N05_E123133.csv\"\n",
    "df_path = \"/Users/joonwonlee/Documents/GEMS_DATA/data_2024/data_24_07_0131_N-57_E118135.csv\"\n",
    "print(f\"Loading Base CSV: {df_path}\")\n",
    "df = pd.read_csv(df_path)\n",
    "\n",
    "instance = dmbh.center_matching_hour(df, lat_start, lat_end, lon_start, lon_end)\n",
    "\n",
    "for year in years:\n",
    "    for month in months:\n",
    "        try:\n",
    "            # Load Dense ORI Data\n",
    "            pickle_path = os.path.join(mac_data_path, f'pickle_{year}')\n",
    "            input_filename = f\"orbit_map{str(year)[2:]}_{month_str}.pkl\"\n",
    "            input_filepath = os.path.join(pickle_path, input_filename)\n",
    "            \n",
    "            with open(input_filepath, 'rb') as pickle_file:\n",
    "                loaded_map = pickle.load(pickle_file)\n",
    "            \n",
    "            # Coarse Data 생성\n",
    "            center_points = instance.make_center_points(step_lat=step_lat, step_lon=step_lon)\n",
    "            coarse_cen_map = instance.coarse_by_center(loaded_map, center_points)\n",
    "\n",
    "            # Save Coarse Data\n",
    "            output_filename = f\"coarse_cen_map{str(year)[2:]}_{month_str}.pkl\"\n",
    "            output_filepath = os.path.join(pickle_path, output_filename)\n",
    "            \n",
    "            with open(output_filepath, 'wb') as pickle_file:\n",
    "                pickle.dump(coarse_cen_map, pickle_file)\n",
    "            \n",
    "            print(f\"Successfully processed and saved data for year {str(year)[2:]} month {month_str}.\")\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            print(f\"Warning: File {input_filename} not found. Skipping.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {input_filename}: {e}\")\n",
    "\n",
    "# ==========================================\n",
    "# 3. Latitude 조정 없이 Coarsening (함수 버전)\n",
    "# ==========================================\n",
    "def process_and_save_coarse_data(base_path, years, months, lat_lon_bounds, step_sizes, base_csv_path):\n",
    "    \"\"\"\n",
    "    Loads orbit map data, processes it to a coarse grid without calibration,\n",
    "    and saves the result as a pickle file.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Starting Data Coarsening Process ---\")\n",
    "    \n",
    "    lat_start, lat_end, lon_start, lon_end = lat_lon_bounds\n",
    "    step_lat, step_lon = step_sizes\n",
    "    \n",
    "    try:\n",
    "        print(f\"Loading base dataframe from: {base_csv_path}\")\n",
    "        df = pd.read_csv(base_csv_path)\n",
    "        instance = dmbh.center_matching_hour(df, lat_start, lat_end, lon_start, lon_end)\n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing: {e}\")\n",
    "        return\n",
    "\n",
    "    for year in years:\n",
    "        for month in months:\n",
    "            month_str = f\"{month:02d}\"\n",
    "            print(f\"Processing: Year {year}, Month {month_str}\")\n",
    "            \n",
    "            try:\n",
    "                pickle_path = os.path.join(base_path, f'pickle_{year}')\n",
    "                input_filename = f\"orbit_map{str(year)[2:]}_{month_str}.pkl\"\n",
    "                output_filename = f\"coarse_cen_map_without_decrement_latitude{str(year)[2:]}_{month_str}.pkl\"\n",
    "                \n",
    "                input_filepath = os.path.join(pickle_path, input_filename)\n",
    "                output_filepath = os.path.join(pickle_path, output_filename)\n",
    "                \n",
    "                print(f\"  Loading: {input_filename}\")\n",
    "                with open(input_filepath, 'rb') as pickle_file:\n",
    "                    loaded_map = pickle.load(pickle_file)\n",
    "                \n",
    "                print(\"  Generating center points (without calibration)...\")\n",
    "                center_points = instance.make_center_points_wo_calibration(step_lat=step_lat, step_lon=step_lon)\n",
    "                \n",
    "                print(\"  Coarsening data by center...\")\n",
    "                coarse_cen_map = instance.coarse_by_center(loaded_map, center_points)\n",
    "\n",
    "                os.makedirs(pickle_path, exist_ok=True)\n",
    "                print(f\"  Saving: {output_filename}\")\n",
    "                with open(output_filepath, 'wb') as pickle_file:\n",
    "                    pickle.dump(coarse_cen_map, pickle_file)\n",
    "                \n",
    "                print(f\"  Successfully processed and saved data for {year}-{month_str}.\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"  An error occurred: {e}\")\n",
    "\n",
    "# 실행부\n",
    "if __name__ == '__main__':\n",
    "    BASE_PATH = config.mac_data_load_path \n",
    "    \n",
    "    # [수정됨] 사용자가 요청한 N05_E123133 파일 경로\n",
    "    BASE_CSV_PATH = \"/Users/joonwonlee/Documents/GEMS_DATA/data_2024/data_24_07_0131_N05_E123133.csv\"\n",
    "    \n",
    "    YEARS_TO_PROCESS = [2024]\n",
    "    MONTHS_TO_PROCESS = [7]\n",
    "    \n",
    "    # [수정됨] 사용자가 요청한 좌표 범위 (0~5, 123~133)\n",
    "    #LAT_LON_BOUNDS = (0, 5, 123, 133)\n",
    "    LAT_LON_BOUNDS = (-5, 7, 118, 135)\n",
    "    STEP_SIZES = (0.044, 0.063)\n",
    "    \n",
    "    process_and_save_coarse_data(\n",
    "        base_path=BASE_PATH,\n",
    "        years=YEARS_TO_PROCESS,\n",
    "        months=MONTHS_TO_PROCESS,\n",
    "        lat_lon_bounds=LAT_LON_BOUNDS,\n",
    "        step_sizes=STEP_SIZES,\n",
    "        base_csv_path=BASE_CSV_PATH\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c68f599e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subsetting data to lat: [0, 5], lon: [123, 133.0]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# Add your custom path\n",
    "gems_tco_path = \"/Users/joonwonlee/Documents/GEMS_TCO-1/src\"\n",
    "sys.path.append(gems_tco_path)\n",
    "from GEMS_TCO import kernels_reparam_space_time_gpu as kernels_reparam_space_time\n",
    "from GEMS_TCO import orderings as _orderings \n",
    "from GEMS_TCO import alg_optimization, alg_opt_Encoder\n",
    "\n",
    "from typing import Optional, List, Tuple\n",
    "from pathlib import Path\n",
    "import typer\n",
    "import json\n",
    "from json import JSONEncoder\n",
    "from GEMS_TCO import configuration as config\n",
    "from GEMS_TCO.data_loader import load_data2, exact_location_filter\n",
    "from GEMS_TCO import debiased_whittle\n",
    "from torch.nn import Parameter\n",
    "from GEMS_TCO.data_loader import load_data2, exact_location_filter\n",
    "\n",
    "space: List[str] = ['1', '1']\n",
    "lat_lon_resolution = [int(s) for s in space]\n",
    "mm_cond_number: int = 8\n",
    "years = ['2024']\n",
    "month_range = [7] \n",
    "\n",
    "output_path = input_path = Path(config.mac_estimates_day_path)\n",
    "data_load_instance = load_data2(config.mac_data_load_path)\n",
    "\n",
    "#lat_range_input = [1, 3]\n",
    "#lon_range_input = [125.0, 129.0]\n",
    "\n",
    "lat_range_input=[0,5]      \n",
    "lon_range_input=[123, 133.0] \n",
    "\n",
    "df_map, ord_mm, nns_map = data_load_instance.load_maxmin_ordered_data_bymonthyear(\n",
    "lat_lon_resolution=lat_lon_resolution, \n",
    "mm_cond_number=mm_cond_number,\n",
    "years_=years, \n",
    "months_=month_range,\n",
    "\n",
    "lat_range=lat_range_input,   \n",
    "lon_range=lon_range_input\n",
    "\n",
    ")\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8096b73e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([145008, 4])\n"
     ]
    }
   ],
   "source": [
    "daily_aggregated_tensors_dw = [] \n",
    "daily_hourly_maps_dw = []      \n",
    "\n",
    "daily_aggregated_tensors_vecc = [] \n",
    "daily_hourly_maps_vecc = []   \n",
    "\n",
    "\n",
    "for day_index in range(31):\n",
    "    hour_start_index = day_index * 8\n",
    "    \n",
    "    hour_end_index = (day_index + 1) * 8\n",
    "    #hour_end_index = day_index*8 + 1\n",
    "    hour_indices = [hour_start_index, hour_end_index]\n",
    "\n",
    "    day_hourly_map, day_aggregated_tensor = data_load_instance.load_working_data(\n",
    "    df_map, \n",
    "    hour_indices, \n",
    "    ord_mm= None,  # or just omit it\n",
    "    dtype=torch.float64, # or just omit it \n",
    "    keep_ori=True  #keep_exact_loc\n",
    "    )\n",
    "\n",
    "    daily_aggregated_tensors_dw.append( day_aggregated_tensor )\n",
    "    daily_hourly_maps_dw.append( day_hourly_map )\n",
    "\n",
    "    day_hourly_map, day_aggregated_tensor = data_load_instance.load_working_data(\n",
    "    df_map, \n",
    "    hour_indices, \n",
    "    ord_mm= ord_mm,  # or just omit it\n",
    "    dtype=torch.float64, # or just omit it \n",
    "    keep_ori=False  #keep_exact_loc\n",
    "    )\n",
    "\n",
    "    daily_aggregated_tensors_vecc.append( day_aggregated_tensor )\n",
    "    daily_hourly_maps_vecc.append( day_hourly_map )\n",
    "print(daily_aggregated_tensors_vecc[0].shape)\n",
    "#print(daily_hourly_maps[0])\n",
    "nn = daily_aggregated_tensors_vecc[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e6c0272c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.9913e+00, 1.3170e+02, 2.6778e+02, 7.5000e+01],\n",
       "        [4.9913e+00, 1.3170e+02, 2.6778e+02, 7.5000e+01],\n",
       "        [4.9913e+00, 1.3170e+02, 2.6778e+02, 7.5000e+01],\n",
       "        ...,\n",
       "        [9.8304e-03, 1.2316e+02, 2.6370e+02, 7.5000e+01],\n",
       "        [9.9527e-03, 1.2310e+02, 2.6461e+02, 7.5000e+01],\n",
       "        [9.9826e-03, 1.2304e+02, 2.6473e+02, 7.5000e+01]], dtype=torch.float64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_hourly_maps_dw[2]['2024_07_y24m07day03_hm06:49']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "faiss_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
