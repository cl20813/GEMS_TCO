{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joonw\\anaconda3\\envs\\jl2815\\Lib\\site-packages\\GEMS_TCO\\kernels.py:64: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  '''\n"
     ]
    }
   ],
   "source": [
    "# work environment: jl2815\n",
    "# Standard libraries\n",
    "import sys\n",
    "import logging\n",
    "import argparse # Argument parsing\n",
    "import math\n",
    "from collections import defaultdict\n",
    "import concurrent\n",
    "from concurrent.futures import ThreadPoolExecutor  # Importing specific executor for clarity\n",
    "import time\n",
    "\n",
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Nearest neighbor search\n",
    "import sklearn\n",
    "from sklearn.neighbors import BallTree\n",
    "\n",
    "# Special functions and optimizations\n",
    "from scipy.special import gamma, kv  # Bessel function and gamma function\n",
    "from scipy.stats import multivariate_normal  # Simulation\n",
    "from scipy.optimize import minimize\n",
    "from scipy.spatial.distance import cdist  # For space and time distance\n",
    "from scipy.spatial import distance  # Find closest spatial point\n",
    "from scipy.optimize import differential_evolution\n",
    "\n",
    "# Plotting and visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Type hints\n",
    "from typing import Callable, Union, Tuple\n",
    "\n",
    "# Add your custom path\n",
    "sys.path.append(\"/cache/home/jl2815/tco\")\n",
    "\n",
    "# Custom imports\n",
    "from GEMS_TCO import orbitmap \n",
    "from GEMS_TCO import kernels \n",
    "from GEMS_TCO import evaluate\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated data shape: (1600, 5)\n"
     ]
    }
   ],
   "source": [
    "lat_lon_resolution = [10,10]\n",
    "mm_cond_number = 10\n",
    "params= [60, 5.25, 5.25, 0.2, 0.5, 5]\n",
    "key_for_dict= 8\n",
    "\n",
    "\n",
    "# Load the one dictionary to set spaital coordinates\n",
    "filepath = \"C:/Users/joonw/TCO/GEMS_data/data_2023/sparse_cen_map23_01.pkl\"\n",
    "\n",
    "with open(filepath, 'rb') as pickle_file:\n",
    "    coarse_dict_24_1 = pickle.load(pickle_file)\n",
    "\n",
    "sample_df = coarse_dict_24_1['y23m01day01_hm02:12']\n",
    "\n",
    "sample_key = coarse_dict_24_1.get('y23m01day01_hm02:12')\n",
    "if sample_key is None:\n",
    "    print(\"Key 'y23m01day01_hm02:12' not found in the dictionary.\")\n",
    "\n",
    "# { (20,20):(5,1), (5,5):(20,40) }\n",
    "rho_lat = lat_lon_resolution[0]          \n",
    "rho_lon = lat_lon_resolution[1]\n",
    "lat_n = sample_df['Latitude'].unique()[::rho_lat]\n",
    "lon_n = sample_df['Longitude'].unique()[::rho_lon]\n",
    "\n",
    "lat_number = len(lat_n)\n",
    "lon_number = len(lon_n)\n",
    "\n",
    "# Set spatial coordinates for each dataset\n",
    "coarse_dicts = {}\n",
    "\n",
    "years = ['2024']\n",
    "for year in years:\n",
    "    for month in range(7, 8):  # Iterate over all months\n",
    "        filepath = f\"C:/Users/joonw/TCO/GEMS_data/data_{year}/sparse_cen_map{year[2:]}_{month:02d}.pkl\"\n",
    "        with open(filepath, 'rb') as pickle_file:\n",
    "            loaded_map = pickle.load(pickle_file)\n",
    "            for key in loaded_map:\n",
    "                tmp_df = loaded_map[key]\n",
    "                coarse_filter = (tmp_df['Latitude'].isin(lat_n)) & (tmp_df['Longitude'].isin(lon_n))\n",
    "                coarse_dicts[f\"{year}_{month:02d}_{key}\"] = tmp_df[coarse_filter].reset_index(drop=True)\n",
    "\n",
    "\n",
    "key_idx = sorted(coarse_dicts)\n",
    "if not key_idx:\n",
    "    raise ValueError(\"coarse_dicts is empty\")\n",
    "\n",
    "# extract first hour data because all data shares the same spatial grid\n",
    "data_for_coord = coarse_dicts[key_idx[0]]\n",
    "x1 = data_for_coord['Longitude'].values\n",
    "y1 = data_for_coord['Latitude'].values \n",
    "coords1 = np.stack((x1, y1), axis=-1)\n",
    "\n",
    "instance = orbitmap.MakeOrbitdata(data_for_coord, lat_s=5, lat_e=10, lon_s=110, lon_e=120)\n",
    "s_dist = cdist(coords1, coords1, 'euclidean')\n",
    "ord_mm, _ = instance.maxmin_naive(s_dist, 0)\n",
    "\n",
    "data_for_coord = data_for_coord.iloc[ord_mm].reset_index(drop=True)\n",
    "coords1_reordered = np.stack((data_for_coord['Longitude'].values, data_for_coord['Latitude'].values), axis=-1)\n",
    "nns_map = instance.find_nns_naive(locs=coords1_reordered, dist_fun='euclidean', max_nn=mm_cond_number)\n",
    "\n",
    "\n",
    "key_for_dict= 8\n",
    "analysis_data_map = {}\n",
    "for i in range(key_for_dict):\n",
    "    tmp = coarse_dicts[key_idx[i]]\n",
    "    tmp['Hours_elapsed'] = np.round(tmp['Hours_elapsed'])\n",
    "    # tmp = tmp.iloc[ord_mm].reset_index(drop=True)  \n",
    "    tmp = tmp.iloc[ord_mm, :4].to_numpy()\n",
    "    analysis_data_map[key_idx[i]] = tmp\n",
    "\n",
    "aggregated_data = pd.DataFrame()\n",
    "for i in range((key_for_dict)):\n",
    "    tmp = coarse_dicts[key_idx[i]]\n",
    "    tmp = tmp.iloc[ord_mm].reset_index(drop=True)  \n",
    "    tmp = tmp.iloc[ord_mm].reset_index(drop=True)  \n",
    "    aggregated_data = pd.concat((aggregated_data, tmp), axis=0)\n",
    "          \n",
    "aggregated_np = aggregated_data.iloc[:,:4].to_numpy()\n",
    "\n",
    "print(f'Aggregated data shape: {aggregated_data.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = aggregated_data.sort_values(by=['Longitude', 'Latitude']).reset_index(drop=True)\n",
    "\n",
    "lon_key = sorted(df['Longitude'].unique())\n",
    "instance.lon_key = lon_key\n",
    "for i in range(len(lon_key)):\n",
    "    tmp = df[df['Longitude'] == lon_key[i]]\n",
    "    tmp = tmp.sort_values(by=['Latitude']).reset_index(drop=True)\n",
    "    df.loc[df['Longitude'] == lon_key[i], 'Latitude'] = tmp['Latitude'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4312.992225581795\n",
      "4355.527033565967\n"
     ]
    }
   ],
   "source": [
    "instance = kernels.likelihood_function(smooth=0.5, input_map=analysis_data_map, nns_map=nns_map, mm_cond_number=mm_cond_number)\n",
    "\n",
    "out1 =  instance.full_likelihood(params, aggregated_np, aggregated_np[:,2], instance.matern_cov_yx)\n",
    "print(out1)\n",
    "\n",
    "out1 = instance.vecchia_like_local(params, instance.matern_cov_yx)\n",
    "print(out1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.5250000e+00, 1.1952500e+02, 2.9094240e+02, 4.7772800e+05],\n",
       "       [9.5250000e+00, 1.1302500e+02, 2.6297015e+02, 4.7772800e+05],\n",
       "       [9.5250000e+00, 1.1752500e+02, 2.6404147e+02, 4.7772800e+05],\n",
       "       [9.5250000e+00, 1.1152500e+02, 2.7526453e+02, 4.7772800e+05],\n",
       "       [9.5250000e+00, 1.1452500e+02, 2.6751343e+02, 4.7772800e+05],\n",
       "       [9.5250000e+00, 1.1002500e+02, 2.7199080e+02, 4.7772800e+05],\n",
       "       [9.5250000e+00, 1.1602500e+02, 2.6232883e+02, 4.7772800e+05],\n",
       "       [9.5250000e+00, 1.1852500e+02, 2.6696918e+02, 4.7772800e+05],\n",
       "       [9.5250000e+00, 1.1052500e+02, 2.6459607e+02, 4.7772800e+05],\n",
       "       [9.5250000e+00, 1.1102500e+02, 2.7108868e+02, 4.7772800e+05],\n",
       "       [9.5250000e+00, 1.1202500e+02, 2.7615840e+02, 4.7772800e+05],\n",
       "       [9.5250000e+00, 1.1252500e+02, 2.7298100e+02, 4.7772800e+05],\n",
       "       [9.5250000e+00, 1.1352500e+02, 2.6819257e+02, 4.7772800e+05],\n",
       "       [9.5250000e+00, 1.1402500e+02, 2.7172556e+02, 4.7772800e+05],\n",
       "       [9.5250000e+00, 1.1502500e+02, 2.7085590e+02, 4.7772800e+05],\n",
       "       [9.5250000e+00, 1.1552500e+02, 2.6973755e+02, 4.7772800e+05],\n",
       "       [9.5250000e+00, 1.1652500e+02, 2.6503250e+02, 4.7772800e+05],\n",
       "       [9.5250000e+00, 1.1702500e+02, 2.6356796e+02, 4.7772800e+05],\n",
       "       [9.5250000e+00, 1.1802500e+02, 2.6490814e+02, 4.7772800e+05],\n",
       "       [9.5250000e+00, 1.1902500e+02, 2.6713360e+02, 4.7772800e+05]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_col = current_np[current_np[:, 0] == instance.lon_key[col_idx]]\n",
    "current_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(5.025),\n",
       " np.float64(5.524999999999999),\n",
       " np.float64(6.024999999999997),\n",
       " np.float64(6.524999999999995),\n",
       " np.float64(7.024999999999993),\n",
       " np.float64(7.5249999999999915),\n",
       " np.float64(8.02499999999999),\n",
       " np.float64(8.524999999999988),\n",
       " np.float64(9.024999999999986),\n",
       " np.float64(9.524999999999984)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance.lon_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(6450.18461611847)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance.lat_key = sorted(np.unique(analysis_data_map['2024_07_y24m07day01_hm01:00'][:,1]), reverse=True)\n",
    "# instance.lat_key = sorted(np.unique(analysis_data_map['2024_07_y24m07day01_hm01:00'][:,1]))\n",
    "# observation 1: lat key is so much better than lon key\n",
    "# observation 2: lat key is better with descending order.\n",
    "number_of_timestamps = instance.number_of_timestamps\n",
    "instance.cov_map = defaultdict(list)\n",
    "\n",
    "\n",
    "neg_log_lik = 0\n",
    "for time_idx in range(number_of_timestamps):\n",
    "    current_np = instance.input_map[instance.key_list[time_idx]]\n",
    "\n",
    "    for col_idx in range(len(instance.lon_key)):\n",
    "        current_col = current_np[current_np[:, 1] == instance.lat_key[col_idx]]\n",
    "\n",
    "        if col_idx <2:\n",
    "            neg_log_lik += instance.full_likelihood(params, current_col, current_col[:,2], instance.matern_cov_yx)\n",
    "\n",
    "        elif col_idx>2:  \n",
    "            if time_idx ==0:\n",
    "\n",
    "                cov_matrix = instance.cov_map[0]['cov_matrix']\n",
    "                tmp_for_beta = instance.cov_map[0]['tmp_for_beta']\n",
    "                cov_xx_inv = instance.cov_map[0]['cov_xx_inv']\n",
    "                L_inv = instance.cov_map[0]['L_inv']\n",
    "                cov_ygivenx = instance.cov_map[0]['cov_ygivenx'] \n",
    "                cond_mean_tmp = instance.cov_map[0]['cond_mean_tmp']\n",
    "                log_det = instance.cov_map[0]['log_det']\n",
    "                locs  = instance.cov_map[0]['locs']  \n",
    "                \n",
    "                cond_col = current_np[(current_np[:, 1] == instance.lon_key[col_idx-1]) | (current_np[:, 1] == instance.lon_key[col_idx-2])]\n",
    "                \n",
    "                np_arr = np.vstack((current_col, cond_col))     \n",
    "                y_and_neighbors = np_arr[:,2]\n",
    "\n",
    "\n",
    "\n",
    "            if time_idx >=1:\n",
    "                cov_matrix = instance.cov_map[1]['cov_matrix']\n",
    "                tmp_for_beta = instance.cov_map[1]['tmp_for_beta']\n",
    "                cov_xx_inv = instance.cov_map[1]['cov_xx_inv']\n",
    "                L_inv = instance.cov_map[1]['L_inv']\n",
    "                cov_ygivenx = instance.cov_map[1]['cov_ygivenx'] \n",
    "                cond_mean_tmp = instance.cov_map[1]['cond_mean_tmp']\n",
    "                log_det = instance.cov_map[1]['log_det']\n",
    "                locs  = instance.cov_map[1]['locs']  \n",
    "\n",
    "                cond_col = current_np[(current_np[:, 1] == instance.lon_key[col_idx-1]) | (current_np[:, 1] == instance.lon_key[col_idx-2])]\n",
    "                onelag_np = instance.input_map[instance.key_list[time_idx-1]]\n",
    "                cond_col_onelag = onelag_np[(onelag_np[:, 1] == instance.lon_key[col_idx]) | (onelag_np[:, 1] == instance.lon_key[col_idx-1]) | (onelag_np[:, 1] == instance.lon_key[col_idx-2])]\n",
    "                cond_col = np.vstack((cond_col, cond_col_onelag))\n",
    "            \n",
    "                np_arr = np.vstack((current_col, cond_col))\n",
    "\n",
    "                y_and_neighbors = np_arr[:,2]\n",
    "                current_y = current_col[:,2]\n",
    "                locs = np_arr[:,:2]\n",
    "                           \n",
    "            \n",
    "            current_y = current_col[:,2]   \n",
    "            p = len(current_col)\n",
    "\n",
    "            tmp2 = np.dot( np.dot(L_inv, locs).T, np.dot(L_inv, y_and_neighbors))\n",
    "            beta = np.linalg.solve(tmp_for_beta , tmp2)\n",
    "            mu = np.dot(locs, beta)\n",
    "            mu_current = mu[:p]\n",
    "            mu_neighbors = mu[p:]\n",
    "\n",
    "            # mean and variance of y|x\n",
    "            cov_yx = cov_matrix[:p,p:]\n",
    "            cov_yy= cov_matrix[:p,:p]\n",
    "\n",
    "            cov_ygivenx = cov_yy - np.dot(cov_yx, np.dot(cov_xx_inv, cov_yx.T))\n",
    "\n",
    "            cond_mean_tmp = np.dot(cov_yx, cov_xx_inv)\n",
    "            cond_mean = mu_current + np.dot(cond_mean_tmp, (y_and_neighbors[p:]-mu_neighbors) )  # adjust for bias, mean_xz should be 0 which is not true but we can't do same for y1 so just use mean_z almost 0\n",
    "\n",
    "            alpha = current_y - cond_mean\n",
    "\n",
    "            quad_form = np.dot(alpha.T, np.linalg.solve(cov_ygivenx,alpha))\n",
    "            # print(log_det)\n",
    "            neg_log_lik += 0.5 * (1 * np.log(2 * np.pi) + log_det + quad_form)\n",
    "\n",
    "        else:\n",
    "            if time_idx > 1:\n",
    "                cov_matrix = instance.cov_map[1]['cov_matrix']\n",
    "                tmp_for_beta = instance.cov_map[1]['tmp_for_beta']\n",
    "                cov_xx_inv = instance.cov_map[1]['cov_xx_inv']\n",
    "                L_inv = instance.cov_map[1]['L_inv']\n",
    "                cov_ygivenx = instance.cov_map[1]['cov_ygivenx'] \n",
    "                cond_mean_tmp = instance.cov_map[1]['cond_mean_tmp']\n",
    "                log_det = instance.cov_map[1]['log_det']\n",
    "                locs  = instance.cov_map[1]['locs']\n",
    "         \n",
    "        \n",
    "                cond_col = current_np[(current_np[:, 1] == instance.lon_key[col_idx-1]) | (current_np[:, 1] == instance.lon_key[col_idx-2])]\n",
    "                onelag_np = instance.input_map[instance.key_list[time_idx-1]]\n",
    "                cond_col_onelag = onelag_np[(onelag_np[:, 1] == instance.lon_key[col_idx]) | (onelag_np[:, 1] == instance.lon_key[col_idx-1]) | (onelag_np[:, 1] == instance.lon_key[col_idx-2])]\n",
    "                cond_col = np.vstack((cond_col, cond_col_onelag))\n",
    "                np_arr = np.vstack((current_col, cond_col)) \n",
    "                y_and_neighbors = np_arr[:,2]\n",
    "                current_y = current_col[:,2]  \n",
    "\n",
    "                p = len(current_col)\n",
    "                # print(f' {L_inv.shape}, {locs.shape}, {y_and_neighbors.shape}')\n",
    "                \n",
    "                tmp2 = np.dot( np.dot(L_inv, locs).T, np.dot(L_inv, y_and_neighbors))\n",
    "                beta = np.linalg.solve(tmp_for_beta , tmp2)\n",
    "                mu = np.dot(locs, beta)\n",
    "                mu_current = mu[:p]\n",
    "                mu_neighbors = mu[p:]\n",
    "\n",
    "                # mean and variance of y|x\n",
    "                cov_yx = cov_matrix[:p,p:]\n",
    "                cov_yy= cov_matrix[:p,:p]\n",
    "\n",
    "                cov_ygivenx = cov_yy - np.dot(cov_yx, np.dot(cov_xx_inv, cov_yx.T))\n",
    "\n",
    "                cond_mean_tmp = np.dot(cov_yx, cov_xx_inv)\n",
    "                cond_mean = mu_current + np.dot(cond_mean_tmp, (y_and_neighbors[p:]-mu_neighbors) )  # adjust for bias, mean_xz should be 0 which is not true but we can't do same for y1 so just use mean_z almost 0\n",
    "\n",
    "                alpha = current_y - cond_mean\n",
    "\n",
    "                quad_form = np.dot(alpha.T, np.linalg.solve(cov_ygivenx,alpha))\n",
    "                # print(log_det)\n",
    "                neg_log_lik += 0.5 * (1 * np.log(2 * np.pi) + log_det + quad_form)\n",
    "\n",
    "            elif time_idx == 0:\n",
    "                \n",
    "                cond_col = current_np[(current_np[:, 1] == instance.lon_key[col_idx-1]) | (current_np[:, 1] == instance.lon_key[col_idx-2])]\n",
    "                \n",
    "            else:    \n",
    "\n",
    "\n",
    "                cond_col = current_np[(current_np[:, 1] == instance.lon_key[col_idx-1]) | (current_np[:, 1] == instance.lon_key[col_idx-2])]\n",
    "          \n",
    "                onelag_np = instance.input_map[instance.key_list[time_idx-1]]\n",
    "                cond_col_onelag = onelag_np[(onelag_np[:, 1] == instance.lon_key[col_idx]) | (onelag_np[:, 1] == instance.lon_key[col_idx-1]) | (onelag_np[:, 1] == instance.lon_key[col_idx-2])]\n",
    "                cond_col = np.vstack((cond_col, cond_col_onelag))\n",
    "            \n",
    "            np_arr = np.vstack((current_col, cond_col))\n",
    "\n",
    "            y_and_neighbors = np_arr[:,2]\n",
    "            current_y = current_col[:,2]\n",
    "            locs = np_arr[:,:2]\n",
    "\n",
    "            p = len(current_col)\n",
    "            cov_matrix = instance.matern_cov_yx(params=params, y = np_arr, x = np_arr)\n",
    "            L = np.linalg.cholesky(cov_matrix)\n",
    "            L11 = L[:p,:p]\n",
    "            L12 = np.zeros(L[:p,p:].shape)\n",
    "            L21 = L[p:,:p]\n",
    "            L22 = L[p:,p:]\n",
    "            L11_inv = np.linalg.inv(L11)\n",
    "            L22_inv = np.linalg.inv(L22)\n",
    "\n",
    "            L_inv = np.block([\n",
    "                [L11_inv, L12],\n",
    "                [- np.dot( np.dot(L22_inv,L21), L11_inv), L22_inv]\n",
    "            ])\n",
    "\n",
    "            tmp1 = np.dot(L_inv,locs)\n",
    "            tmp2 = np.dot( np.dot(L_inv, locs).T, np.dot(L_inv, y_and_neighbors))\n",
    "            tmp_for_beta= np.dot(tmp1.T,tmp1)\n",
    "            beta = np.linalg.solve(tmp_for_beta , tmp2)\n",
    "\n",
    "            mu = np.dot(locs, beta)\n",
    "            mu_current = mu[:p]\n",
    "            mu_neighbors = mu[p:]\n",
    "\n",
    "            # mean and variance of y|x\n",
    "            cov_yx = cov_matrix[:p,p:]\n",
    "            cov_yy= cov_matrix[:p,:p]\n",
    "\n",
    "            # cov_xx = np.dot(L21,L21.T) +np.dot(L22,L22.T) \n",
    "            cov_xx = cov_matrix[p:,p:]\n",
    "            cov_xx_inv = np.linalg.inv(cov_xx)\n",
    "        \n",
    "            cov_ygivenx = cov_yy - np.dot(cov_yx, np.dot(cov_xx_inv, cov_yx.T))\n",
    "\n",
    "            cond_mean_tmp = np.dot(cov_yx, cov_xx_inv)\n",
    "            cond_mean = mu_current + np.dot(cond_mean_tmp, (y_and_neighbors[p:]-mu_neighbors) )  # adjust for bias, mean_xz should be 0 which is not true but we can't do same for y1 so just use mean_z almost 0\n",
    "\n",
    "            alpha = current_y - cond_mean\n",
    "\n",
    "            quad_form = np.dot(alpha.T, np.linalg.solve(cov_ygivenx,alpha))\n",
    "\n",
    "            sign, log_det = np.linalg.slogdet(cov_ygivenx)\n",
    "            # print(log_det)\n",
    "            neg_log_lik += 0.5 * (1 * np.log(2 * np.pi) + log_det + quad_form)\n",
    "\n",
    "            if time_idx == 0:\n",
    "                instance.cov_map[0] = {\n",
    "                    'tmp_for_beta': tmp_for_beta,\n",
    "                    'cov_xx_inv': cov_xx_inv,\n",
    "                    'cov_matrix': cov_matrix,\n",
    "                    'L_inv':L_inv,\n",
    "                    'cov_ygivenx':cov_ygivenx,\n",
    "                    'cond_mean_tmp': cond_mean_tmp,\n",
    "                    'log_det': log_det,\n",
    "                    'locs':locs\n",
    "                }   \n",
    "            elif time_idx ==1:   \n",
    "                instance.cov_map[1] = {\n",
    "                    'tmp_for_beta': tmp_for_beta,\n",
    "                    'cov_xx_inv': cov_xx_inv,\n",
    "                    'cov_matrix': cov_matrix,\n",
    "                    'L_inv':L_inv,\n",
    "                    'cov_ygivenx':cov_ygivenx,\n",
    "                    'cond_mean_tmp': cond_mean_tmp,\n",
    "                    'log_det': log_det,\n",
    "                    'locs':locs\n",
    "                }\n",
    "\n",
    "            \n",
    "neg_log_lik        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jl2815",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
