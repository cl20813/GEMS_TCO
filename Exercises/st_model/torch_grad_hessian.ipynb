{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "# gems_tco_path = \"/Users/joonwonlee/Documents/GEMS_TCO-1/src\"\n",
    "# sys.path.append(gems_tco_path)\n",
    "\n",
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle \n",
    "\n",
    "import GEMS_TCO\n",
    "from GEMS_TCO import kernels \n",
    "from GEMS_TCO import orderings as _orderings\n",
    "from GEMS_TCO import load_data\n",
    "\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "from torch.func import grad, hessian, jacfwd, jacrev\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import copy                    # clone tensor\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "from json import JSONEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "Two options: 1. torch.autograd 2. torch.func (recommended for both gradients and hessians)\n",
    "\n",
    "Observations:\n",
    "- In order to track gradients, ```sqrt()``` in distance function has to be removed and put ```sqrt(distance function output)``` in covariance function.   \n",
    "\n",
    "- If dtypes don't match, both autograd and torch.func cannot track hessians, so consider ```.to(torch.float64)``` so ``` aggregated_data[:,:4].torch.float64()```   \n",
    "for the consistency.\n",
    "Actually, it turns out that if I use ```float32```, then autograd derivative can be different from analytical derivative by ```0.001 ~ 0.004```. \n",
    "\n",
    "the difference is on the order of one-thousandth \n",
    "\n",
    "- For hessians, torch.func is recommended. ``` torch.autograd.functional.hessian(compute_loss, params)``` this doesn't work.   \n",
    "\n",
    "- It seems there is nontrivial difference between float32 and float64 settings. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD estimates for July 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_lon_resolution = [10,10]\n",
    "day = 1\n",
    "mm_cond_number = 10\n",
    "\n",
    "years = ['2024']\n",
    "month_range =[7,8]\n",
    "idx_for_datamap= [ 8*(day-1),8*day]\n",
    "\n",
    "input_path = Path(\"/Users/joonwonlee/Documents/GEMS_DATA/\")  # mac\n",
    "instance = load_data(input_path)\n",
    "month_map, ord_mm, nns_map= instance.load_mm20k_data_bymonthyear( lat_lon_resolution= lat_lon_resolution, mm_cond_number=mm_cond_number,years_=years, months_=month_range)\n",
    "analysis_data_map, aggregated_data = instance.load_working_data_byday( month_map, ord_mm, nns_map, idx_for_datamap=idx_for_datamap)\n",
    "\n",
    "\n",
    "'''  \n",
    "input_path = \"/Users/joonwonlee/Documents/GEMS_TCO-1/Exercises/st_model/estimates\"\n",
    "output_filename = 'vecchia_inter_estimates_1250_july24.csv'\n",
    "output_csv_path = os.path.join(input_path, output_filename)\n",
    "\n",
    "df = pd.read_csv(output_csv_path)\n",
    "'''\n",
    "input_filename = \"full_v15_1250.0.csv\"\n",
    "input_path = \"/Users/joonwonlee/Documents/GEMS_TCO-1/Exercises/st_model/estimates\"\n",
    "input_filepath = os.path.join(input_path, input_filename)\n",
    "df_full_v15 = pd.read_csv(input_filepath)\n",
    "df_full_v15 = df_full_v15.iloc[:,5:13]\n",
    "\n",
    "df = df_full_v15\n",
    "\n",
    "input_filename = \"full_day_v05_1250.0.csv\"\n",
    "input_path = \"/Users/joonwonlee/Documents/GEMS_TCO-1/Exercises/st_model/estimates\"\n",
    "input_filepath = os.path.join(input_path, input_filename)\n",
    "df_full_v05 = pd.read_csv(input_filepath)\n",
    "df_full_v05 = df_full_v05.iloc[:,5:13]\n",
    "\n",
    "df2 = df_full_v05\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradients and hessians sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input parameters: tensor([ 2.7345e+01,  4.9205e-01,  5.3007e-01,  4.8692e-03, -1.1557e-01,\n",
      "         4.2872e-01,  4.4720e+00], dtype=torch.float64, requires_grad=True)\n",
      " the gradient: (tensor([  30.2369, -645.6859, -658.9328,   21.8283, -144.2488,  729.0353,\n",
      "          86.5523], dtype=torch.float64),)\n",
      " the gradient: tensor([  30.2369, -645.6859, -658.9328,   21.8283, -144.2488,  729.0353,\n",
      "          86.5523], dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "nheads =10\n",
    "instance = kernels.vecchia_experiment(0.5, analysis_data_map, aggregated_data,nns_map,mm_cond_number, nheads)\n",
    "\n",
    "# Convert parameters to a tensor with requires_grad=True\n",
    "params = torch.tensor(df.iloc[0, :-1].values, dtype=torch.float64, requires_grad=True)\n",
    "print(f'input parameters: {params}')\n",
    "\n",
    "# Define the function to compute the loss\n",
    "def compute_loss(params):\n",
    "    return instance.full_likelihood(params, aggregated_data[:, :4].to(torch.float64), aggregated_data[:, 2].to(torch.float64), instance.matern_cov_anisotropy_v05)\n",
    "    # return instance.vecchia_interpolation_1to6(params, instance.matern_cov_ani, 35)\n",
    "    \n",
    "# Compute the first derivative using torch.func.grad\n",
    "grad_f = torch.autograd.grad(compute_loss(params), params)\n",
    "print(f' the gradient: {grad_f}')\n",
    "\n",
    "grad_function = torch.func.grad(compute_loss)\n",
    "gradient = grad_function(params)\n",
    "print(f' the gradient: {gradient}')\n",
    "\n",
    "#[  0.9324, -43.9642, -35.9082,  59.9937, -17.1091, -76.0932,  -0.6668]\n",
    "torch.autograd.gradcheck(compute_loss, params, atol=1e-9, rtol=1e-6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gradient(vecc) * hessian (full) * gradient (vecc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cond_number of hessian 81546.67407274901\n",
      "tensor([[ 5.2539e-01, -1.6332e+00, -2.2620e+00, -5.2439e-02, -3.4863e-01,\n",
      "          2.9656e+01,  2.6553e+00],\n",
      "        [-1.6332e+00,  6.8766e+01, -1.4994e+01,  1.6771e+01,  3.4375e+00,\n",
      "          2.0829e+02, -5.8696e+00],\n",
      "        [-2.2620e+00, -1.4994e+01,  5.8137e+01, -4.7796e-01, -3.1544e+01,\n",
      "          1.4603e+02, -1.1885e+01],\n",
      "        [-5.2439e-02,  1.6771e+01, -4.7796e-01,  1.1683e+03, -4.9980e+02,\n",
      "          1.3625e+02, -6.7108e-01],\n",
      "        [-3.4863e-01,  3.4375e+00, -3.1544e+01, -4.9980e+02,  2.3982e+03,\n",
      "         -6.6300e+02, -3.5057e+01],\n",
      "        [ 2.9656e+01,  2.0829e+02,  1.4603e+02,  1.3625e+02, -6.6300e+02,\n",
      "          1.1916e+04,  2.8444e+02],\n",
      "        [ 2.6553e+00, -5.8696e+00, -1.1885e+01, -6.7108e-01, -3.5057e+01,\n",
      "          2.8444e+02,  2.1738e+01]], dtype=torch.float64,\n",
      "       grad_fn=<ViewBackward0>) tensor(81546.6741, dtype=torch.float64, grad_fn=<SqueezeBackward1>)\n",
      "Eigenvalues: tensor([1.1977e+04+0.j, 2.5281e+03+0.j, 9.9058e+02+0.j, 1.4687e-01+0.j, 5.2312e+00+0.j,\n",
      "        5.2351e+01+0.j, 7.8207e+01+0.j], dtype=torch.complex128,\n",
      "       grad_fn=<LinalgEigBackward0>)\n",
      "Eigenvectors: tensor([[ 2.4711e-03+0.j, -7.1296e-04+0.j,  5.7063e-05+0.j,  9.9621e-01+0.j,\n",
      "          4.3869e-02+0.j,  7.5085e-02+0.j,  7.0064e-05+0.j],\n",
      "        [ 1.7411e-02+0.j, -5.1084e-03+0.j,  2.0600e-02+0.j,  3.0851e-02+0.j,\n",
      "          2.6632e-01+0.j, -5.6483e-01+0.j, -7.7996e-01+0.j],\n",
      "        [ 1.2353e-02+0.j,  7.7104e-03+0.j, -1.0731e-02+0.j,  3.5688e-02+0.j,\n",
      "          3.6619e-01+0.j, -6.8836e-01+0.j,  6.2488e-01+0.j],\n",
      "        [ 1.5826e-02+0.j,  3.3771e-01+0.j,  9.4089e-01+0.j, -7.0441e-04+0.j,\n",
      "          4.7061e-03+0.j,  8.5500e-03+0.j,  1.8379e-02+0.j],\n",
      "        [-6.9950e-02+0.j, -9.3848e-01+0.j,  3.3766e-01+0.j, -1.1334e-03+0.j,\n",
      "          1.0160e-02+0.j,  2.2213e-03+0.j,  1.5319e-02+0.j],\n",
      "        [ 9.9691e-01+0.j, -7.1334e-02+0.j,  8.7749e-03+0.j, -1.7669e-03+0.j,\n",
      "         -2.9998e-02+0.j,  7.4693e-03+0.j,  7.2318e-03+0.j],\n",
      "        [ 2.3903e-02+0.j,  4.9153e-03+0.j, -1.0286e-02+0.j, -7.3065e-02+0.j,\n",
      "          8.8996e-01+0.j,  4.4874e-01+0.j, -2.3747e-02+0.j]],\n",
      "       dtype=torch.complex128, grad_fn=<LinalgEigBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# params = [24.42, 1.92, 1.92, 0.001, -0.045, 0.237, 3.34]\n",
    "\n",
    "df =df_full_v15\n",
    "df = df_full_v05\n",
    "# Convert parameters to a tensor with requires_grad=True\n",
    "params = torch.tensor(df.iloc[0, :-1].values, dtype=torch.float64, requires_grad=True)\n",
    "\n",
    "# params = [ 27.25, 2.18, 2.294, 4.099e-4, -0.07915, 0.0999, 3.65]   #200\n",
    "# params = torch.tensor(params, dtype=torch.float64, requires_grad=True)\n",
    "  \n",
    "\n",
    "nheads =10\n",
    "instance = kernels.vecchia_experiment(0.5, analysis_data_map, aggregated_data,nns_map,mm_cond_number, nheads)\n",
    "\n",
    "cov_map =  instance.cov_structure_saver(params, instance.matern_cov_anisotropy_v05)\n",
    "o1, o2 = instance.full_ghg_statistic(params,instance.full_likelihood,instance.matern_cov_anisotropy_v05, aggregated_data[:, :4],aggregated_data[:, 2])\n",
    "print(o1, o2)\n",
    "\n",
    "\n",
    "\n",
    "eigenvalues, eigenvectors = torch.linalg.eig(o1)\n",
    "\n",
    "# Print the results\n",
    "print(\"Eigenvalues:\", eigenvalues)\n",
    "print(\"Eigenvectors:\", eigenvectors)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I prefer looking at likelihoods only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nheads = 200\n",
    "params = [ 27.25, 2.18, 2.294, 4.099e-4, -0.07915, 0.0999, 3.65]   #200\n",
    "params = torch.tensor(params, dtype=torch.float64, requires_grad=True)\n",
    "\n",
    "instance = kernels.vecchia_experiment(0.5, analysis_data_map, aggregated_data,nns_map,mm_cond_number, nheads)\n",
    "\n",
    "mm_cond_number=10\n",
    "fl= instance.full_likelihood(params, aggregated_data[:, :4],aggregated_data[:, 2], instance.matern_cov_anisotropy_v05)\n",
    "print(fl)\n",
    "\n",
    "ll = instance.vecchia_b2(params, instance.matern_cov_anisotropy_v05 )\n",
    "print(f'mm_cond_number: {mm_cond_number} likelihood: {ll}')\n",
    "\n",
    "ll2 = instance.vecchia_interpolation_1to6(params, instance.matern_cov_anisotropy_v05 )\n",
    "print(f'mm_cond_number: {mm_cond_number} likelihood: {ll2}')\n",
    "\n",
    "key_order = [0,1,2,4,3,5,7,6]\n",
    "keys = list(analysis_data_map.keys())\n",
    "reordered_dict = {keys[key]: analysis_data_map[keys[key]] for key in key_order}\n",
    "instance = kernels.vecchia_experiment(0.5, reordered_dict, aggregated_data,nns_map,mm_cond_number, nheads)\n",
    "\n",
    "\n",
    "ll = instance.vecchia_b2(params, instance.matern_cov_anisotropy_v05 )\n",
    "print(f'mm_cond_number: {mm_cond_number} likelihood: {ll}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now compare statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cond_number of hessian 2816516.366634098\n",
      "3940.2817598903225\n",
      "-59.56466834318\n"
     ]
    }
   ],
   "source": [
    "copy_analysis_map = copy.deepcopy(analysis_data_map)\n",
    "key_order = [0,1,2,4,3,5,7,6]\n",
    "keys = list(analysis_data_map.keys())\n",
    "reordered_dict = {keys[key]: copy_analysis_map[keys[key]] for key in key_order}\n",
    "\n",
    "\n",
    "params = [ 27.25, 2.18, 2.294, 4.099e-4, -0.07915, 0.0999, 3.65]   #200\n",
    "params = torch.tensor(params, dtype=torch.float64, requires_grad=True)\n",
    "nheads =200\n",
    "instance = kernels.vecchia_experiment(0.5, analysis_data_map, aggregated_data,nns_map,mm_cond_number, nheads)\n",
    "fl= instance.full_likelihood(params, aggregated_data[:, :4],aggregated_data[:, 2], instance.matern_cov_anisotropy_v05)\n",
    "fs = instance.full_ghg_statistic(params,instance.full_likelihood, instance.matern_cov_anisotropy_v05, aggregated_data[:, :4],aggregated_data[:, 2])\n",
    "\n",
    "print(fl.item())\n",
    "print(fs.item())\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cond_number of hessian 2816516.366634098\n",
      "3940.2817598903225\n",
      "-59.56466834318\n",
      "vecchia_b2 mm_cond_number: 20 likelihood: 3975.3121026623235, statistic:-43.993833612555065\n",
      "vecchia_interpolation mm_cond_number: 20 likelihood: 3898.6010621925916, statistic:-29.24946918728037\n",
      "vecchia_b2_reordered mm_cond_number: 20 likelihood: 3972.5613997053033, statistic:-33.000113088118\n",
      "day 1 above\n",
      "cond_number of hessian 212182.97911473023\n",
      "3663.07630645092\n",
      "299.06449546243493\n",
      "vecchia_b2 mm_cond_number: 20 likelihood: 3678.227239185976, statistic:306.403761341758\n",
      "vecchia_interpolation mm_cond_number: 20 likelihood: 3593.9613722562485, statistic:346.83343565608084\n",
      "vecchia_b2_reordered mm_cond_number: 20 likelihood: 3678.0105807485916, statistic:305.79937533188473\n",
      "day 2 above\n",
      "cond_number of hessian 183073.7950892095\n",
      "4343.463121533729\n",
      "83.91664846163812\n",
      "vecchia_b2 mm_cond_number: 20 likelihood: 4367.746971329721, statistic:56.015318528607715\n",
      "vecchia_interpolation mm_cond_number: 20 likelihood: 4295.084667816446, statistic:61.17919423440279\n",
      "vecchia_b2_reordered mm_cond_number: 20 likelihood: 4377.247113226095, statistic:56.55501444263892\n",
      "day 3 above\n",
      "cond_number of hessian 229398.97183150565\n",
      "4176.694521833107\n",
      "-17.229593179563764\n",
      "vecchia_b2 mm_cond_number: 20 likelihood: 4221.472119446713, statistic:27.277282871831062\n",
      "vecchia_interpolation mm_cond_number: 20 likelihood: 4137.018148790564, statistic:52.4305666824352\n",
      "vecchia_b2_reordered mm_cond_number: 20 likelihood: 4216.360455810484, statistic:0.403899777226286\n",
      "day 4 above\n",
      "cond_number of hessian 38115.8884741029\n",
      "3570.7439797369634\n",
      "488.4422245175275\n",
      "vecchia_b2 mm_cond_number: 20 likelihood: 3621.9635435647006, statistic:411.04432044126753\n",
      "vecchia_interpolation mm_cond_number: 20 likelihood: 3544.245733685256, statistic:438.72816416974905\n",
      "vecchia_b2_reordered mm_cond_number: 20 likelihood: 3612.3469147075, statistic:436.630985346751\n",
      "day 5 above\n",
      "cond_number of hessian 308841.07111646316\n",
      "4056.432055551953\n",
      "42.92307229639042\n",
      "vecchia_b2 mm_cond_number: 20 likelihood: 4101.680400760245, statistic:18.1684571597105\n",
      "vecchia_interpolation mm_cond_number: 20 likelihood: 4002.2192143242446, statistic:26.16992424301987\n",
      "vecchia_b2_reordered mm_cond_number: 20 likelihood: 4086.9964393958226, statistic:26.69525695681834\n",
      "day 6 above\n",
      "cond_number of hessian 205356.63358799714\n",
      "4425.151112241204\n",
      "128.11351231961606\n",
      "vecchia_b2 mm_cond_number: 20 likelihood: 4458.4826684540785, statistic:103.07556640152819\n",
      "vecchia_interpolation mm_cond_number: 20 likelihood: 4407.594661585072, statistic:153.97799488058476\n",
      "vecchia_b2_reordered mm_cond_number: 20 likelihood: 4448.4241291496555, statistic:101.6783887360184\n",
      "day 7 above\n",
      "cond_number of hessian 206771.24498913877\n",
      "4300.3574636734675\n",
      "16.31338391097391\n",
      "vecchia_b2 mm_cond_number: 20 likelihood: 4388.130833701285, statistic:68.50386261493549\n",
      "vecchia_interpolation mm_cond_number: 20 likelihood: 4316.969543472212, statistic:91.36553332798192\n",
      "vecchia_b2_reordered mm_cond_number: 20 likelihood: 4381.710530096565, statistic:64.93593084546438\n",
      "day 8 above\n",
      "cond_number of hessian 1550136.1257715044\n",
      "3778.682120807496\n",
      "202.0936203152329\n",
      "vecchia_b2 mm_cond_number: 20 likelihood: 3824.990322889017, statistic:128.7078097917488\n",
      "vecchia_interpolation mm_cond_number: 20 likelihood: 3723.132939053775, statistic:154.73228355133708\n",
      "vecchia_b2_reordered mm_cond_number: 20 likelihood: 3808.704593069864, statistic:151.52749489448556\n",
      "day 9 above\n",
      "cond_number of hessian 224061.12567819454\n",
      "4210.454494444216\n",
      "85.8065347886513\n",
      "vecchia_b2 mm_cond_number: 20 likelihood: 4249.196873589959, statistic:54.928390557257345\n",
      "vecchia_interpolation mm_cond_number: 20 likelihood: 4117.866337079586, statistic:31.911956856682426\n",
      "vecchia_b2_reordered mm_cond_number: 20 likelihood: 4247.193668546364, statistic:56.16707346342244\n",
      "day 10 above\n",
      "cond_number of hessian 1690718.4192618672\n",
      "3811.798100703498\n",
      "162.26057488419025\n",
      "vecchia_b2 mm_cond_number: 20 likelihood: 3837.083257173617, statistic:145.75863581254436\n",
      "vecchia_interpolation mm_cond_number: 20 likelihood: 3726.6890165802542, statistic:154.9325782126018\n",
      "vecchia_b2_reordered mm_cond_number: 20 likelihood: 3839.754460550377, statistic:131.8371650257125\n",
      "day 11 above\n",
      "cond_number of hessian 63537.94468948002\n",
      "3544.8111566058383\n",
      "986.4175750033716\n",
      "vecchia_b2 mm_cond_number: 20 likelihood: 3564.743293258005, statistic:968.1395221615202\n",
      "vecchia_interpolation mm_cond_number: 20 likelihood: 3495.080205676562, statistic:978.0882741678824\n",
      "vecchia_b2_reordered mm_cond_number: 20 likelihood: 3561.9905296898164, statistic:943.2188750640967\n",
      "day 12 above\n",
      "cond_number of hessian 292477.22700400156\n",
      "3578.6805701270364\n",
      "1042.052958415718\n",
      "vecchia_b2 mm_cond_number: 20 likelihood: 3605.6343855881537, statistic:963.6952830530785\n",
      "vecchia_interpolation mm_cond_number: 20 likelihood: 3543.3758346830787, statistic:747.7075068862723\n",
      "vecchia_b2_reordered mm_cond_number: 20 likelihood: 3601.2327019353597, statistic:945.6898414899069\n",
      "day 13 above\n",
      "cond_number of hessian 1199356.2961698393\n",
      "3737.2161536568747\n",
      "170.24490642202932\n",
      "vecchia_b2 mm_cond_number: 20 likelihood: 3764.524184527033, statistic:129.4526409253935\n",
      "vecchia_interpolation mm_cond_number: 20 likelihood: 3690.0534779112086, statistic:130.02625037101214\n",
      "vecchia_b2_reordered mm_cond_number: 20 likelihood: 3751.237367854742, statistic:117.12126666668559\n",
      "day 14 above\n"
     ]
    }
   ],
   "source": [
    "lat_lon_resolution = [8,8]\n",
    "params = [ 27.25, 2.18, 2.294, 4.099e-4, -0.07915, 0.0999, 3.65]   #200\n",
    "params = torch.tensor(params, dtype=torch.float64, requires_grad=True)\n",
    "\n",
    "\n",
    "for day in range(1,15):\n",
    "    # day = 7\n",
    "    mm_cond_number = 20\n",
    "\n",
    "    years = ['2024']\n",
    "    month_range =[7,8]\n",
    "    idx_for_datamap= [ 8*(day-1),8*day]\n",
    "\n",
    "    instance = load_data_local_computer()\n",
    "    month_map, ord_mm, nns_map= instance.load_mm20k_data_bymonthyear( lat_lon_resolution= lat_lon_resolution, mm_cond_number=mm_cond_number,years_=years, months_=month_range)\n",
    "    analysis_data_map, aggregated_data = instance.load_working_data_byday( month_map, ord_mm, nns_map, idx_for_datamap=idx_for_datamap)\n",
    "\n",
    "    nheads = 20\n",
    "    instance = kernels.vecchia_experiment(0.5, analysis_data_map, aggregated_data,nns_map,mm_cond_number, nheads)\n",
    "\n",
    "    fl= instance.full_likelihood(params, aggregated_data[:, :4],aggregated_data[:, 2], instance.matern_cov_anisotropy_v05)\n",
    "    \n",
    "    fs = instance.full_ghg_statistic(params,instance.full_likelihood, instance.matern_cov_anisotropy_v05, aggregated_data[:, :4],aggregated_data[:, 2])\n",
    "\n",
    "    print(fl.item())\n",
    "\n",
    "    print(fs.item())\n",
    "\n",
    "    o1= instance.vecc_ghg_statistic(params,instance.full_likelihood, instance.vecchia_b2,instance.matern_cov_anisotropy_v05, aggregated_data[:, :4],aggregated_data[:, 2])\n",
    "\n",
    "    ll = instance.vecchia_b2(params, instance.matern_cov_anisotropy_v05 )\n",
    "    print(f'vecchia_b2 mm_cond_number: {mm_cond_number} likelihood: {ll}, statistic:{o1}')\n",
    "\n",
    "    o1= instance.vecc_ghg_statistic(params,instance.full_likelihood, instance.vecchia_interpolation_1to6,instance.matern_cov_anisotropy_v05, aggregated_data[:, :4],aggregated_data[:, 2])\n",
    "\n",
    "    ll = instance.vecchia_interpolation_1to6(params, instance.matern_cov_anisotropy_v05 )\n",
    "    print(f'vecchia_interpolation mm_cond_number: {mm_cond_number} likelihood: {ll}, statistic:{o1}')\n",
    "\n",
    "\n",
    "    key_order = [0,1,2,4,3,5,7,6]\n",
    "    keys = list(analysis_data_map.keys())\n",
    "    reordered_dict = {keys[key]: analysis_data_map[keys[key]] for key in key_order}\n",
    "\n",
    "    instance = kernels.vecchia_experiment(0.5, reordered_dict, aggregated_data,nns_map,mm_cond_number, nheads)\n",
    "\n",
    "    o1= instance.vecc_ghg_statistic(params,instance.full_likelihood, instance.vecchia_b2, instance.matern_cov_anisotropy_v05, aggregated_data[:, :4],aggregated_data[:, 2])\n",
    "    ll = instance.vecchia_b2(params, instance.matern_cov_anisotropy_v05 )\n",
    "    print(f'vecchia_b2_reordered mm_cond_number: {mm_cond_number} likelihood: {ll}, statistic:{o1}')\n",
    "\n",
    "    print( f'day {day} above')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vary the size of conditioning set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cond_number of hessian 189194.83871267262\n",
      "full likelihood: 2547.258276245673, full statistic: 5.100717330882949\n",
      "cond_number of hessian 189194.83871267262\n",
      "mm_cond_number: 5 likelihood: 2571.7202011676554, statistic:4.810536260238044\n",
      "cond_number of hessian 189194.83871267262\n",
      "mm_cond_number: 6 likelihood: 2569.9784416212933, statistic:4.106628202046433\n",
      "cond_number of hessian 189194.83871267262\n",
      "mm_cond_number: 7 likelihood: 2567.640680723155, statistic:4.602141260135241\n",
      "cond_number of hessian 189194.83871267262\n",
      "mm_cond_number: 8 likelihood: 2567.6782831405317, statistic:5.079131623977824\n",
      "cond_number of hessian 189194.83871267262\n",
      "mm_cond_number: 9 likelihood: 2568.0001926920804, statistic:5.343090709089482\n",
      "cond_number of hessian 189194.83871267262\n",
      "mm_cond_number: 10 likelihood: 2566.523313914881, statistic:5.518904441534436\n",
      "cond_number of hessian 189194.83871267262\n",
      "mm_cond_number: 11 likelihood: 2566.7857736093847, statistic:5.4051722056787765\n",
      "cond_number of hessian 189194.83871267262\n",
      "mm_cond_number: 12 likelihood: 2568.124282603543, statistic:5.0296126600381275\n",
      "cond_number of hessian 189194.83871267262\n",
      "mm_cond_number: 13 likelihood: 2568.233047121573, statistic:5.250201889848884\n",
      "cond_number of hessian 189194.83871267262\n",
      "mm_cond_number: 14 likelihood: 2567.7039694302566, statistic:5.450737014135071\n",
      "cond_number of hessian 189194.83871267262\n",
      "mm_cond_number: 15 likelihood: 2568.0358535771416, statistic:5.417689812997492\n",
      "cond_number of hessian 189194.83871267262\n",
      "mm_cond_number: 16 likelihood: 2568.219484059257, statistic:5.164314269337584\n",
      "cond_number of hessian 189194.83871267262\n",
      "mm_cond_number: 17 likelihood: 2568.4759060207284, statistic:5.039571475176778\n",
      "cond_number of hessian 189194.83871267262\n",
      "mm_cond_number: 18 likelihood: 2568.5694376562374, statistic:4.8627871727010685\n",
      "cond_number of hessian 189194.83871267262\n",
      "mm_cond_number: 19 likelihood: 2568.953714275638, statistic:5.170509997209056\n",
      "cond_number of hessian 189194.83871267262\n",
      "mm_cond_number: 20 likelihood: 2569.1609961219333, statistic:5.325902938501164\n",
      "cond_number of hessian 189194.83871267262\n",
      "mm_cond_number: 21 likelihood: 2569.1609961219333, statistic:5.325902938501164\n",
      "cond_number of hessian 189194.83871267262\n",
      "mm_cond_number: 22 likelihood: 2569.1609961219333, statistic:5.325902938501164\n",
      "cond_number of hessian 189194.83871267262\n",
      "mm_cond_number: 23 likelihood: 2569.1609961219333, statistic:5.325902938501164\n",
      "cond_number of hessian 189194.83871267262\n",
      "mm_cond_number: 24 likelihood: 2569.1609961219333, statistic:5.325902938501164\n",
      "cond_number of hessian 189194.83871267262\n",
      "mm_cond_number: 25 likelihood: 2569.1609961219333, statistic:5.325902938501164\n",
      "cond_number of hessian 189194.83871267262\n",
      "mm_cond_number: 26 likelihood: 2569.1609961219333, statistic:5.325902938501164\n",
      "cond_number of hessian 189194.83871267262\n",
      "mm_cond_number: 27 likelihood: 2569.1609961219333, statistic:5.325902938501164\n",
      "cond_number of hessian 189194.83871267262\n",
      "mm_cond_number: 28 likelihood: 2569.1609961219333, statistic:5.325902938501164\n",
      "cond_number of hessian 189194.83871267262\n",
      "mm_cond_number: 29 likelihood: 2569.1609961219333, statistic:5.325902938501164\n"
     ]
    }
   ],
   "source": [
    "instance = kernels.vecchia_experiment(0.5, analysis_data_map, aggregated_data,nns_map,mm_cond_number, nheads)\n",
    "fl= instance.full_likelihood(params, aggregated_data[:, :4],aggregated_data[:, 2], instance.matern_cov_anisotropy_v05)\n",
    "fs = instance.full_ghg_statistic(params,instance.full_likelihood, instance.matern_cov_anisotropy_v05, aggregated_data[:, :4],aggregated_data[:, 2])\n",
    "\n",
    "print(f'full likelihood: {fl}, full statistic: {fs}')\n",
    "for i in range(5,30):\n",
    "    mm_cond_number = i\n",
    "    instance = kernels.vecchia_experiment(0.5, analysis_data_map, aggregated_data,nns_map,mm_cond_number, nheads)\n",
    "    \n",
    "    o1= instance.vecc_ghg_statistic(params,instance.full_likelihood, instance.vecchia_b2,instance.matern_cov_anisotropy_v05, aggregated_data[:, :4],aggregated_data[:, 2])\n",
    "    ll = instance.vecchia_b2(params, instance.matern_cov_anisotropy_v05 )\n",
    "    print(f'mm_cond_number: {i} likelihood: {ll}, statistic:{o1}')\n",
    "\n"
   ]
<<<<<<< HEAD
<<<<<<< HEAD
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
=======
>>>>>>> 98fc71c474ddced6792e89e9ab27c07529da5b48
=======
>>>>>>> 0a418ac421c02a3cd32b6e4c97b2bdc92cdb79b7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "faiss_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
<<<<<<< HEAD
   "version": "3.12.3"
=======
   "version": "3.12.9"
>>>>>>> 98fc71c474ddced6792e89e9ab27c07529da5b48
=======
   "version": "3.12.9"
>>>>>>> 0a418ac421c02a3cd32b6e4c97b2bdc92cdb79b7
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
