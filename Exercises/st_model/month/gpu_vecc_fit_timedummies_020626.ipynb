{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46152216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import sys\n",
    "# Add your custom path\n",
    "gems_tco_path = \"/Users/joonwonlee/Documents/GEMS_TCO-1/src\"\n",
    "sys.path.append(gems_tco_path)\n",
    "import os\n",
    "import logging\n",
    "import argparse # Argument parsing\n",
    "\n",
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import copy                    # clone tensor\n",
    "import time\n",
    "\n",
    "# Custom imports\n",
    "\n",
    "from GEMS_TCO import kernels_month\n",
    "\n",
    "from GEMS_TCO import orderings as _orderings \n",
    "from GEMS_TCO import alg_optimization, BaseLogger\n",
    "from GEMS_TCO import kernels_columns as kernels_reparam_space_time_gpu_col\n",
    "from typing import Optional, List, Tuple\n",
    "from pathlib import Path\n",
    "import typer\n",
    "import json\n",
    "from json import JSONEncoder\n",
    "from GEMS_TCO import configuration as config\n",
    "from GEMS_TCO.data_loader import load_data2, exact_location_filter\n",
    "from GEMS_TCO import debiased_whittle\n",
    "from torch.nn import Parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21342d99",
   "metadata": {},
   "source": [
    "Load daily data applying max-min ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "961692a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Global Monthly Mean for 2024-7: 257.0667 ---\n"
     ]
    }
   ],
   "source": [
    "space: List[str] = ['1', '1']\n",
    "lat_lon_resolution = [int(s) for s in space]\n",
    "mm_cond_number: int = 8\n",
    "years = ['2024']\n",
    "month_range = [7] \n",
    "\n",
    "output_path = input_path = Path(config.mac_estimates_day_path)\n",
    "data_load_instance = load_data2(config.mac_data_load_path)\n",
    "\n",
    "#lat_range_input = [1, 3]\n",
    "#lon_range_input = [125.0, 129.0]\n",
    "\n",
    "#lat_range_input=[-3,2]      \n",
    "#lon_range_input=[121, 131] \n",
    "lat_range_input=[-3,-1]      \n",
    "lon_range_input=[121, 125] \n",
    "\n",
    "df_map, ord_mm, nns_map, day_offsets = data_load_instance.load_maxmin_ordered_data_bymonthyear(\n",
    "lat_lon_resolution=lat_lon_resolution, \n",
    "mm_cond_number=mm_cond_number,\n",
    "years_=years, \n",
    "months_=month_range,\n",
    "\n",
    "lat_range=lat_range_input,   \n",
    "lon_range=lon_range_input\n",
    "  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0f596f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated Tensor Shape: torch.Size([22680, 11])\n"
     ]
    }
   ],
   "source": [
    "daily_aggregated_tensors_dw = [] \n",
    "daily_hourly_maps_dw = []      \n",
    "\n",
    "daily_aggregated_tensors_vecc = [] \n",
    "daily_hourly_maps_vecc = []   \n",
    "\n",
    "for day_index in range(31):\n",
    "    hour_start_index = day_index * 8\n",
    "    hour_end_index = (day_index + 1) * 8\n",
    "    hour_indices = [hour_start_index, hour_end_index]\n",
    "\n",
    "    # --- DWìš© ë°ì´í„° ë¡œë“œ (day_offsets ì¸ì ì¶”ê°€) ---\n",
    "    day_hourly_map, day_aggregated_tensor = data_load_instance.load_working_data(\n",
    "        df_map, \n",
    "        day_offsets,  # <--- ì´ ë¶€ë¶„ì´ ì¶”ê°€ë˜ì–´ì•¼ í•©ë‹ˆë‹¤\n",
    "        hour_indices, \n",
    "        ord_mm=ord_mm,\n",
    "        dtype=torch.float64, \n",
    "        keep_ori=False\n",
    "    )\n",
    "    daily_aggregated_tensors_dw.append(day_aggregated_tensor)\n",
    "    daily_hourly_maps_dw.append(day_hourly_map)\n",
    "\n",
    "    # --- Vecchiaìš© ë°ì´í„° ë¡œë“œ (day_offsets ì¸ì ì¶”ê°€) ---\n",
    "    day_hourly_map, day_aggregated_tensor = data_load_instance.load_working_data(\n",
    "        df_map, \n",
    "        day_offsets,  # <--- ì´ ë¶€ë¶„ì´ ì¶”ê°€ë˜ì–´ì•¼ í•©ë‹ˆë‹¤\n",
    "        hour_indices, \n",
    "        ord_mm=ord_mm,\n",
    "        dtype=torch.float64, \n",
    "        keep_ori= True\n",
    "    )\n",
    "    daily_aggregated_tensors_vecc.append(day_aggregated_tensor)\n",
    "    daily_hourly_maps_vecc.append(day_hourly_map)\n",
    "\n",
    "print(f\"Aggregated Tensor Shape: {daily_aggregated_tensors_vecc[0].shape}\")\n",
    "# ì˜ˆìƒ ì¶œë ¥: torch.Size([í–‰ìˆ˜, 12]) -> ì—´ì´ 12ê°œì—¬ì•¼ ì„±ê³µì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b57518db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging data for days: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27]\n",
      "------------------------------\n",
      "âœ… Merging Complete for 28 days.\n",
      "Tensor Shape: torch.Size([635040, 11])\n",
      "Map Keys (Hours): 224 hours\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "v=0.5\n",
    "\n",
    "patience, factor = 5, 0.5\n",
    "# [ìˆ˜ì • 2] ì´ì›ƒ ìˆ«ì í™•ì¸ (A+B+C = 26ê°œ ì´ìƒì´ì–´ì•¼ í•¨)\n",
    "mm_cond_number = 8        # ë„‰ë„‰í•˜ê²Œ ì„¤ì •\n",
    "nheads = 15                # ì‹œê°„ë‹¹ 30ê°œ (ì•ë¶€ë¶„ Low Freq)\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# ==========================================\n",
    "# 1. ë³‘í•©í•  ê¸°ê°„ ì„¤ì • (User Setting)\n",
    "# ==========================================\n",
    "# ì˜ˆ: 0ì¼ë¶€í„° 9ì¼ê¹Œì§€ (ì´ 10ì¼ì¹˜)ë§Œ í•™ìŠµí•˜ê³  ì‹¶ë‹¤ë©´ range(10)\n",
    "# ì˜ˆ: 31ì¼ ì „ì²´ë¥¼ í•™ìŠµí•˜ê³  ì‹¶ë‹¤ë©´ range(31)\n",
    "TARGET_DAYS_IDX = range(28) \n",
    "\n",
    "print(f\"Merging data for days: {list(TARGET_DAYS_IDX)}\")\n",
    "\n",
    "# ==========================================\n",
    "# 2. Tensor ë³‘í•© (Torch.cat)\n",
    "# ==========================================\n",
    "# ì„ íƒí•œ ë‚ ì§œë“¤ì˜ Tensorë§Œ ë¦¬ìŠ¤íŠ¸ì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
    "selected_tensors = [daily_aggregated_tensors_vecc[i] for i in TARGET_DAYS_IDX]\n",
    "\n",
    "# dim=0 (í–‰ ë°©í–¥)ìœ¼ë¡œ ì´ì–´ ë¶™ì…ë‹ˆë‹¤.\n",
    "full_aggregated_tensor_vecc = torch.cat(selected_tensors, dim=0)\n",
    "\n",
    "# ==========================================\n",
    "# 3. Input Map ë³‘í•© (Dict Update)\n",
    "# ==========================================\n",
    "full_input_map_vecc = {}\n",
    "\n",
    "# ì„ íƒí•œ ë‚ ì§œë“¤ì˜ Dictionaryë¥¼ ìˆœíšŒí•˜ë©° í•˜ë‚˜ë¡œ í•©ì¹©ë‹ˆë‹¤.\n",
    "# ì£¼ì˜: load_working_dataì—ì„œ ìƒì„±ëœ key(ì‹œê°„ ì¸ë±ìŠ¤)ê°€ ë‚ ì§œë³„ë¡œ ê²¹ì¹˜ì§€ ì•Šê³ \n",
    "# global index(ì˜ˆ: 0~7, 8~15...)ë¡œ ë˜ì–´ ìˆì–´ì•¼ ë®ì–´ì”Œì›Œì§€ì§€ ì•ŠìŠµë‹ˆë‹¤.\n",
    "# ì‘ì„±í•˜ì‹  ì½”ë“œì˜ hour_indices ê³„ì‚°ì‹ì„ ë³´ë©´ Global Indexì´ë¯€ë¡œ ì•ˆì „í•©ë‹ˆë‹¤.\n",
    "for i in TARGET_DAYS_IDX:\n",
    "    daily_map = daily_hourly_maps_vecc[i]\n",
    "    full_input_map_vecc.update(daily_map)\n",
    "\n",
    "# ==========================================\n",
    "# 4. NNS Map ë³‘í•© (ê°€ì¥ ì¤‘ìš” â˜…)\n",
    "# ==========================================\n",
    "# ì£¼ì˜: NNS Map(ì´ì›ƒ ì¸ë±ìŠ¤)ì´ ë§Œì•½ 'í•˜ë£¨ ë‹¨ìœ„'ë¡œ 0ë¶€í„° ì‹œì‘í•˜ê²Œ ê³„ì‚°ë˜ì–´ ìˆë‹¤ë©´,\n",
    "# 2ì¼ì°¨ì˜ ì´ì›ƒ ì¸ë±ìŠ¤ëŠ” 1ì¼ì°¨ ë°ì´í„° ê°œìˆ˜ë§Œí¼ ë”í•´ì¤˜ì•¼ í•©ë‹ˆë‹¤ (Offset).\n",
    "# ë§Œì•½ NNS Mapì„ ì•„ì§ ì•ˆ ë§Œë“œì…¨ê±°ë‚˜, ì „ì²´ ë°ì´í„° ê¸°ì¤€ ìƒˆë¡œ ë§Œë“œì‹¤ ê±°ë¼ë©´ ì´ ë¶€ë¶„ì€ íŒ¨ìŠ¤í•˜ì„¸ìš”.\n",
    "\n",
    "# (ì˜ˆì‹œ: ë§Œì•½ daily_nns_maps ë¼ëŠ” ë¦¬ìŠ¤íŠ¸ê°€ ìˆë‹¤ê³  ê°€ì •í•  ë•Œì˜ ë³‘í•© ë¡œì§)\n",
    "# full_nns_map = []\n",
    "# current_offset = 0\n",
    "# for i in TARGET_DAYS_IDX:\n",
    "#     # í•´ë‹¹ ë‚ ì§œì˜ ë°ì´í„° ê°œìˆ˜\n",
    "#     day_len = daily_aggregated_tensors_vecc[i].shape[0]\n",
    "#     \n",
    "#     # í•´ë‹¹ ë‚ ì§œì˜ NNS Mapì„ ê°€ì ¸ì™€ì„œ Offset ë”í•˜ê¸° (ìœ íš¨í•œ ì¸ë±ìŠ¤ë§Œ)\n",
    "#     # nns_local = daily_nns_maps[i] + current_offset\n",
    "#     # full_nns_map.extend(nns_local)\n",
    "#     \n",
    "#     current_offset += day_len\n",
    "\n",
    "# ==========================================\n",
    "# 5. ê²°ê³¼ í™•ì¸\n",
    "# ==========================================\n",
    "print(\"-\" * 30)\n",
    "print(f\"âœ… Merging Complete for {len(TARGET_DAYS_IDX)} days.\")\n",
    "print(f\"Tensor Shape: {full_aggregated_tensor_vecc.shape}\")\n",
    "print(f\"Map Keys (Hours): {len(full_input_map_vecc)} hours\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# ì´ì œ ëª¨ë¸ì—ëŠ” ì•„ë˜ ë³€ìˆ˜ë¥¼ ë„£ìœ¼ì‹œë©´ ë©ë‹ˆë‹¤.\n",
    "# aggregated_data = full_aggregated_tensor_vecc\n",
    "# input_map = full_input_map_vecc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64b1a20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n",
      "========================================\n",
      "--- Merging Data for Days: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27] ---\n",
      "========================================\n",
      "Merged Tensor Shape: torch.Size([635040, 11])\n",
      "Merged Map Keys: 224\n",
      "\n",
      "Instantiating SpatioTemporalModel (Fit strategy: A+B+C)...\n",
      "\n",
      "--- Starting Optimization (Full 10 Days) ---\n",
      "ğŸš€ Pre-computing (Top 15 Max-Min Ordered Heads per hour)... [Mean Lat: -2.0043] âœ… Done. (Total Heads: 3360, Total Tails: 631680)\n",
      "--- Starting Batched L-BFGS Optimization (GPU) ---\n",
      "--- Step 1/3 / Loss: 1.247805 ---\n",
      "  Param 0: Value=3.4137, Grad=5.892208193798753e-07\n",
      "  Param 1: Value=0.7938, Grad=-2.654627065246779e-07\n",
      "  Param 2: Value=0.2175, Grad=-2.886890257192976e-07\n",
      "  Param 3: Value=-3.2836, Grad=7.534578038521575e-10\n",
      "  Param 4: Value=0.0050, Grad=8.544382242470401e-08\n",
      "  Param 5: Value=-0.0822, Grad=6.400916973433972e-09\n",
      "  Param 6: Value=-0.3507, Grad=5.398397513929642e-07\n",
      "  Max Abs Grad: 5.892208e-07\n",
      "------------------------------\n",
      "--- Step 2/3 / Loss: 1.221592 ---\n",
      "  Param 0: Value=3.4137, Grad=5.892208193798753e-07\n",
      "  Param 1: Value=0.7938, Grad=-2.654627065246779e-07\n",
      "  Param 2: Value=0.2175, Grad=-2.886890257192976e-07\n",
      "  Param 3: Value=-3.2836, Grad=7.534578038521575e-10\n",
      "  Param 4: Value=0.0050, Grad=8.544382242470401e-08\n",
      "  Param 5: Value=-0.0822, Grad=6.400916973433972e-09\n",
      "  Param 6: Value=-0.3507, Grad=5.398397513929642e-07\n",
      "  Max Abs Grad: 5.892208e-07\n",
      "------------------------------\n",
      "--- Step 3/3 / Loss: 1.221592 ---\n",
      "  Param 0: Value=3.4137, Grad=5.892208193798753e-07\n",
      "  Param 1: Value=0.7938, Grad=-2.654627065246779e-07\n",
      "  Param 2: Value=0.2175, Grad=-2.886890257192976e-07\n",
      "  Param 3: Value=-3.2836, Grad=7.534578038521575e-10\n",
      "  Param 4: Value=0.0050, Grad=8.544382242470401e-08\n",
      "  Param 5: Value=-0.0822, Grad=6.400916973433972e-09\n",
      "  Param 6: Value=-0.3507, Grad=5.398397513929642e-07\n",
      "  Max Abs Grad: 5.892208e-07\n",
      "------------------------------\n",
      "Final Interpretable Params: {'sigma_sq': 13.734557327403946, 'range_lon': 0.45213182782335026, 'range_lat': 0.4055482740215506, 'range_time': 2.335070352482909, 'advec_lat': 0.005047451506194298, 'advec_lon': -0.08219441822745353, 'nugget': 0.7042012287667734}\n",
      "Optimization finished in 630.46s.\n",
      "Final Params & Loss: [3.4136965766941114, 0.7937814871963662, 0.21746775434809196, -3.283647014812686, 0.005047451506194298, -0.08219441822745353, -0.3506911273510723, 1.221591714450266]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# --- 1. Global Settings ---\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# [ì„¤ì •] ìµœì í™” íŒŒë¼ë¯¸í„° (10ì¼ì¹˜ ë°ì´í„°ë¥¼ ìœ„í•´ Step ìˆ˜ ìƒí–¥)\n",
    "LBFGS_LR = 1.0\n",
    "LBFGS_MAX_STEPS = 3       # [ìˆ˜ì •] ìˆ˜ë ´ì„ ìœ„í•´ 3 -> 50 ê¶Œì¥ (ë””ë²„ê¹…ìš©ì´ë©´ 3 ìœ ì§€)\n",
    "LBFGS_HISTORY_SIZE = 100   \n",
    "LBFGS_MAX_EVAL = 100        # Line search íšŸìˆ˜\n",
    "\n",
    "# [ì„¤ì •] ëª¨ë¸ë§í•  ê¸°ê°„ ì„ íƒ (ì˜ˆ: ì•ì˜ 10ì¼ë§Œ ì‚¬ìš©)\n",
    "# daily_aggregated_tensors_vecc ë¦¬ìŠ¤íŠ¸ì˜ ì¸ë±ìŠ¤ ê¸°ì¤€\n",
    "TARGET_DAYS_IDX = range(28) # 0ì¼ì°¨ ~ 9ì¼ì°¨\n",
    "\n",
    "# --- 2. Data Preparation (Merge Lists into One) ---\n",
    "print(f'\\n{\"=\"*40}')\n",
    "print(f'--- Merging Data for Days: {list(TARGET_DAYS_IDX)} ---')\n",
    "print(f'{\"=\"*40}')\n",
    "\n",
    "# (1) Tensor í•©ì¹˜ê¸° (Time ë°©í–¥ìœ¼ë¡œ ì—°ê²°)\n",
    "# daily_aggregated_tensors_veccëŠ” [Tensor(Day1), Tensor(Day2)...] í˜•íƒœ\n",
    "selected_tensors = [daily_aggregated_tensors_vecc[i] for i in TARGET_DAYS_IDX]\n",
    "full_aggr_data = torch.cat(selected_tensors, dim=0).to(DEVICE)\n",
    "\n",
    "# (2) Input Map í•©ì¹˜ê¸° (Dictionary Update)\n",
    "# daily_hourly_maps_veccëŠ” [Dict(Day1), Dict(Day2)...] í˜•íƒœ\n",
    "full_input_map = {}\n",
    "for i in TARGET_DAYS_IDX:\n",
    "    # ì‹œê°„ ì¸ë±ìŠ¤(Key)ê°€ ê²¹ì¹˜ì§€ ì•ŠëŠ”ë‹¤ê³  ê°€ì • (Global Index ì‚¬ìš© ì‹œ ì•ˆì „)\n",
    "    full_input_map.update(daily_hourly_maps_vecc[i])\n",
    "\n",
    "# (3) NNS Map ì„¤ì •\n",
    "# [ê°€ì •] nns_mapì€ ê³µê°„ìƒì˜ ì´ì›ƒ(Spatial NNS)ë§Œ ì •ì˜ë˜ì–´ ìˆìŒ.\n",
    "# ëª¨ë¸ ë‚´ë¶€ì—ì„œ ì‹œê°„ Offsetì„ ìë™ìœ¼ë¡œ ë”í•´ì£¼ë¯€ë¡œ, ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ë©´ ë¨.\n",
    "full_nns_map = nns_map # (User Contextì—ì„œ ì´ë¯¸ ì£¼ì–´ì§„ ë³€ìˆ˜)\n",
    "\n",
    "print(f\"Merged Tensor Shape: {full_aggr_data.shape}\")\n",
    "print(f\"Merged Map Keys: {len(full_input_map)}\")\n",
    "\n",
    "\n",
    "# --- 3. Initial Parameters ---\n",
    "init_sigmasq   = 13.059\n",
    "init_range_lat = 0.2\n",
    "init_range_lon = 0.25\n",
    "init_advec_lat = 0.0218\n",
    "init_range_time = 1.5\n",
    "init_advec_lon = -0.1689\n",
    "init_nugget    = 0.247\n",
    "\n",
    "# Map parameters to Log-Scale\n",
    "init_phi2 = 1.0 / init_range_lon                \n",
    "init_phi1 = init_sigmasq * init_phi2            \n",
    "init_phi3 = (init_range_lon / init_range_lat)**2  \n",
    "init_phi4 = (init_range_lon / init_range_time)**2      \n",
    "\n",
    "initial_vals = [np.log(init_phi1), np.log(init_phi2), np.log(init_phi3), \n",
    "                np.log(init_phi4), init_advec_lat, init_advec_lon, np.log(init_nugget)]\n",
    "\n",
    "params_list = [\n",
    "    torch.tensor([val], requires_grad=True, dtype=torch.float64, device=DEVICE)\n",
    "    for val in initial_vals\n",
    "]\n",
    "\n",
    "\n",
    "# --- 4. Instantiate & Fit ---\n",
    "print(f\"\\nInstantiating SpatioTemporalModel (Fit strategy: A+B+C)...\")\n",
    "\n",
    "# [ì¤‘ìš”] ì •ì˜í•´ë‘” Class ì´ë¦„ í™•ì¸ (ì—¬ê¸°ì„œëŠ” fit_vecchia_lbfgsë¡œ ê°€ì •)\n",
    "# ë§Œì•½ import kernels_reparam_space_time í–ˆë‹¤ë©´ ì•ì— ëª¨ë“ˆëª… ë¶™ì—¬ì•¼ í•¨\n",
    "model_instance = kernels_month.fit_vecchia_lbfgs( \n",
    "    smooth = 0.5,                    # Smoothness (v) ê°’ (User Context í™•ì¸ í•„ìš”)\n",
    "    input_map = full_input_map,      # [ìˆ˜ì •] í•©ì³ì§„ ë°ì´í„°\n",
    "    aggregated_data = full_aggr_data,# [ìˆ˜ì •] í•©ì³ì§„ ë°ì´í„°\n",
    "    nns_map = full_nns_map,          # [ìœ ì§€] ê³µê°„ NNS\n",
    "    mm_cond_number = mm_cond_number, # (User Context ë³€ìˆ˜) ì˜ˆ: 30~40\n",
    "    nheads = nheads                  # (User Context ë³€ìˆ˜) ì˜ˆ: 30\n",
    ")\n",
    "\n",
    "# Optimizer ì„¤ì •\n",
    "optimizer_vecc = model_instance.set_optimizer(\n",
    "    params_list,     \n",
    "    lr=LBFGS_LR,            \n",
    "    max_iter=LBFGS_MAX_EVAL,        \n",
    "    history_size=LBFGS_HISTORY_SIZE \n",
    ")\n",
    "\n",
    "print(f\"\\n--- Starting Optimization (Full 10 Days) ---\")\n",
    "start_time = time.time()\n",
    "\n",
    "# ì‹¤í–‰\n",
    "out, steps_ran = model_instance.fit_vecc_lbfgs(\n",
    "    params_list,\n",
    "    optimizer_vecc,\n",
    "    max_steps=LBFGS_MAX_STEPS, \n",
    "    grad_tol=1e-7\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Optimization finished in {end_time - start_time:.2f}s.\")\n",
    "print(f\"Final Params & Loss: {out}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8a09bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid decimal literal (2978187764.py, line 7)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mVecchia Optimization finished in 67.75s. Results: [3.691525186381127, 1.0134272349673297, 0.13156138084623087, -3.2362903523329813, -0.0014072484629318405, -0.16623085410420968, -1.3863173419076031, 0.9065025151721705]\u001b[39m\n                                         ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid decimal literal\n"
     ]
    }
   ],
   "source": [
    "irr. (-3,2 121,131, intercept, time dummies, latitude)\n",
    "\n",
    "Final Interpretable Params: {\n",
    "    \n",
    "'sigma_sq': 14.557378105972255, \n",
    " 'range_lon': 0.36297285215444397, 'range_lat': 0.33986461719454436, 'range_time': 1.8307357609214716, 'advec_lat': -0.0014072484629318405, 'advec_lon': -0.16623085410420968, 'nugget': 0.24999425486908594}\n",
    "Vecchia Optimization finished in 67.75s. Results: [3.691525186381127, 1.0134272349673297, 0.13156138084623087, -3.2362903523329813, -0.0014072484629318405, -0.16623085410420968, -1.3863173419076031, 0.9065025151721705]\n",
    "\n",
    "regular (hide nugget)\n",
    "------------------------------\n",
    "------------------------------\n",
    "Final Interpretable Params: {'sigma_sq': 13.881823879707401, 'range_lon': 0.3308191657110315, 'range_lat': 0.3048282266752421, 'range_time': 1.6460269337530522, 'advec_lat': -0.0014028377727820455, 'advec_lon': -0.15541841240605433, 'nugget': 1.112667285815519e-07}\n",
    "Vecchia Optimization finished in 141.61s. Results: [3.7367637299362526, 1.1061833800531369, 0.16364694440410635, -3.209095690658186, -0.0014028377727820455, -0.15541841240605433, -16.01133555793201, 0.9490311091657573]\n",
    "\n",
    "\n",
    "irr  ar(1) offset logic ì´ìš©í–ˆì„ë•Œ ì‚¬ì‹¤ ì°¨ì´ ì—†ê³  latitude centering í–ˆì„ ë•Œ ì†Œìˆ˜ì  10ì¨°ìë¦¬ì—ì„œ ì‚´ì§ ê°œì„ \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gems_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
