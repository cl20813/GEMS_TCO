{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 2,
=======
   "execution_count": 9,
>>>>>>> 98fc71c474ddced6792e89e9ab27c07529da5b48
=======
   "execution_count": 9,
>>>>>>> 0a418ac421c02a3cd32b6e4c97b2bdc92cdb79b7
   "id": "63731e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
<<<<<<< HEAD
<<<<<<< HEAD
      " Day 1 data size per day: 20000.0 \n",
=======
      " Day 1 data size per day: 50.0 \n",
>>>>>>> 98fc71c474ddced6792e89e9ab27c07529da5b48
=======
      " Day 1 data size per day: 50.0 \n",
>>>>>>> 0a418ac421c02a3cd32b6e4c97b2bdc92cdb79b7
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
<<<<<<< HEAD
<<<<<<< HEAD
    "gems_tco_path = \"/Users/joonwonlee/Documents/GEMS_TCO-1/src\"\n",
    "sys.path.append(gems_tco_path)\n",
=======
    "# gems_tco_path = \"/Users/joonwonlee/Documents/GEMS_TCO-1/src\"\n",
    "# sys.path.append(gems_tco_path)\n",
>>>>>>> 98fc71c474ddced6792e89e9ab27c07529da5b48
=======
    "# gems_tco_path = \"/Users/joonwonlee/Documents/GEMS_TCO-1/src\"\n",
    "# sys.path.append(gems_tco_path)\n",
>>>>>>> 0a418ac421c02a3cd32b6e4c97b2bdc92cdb79b7
    "\n",
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle \n",
    "\n",
    "import GEMS_TCO\n",
    "from GEMS_TCO import kernels \n",
    "from GEMS_TCO import orderings as _orderings\n",
    "from GEMS_TCO import load_data\n",
    "\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import copy                    # clone tensor\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "from json import JSONEncoder\n",
    "\n",
    "import time\n",
<<<<<<< HEAD
<<<<<<< HEAD
    "\n",
=======
    "from line_profiler import LineProfiler\n",
    "     \n",
>>>>>>> 98fc71c474ddced6792e89e9ab27c07529da5b48
=======
    "from line_profiler import LineProfiler\n",
    "     \n",
>>>>>>> 0a418ac421c02a3cd32b6e4c97b2bdc92cdb79b7
    "# kernprof -l script_to_profile.py\n",
    "# C:\\Users\\joonw\\anaconda3\\envs\\faiss_env\\python.exe -m kernprof -l \"C:\\Users\\joonw\\tco\\GEMS_TCO-2\\Exercises\\make_vecc_faster.py\"  window\n",
    "# /opt/anaconda3/envs/faiss_env/bin/python /Users/joonwonlee/Documents/GEMS_TCO-1/Exercises/make_vecc_faster.py  mac  \n",
    "\n",
    "\n",
    "# df = pd.read_csv(\"C:/Users/joonw/tco/GEMS_TCO-2/Exercises/st_model/estimates/full_estimates_1250_july24.csv\")   # window\n",
    "\n",
<<<<<<< HEAD
<<<<<<< HEAD
    "v05_base_path = Path(\"/Users/joonwonlee/Documents/GEMS_TCO-1/outputs/day/estimates/df_cv_smooth_05/\")\n",
    "\n",
    "\n",
    "#full_day_r2s10_v045_spline1250 = pd.read_csv( base_path / \"full_day_r2s10_v045_spline1250.0.csv\")\n",
    "#full_day_r2s10_v055_spline1250 = pd.read_csv( base_path / \"full_day_r2s10_v055_spline1250.0.csv\")\n",
    "\n",
    "df= pd.read_csv(v05_base_path / \"full_day_v05_r2s10_1127.csv\")\n",
    "lat_lon_resolution = [1,1]\n",
=======
    "df = pd.read_csv(\"/Users/joonwonlee/Documents/GEMS_TCO-1/Exercises/st_model/estimates/full_estimates_1250_july24.csv\") \n",
    "\n",
    "lat_lon_resolution = [20,20]\n",
>>>>>>> 98fc71c474ddced6792e89e9ab27c07529da5b48
=======
    "df = pd.read_csv(\"/Users/joonwonlee/Documents/GEMS_TCO-1/Exercises/st_model/estimates/full_estimates_1250_july24.csv\") \n",
    "\n",
    "lat_lon_resolution = [20,20]\n",
>>>>>>> 0a418ac421c02a3cd32b6e4c97b2bdc92cdb79b7
    "years = ['2024']\n",
    "month_range =[7,8]\n",
    "nheads = 2\n",
    "\n",
    "for day in range(1,2):\n",
    "    print(f'\\n Day {day} data size per day: { (200/lat_lon_resolution[0])*(100/lat_lon_resolution[0])  } \\n')\n",
    "\n",
    "    # parameters\n",
    "    mm_cond_number = 10+day\n",
    "    idx_for_datamap= [ 8*(day-1),8*day]\n",
    "    # params = [ 27.25, 2.18, 2.294, 4.099e-4, -0.07915, 0.0999, 3.65]   #200\n",
    "    params = list(df.iloc[day-1][:-1])\n",
<<<<<<< HEAD
<<<<<<< HEAD
    "    params = params[5:-2]\n",
=======
>>>>>>> 98fc71c474ddced6792e89e9ab27c07529da5b48
=======
>>>>>>> 0a418ac421c02a3cd32b6e4c97b2bdc92cdb79b7
    "    params = torch.tensor(params, dtype=torch.float64, requires_grad=True)\n",
    "\n",
    "    # data\n",
    "    # input_path = Path(\"C:\\\\Users\\\\joonw\\\\tco\\\\Extracted_data\")  # window\n",
    "\n",
    "    input_path = Path(\"/Users/joonwonlee/Documents/GEMS_DATA\")  # mac\n",
    "    instance = load_data(input_path)\n",
    "    map, ord_mm, nns_map= instance.load_mm20k_data_bymonthyear( lat_lon_resolution= lat_lon_resolution, mm_cond_number=mm_cond_number,years_=years, months_=month_range)\n",
    "    analysis_data_map, aggregated_data = instance.load_working_data_byday( map, ord_mm, nns_map, idx_for_datamap= idx_for_datamap)\n",
    "\n",
    "\n",
    "    # different approximations\n",
    "    key_order = [0,1,2,4,3,5,7,6]\n",
    "    reordered_dict, reordered_df = instance.reorder_data(analysis_data_map, key_order)\n",
    "    instance_ori = kernels.vecchia_experiment(0.5, analysis_data_map, aggregated_data,nns_map,mm_cond_number, nheads)\n",
    "    instance = kernels.vecchia_experiment(0.5, reordered_dict, reordered_df, nns_map,mm_cond_number, nheads)\n",
    "\n",
    "    '''  \n",
    "    start_time = time.time()\n",
    "    out1 = instance.full_likelihood(params, aggregated_data[:,:4],aggregated_data[:,2], instance_ori.matern_cov_anisotropy_v05)\n",
    "    end_time = time.time()\n",
    "    epoch_time1 = end_time - start_time\n",
    "    print(f'full two lags: {out1} took {epoch_time1:.2f}') \n",
    "    '''\n",
    "\n",
<<<<<<< HEAD
<<<<<<< HEAD
    "    #instance_ori.cov_structure_saver(params, instance_ori.matern_cov_anisotropy_v05)\n"
=======
    "    instance_ori.cov_structure_saver(params, instance_ori.matern_cov_anisotropy_v05)\n"
>>>>>>> 98fc71c474ddced6792e89e9ab27c07529da5b48
=======
    "    instance_ori.cov_structure_saver(params, instance_ori.matern_cov_anisotropy_v05)\n"
>>>>>>> 0a418ac421c02a3cd32b6e4c97b2bdc92cdb79b7
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 11,
>>>>>>> 98fc71c474ddced6792e89e9ab27c07529da5b48
=======
   "execution_count": 11,
>>>>>>> 0a418ac421c02a3cd32b6e4c97b2bdc92cdb79b7
   "id": "b20d1958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
<<<<<<< HEAD
      "torch.Size([377568, 4])\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
=======
=======
>>>>>>> 0a418ac421c02a3cd32b6e4c97b2bdc92cdb79b7
      "vecc efficient: 667.0032594202934 took 0.08\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mvecc efficient: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout2\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m took \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch_time2\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m) \n\u001b[32m      7\u001b[39m start_time = time.time()\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m out2 = \u001b[43minstance_ori\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvecchia_efficient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstance_ori\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmatern_cov_anisotropy_v05\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m end_time = time.time()\n\u001b[32m     10\u001b[39m epoch_time2 = end_time - start_time\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GEMS_TCO-1/src/GEMS_TCO/kernels.py:922\u001b[39m, in \u001b[36mvecchia_experiment.vecchia_efficient\u001b[39m\u001b[34m(self, params, covariance_function)\u001b[39m\n\u001b[32m    920\u001b[39m     data_list.append(current_np[past])  \n\u001b[32m    921\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m time_idx < \u001b[32m2\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m922\u001b[39m     cov_matrix = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcov_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcov_matrix\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    923\u001b[39m     tmp1 = \u001b[38;5;28mself\u001b[39m.cov_map[(time_idx,index)][\u001b[33m'\u001b[39m\u001b[33mtmp1\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m    924\u001b[39m     cov_xx_inv = \u001b[38;5;28mself\u001b[39m.cov_map[(time_idx,index)][\u001b[33m'\u001b[39m\u001b[33mcov_xx_inv\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[31mTypeError\u001b[39m: list indices must be integers or slices, not str"
<<<<<<< HEAD
>>>>>>> 98fc71c474ddced6792e89e9ab27c07529da5b48
=======
>>>>>>> 0a418ac421c02a3cd32b6e4c97b2bdc92cdb79b7
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
<<<<<<< HEAD
    "#start_time = time.time()\n",
    "#out2 = instance_ori.vecchia_local_full_cond(params, instance_ori.matern_cov_anisotropy_v05)\n",
    "#end_time = time.time()\n",
    "#epoch_time2 = end_time - start_time\n",
    "#print(f'vecc efficient: {out2} took {epoch_time2:.2f}') \n",
    "\n",
    "start_time = time.time()\n",
    "out2 = instance_ori.full_likelihood(params, instance_ori.matern_cov_anisotropy_v05)\n",
    "end_time = time.time()\n",
    "epoch_time2 = end_time - start_time\n",
    "print(f'vecc efficient: {out2} took {epoch_time2:.2f}') \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d2d6ca",
   "metadata": {},
   "source": [
    "full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d03e508c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data shape: torch.Size([589680, 4])\n",
      "Subset data shape:   torch.Size([145008, 4])\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from typing import Callable\n",
    "\n",
    "# =========================================================================\n",
    "# 1. Helper Function for Subsetting\n",
    "# =========================================================================\n",
    "\n",
    "def subset_by_area(input_tensor: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Subsets a tensor to the specified lat/lon area.\n",
    "    Latitude between 0 and 5.\n",
    "    Longitude between 123 and 133.\n",
    "    \"\"\"\n",
    "    # Assumes columns are [lat, lon, value, time]\n",
    "    lat_col, lon_col = 0, 1\n",
    "    lat_mask = (input_tensor[:, lat_col] >= 0) & (input_tensor[:, lat_col] <= 5)\n",
    "    lon_mask = (input_tensor[:, lon_col] >= 123) & (input_tensor[:, lon_col] <= 133)\n",
    "    \n",
    "    df_sub = input_tensor[lat_mask & lon_mask].clone()\n",
    "    return df_sub\n",
    "\n",
    "# =========================================================================\n",
    "# 2. Covariance and Likelihood Functions\n",
    "# =========================================================================\n",
    "\n",
    "def custom_distance_matrix(U: torch.Tensor, V: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Efficient distance computation with broadcasting.\"\"\"\n",
    "    spatial_diff = torch.norm(U[:, :2].unsqueeze(1) - V[:, :2].unsqueeze(0), dim=2)\n",
    "    temporal_diff = torch.abs(U[:, 2].unsqueeze(1) - V[:, 2].unsqueeze(0))\n",
    "    distance = (spatial_diff**2 + temporal_diff**2)\n",
    "    return distance\n",
    "\n",
    "def precompute_coords_anisotropy(params: torch.Tensor, y_data: torch.Tensor, x_data: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Pre-computes transformed coordinates and the distance matrix.\"\"\"\n",
    "    sigmasq, range_lat, range_lon, advec_lat, advec_lon, beta, nugget = params\n",
    "\n",
    "    if y_data is None or x_data is None:\n",
    "        raise ValueError(\"Both y_data and x_data must be provided.\")\n",
    "\n",
    "    # Assumes columns are [lat, lon, value, time]\n",
    "    x1, y1, t1 = x_data[:, 0], x_data[:, 1], x_data[:, 3]\n",
    "    x2, y2, t2 = y_data[:, 0], y_data[:, 1], y_data[:, 3]\n",
    "\n",
    "    spat_coord1 = torch.stack(((x1 - advec_lat * t1) / range_lat, (y1 - advec_lon * t1) / range_lon), dim=-1)\n",
    "    spat_coord2 = torch.stack(((x2 - advec_lat * t2) / range_lat, (y2 - advec_lon * t2) / range_lon), dim=-1)\n",
    "\n",
    "    U = torch.cat((spat_coord1, (beta * t1).reshape(-1, 1)), dim=1)\n",
    "    V = torch.cat((spat_coord2, (beta * t2).reshape(-1, 1)), dim=1)\n",
    "\n",
    "    distance = custom_distance_matrix(U, V)\n",
    "    return distance\n",
    "\n",
    "def matern_cov_anisotropy_v05(params: torch.Tensor, x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Computes the Matérn covariance with v=0.5 (exponential).\"\"\"\n",
    "    sigmasq, range_lat, range_lon, advec_lat, advec_lon, beta, nugget = params\n",
    "    \n",
    "    distance = precompute_coords_anisotropy(params, x, y)\n",
    "    out = torch.zeros_like(distance)\n",
    "\n",
    "    non_zero_indices = distance != 0\n",
    "    if torch.any(non_zero_indices):\n",
    "        out[non_zero_indices] = sigmasq * torch.exp(-torch.sqrt(distance[non_zero_indices]))\n",
    "    out[~non_zero_indices] = sigmasq\n",
    "\n",
    "    # Add nugget/jitter only to the diagonal of the main covariance matrix\n",
    "    if torch.equal(x, y):\n",
    "        out += torch.eye(out.shape[0], dtype=out.dtype) * nugget \n",
    "    return out\n",
    "           \n",
    "def full_likelihood(params: torch.Tensor, input_data: torch.Tensor, response: torch.Tensor, covariance_function: Callable) -> torch.Tensor:\n",
    "    \"\"\"Calculates the full Gaussian negative log-likelihood.\"\"\"\n",
    "    cov_matrix = covariance_function(params=params, y=input_data, x=input_data)\n",
    "    sign, log_det = torch.slogdet(cov_matrix)\n",
    "\n",
    "    # The design matrix 'X' in GLM, here just the spatial locations\n",
    "    locs = input_data[:, :2]\n",
    "\n",
    "    # Compute beta (trend coefficients)\n",
    "    tmp1 = torch.matmul(locs.T, torch.linalg.solve(cov_matrix, locs))\n",
    "    tmp2 = torch.matmul(locs.T, torch.linalg.solve(cov_matrix, response))\n",
    "    beta_coeffs = torch.linalg.solve(tmp1, tmp2)\n",
    "\n",
    "    # Compute the mean and residuals\n",
    "    mu = torch.matmul(locs, beta_coeffs)\n",
    "    y_mu = response - mu\n",
    "\n",
    "    # Compute the quadratic form\n",
    "    quad_form = torch.matmul(y_mu, torch.linalg.solve(cov_matrix, y_mu))\n",
    "\n",
    "    # Compute the negative log likelihood\n",
    "    neg_log_lik = 0.5 * (log_det + quad_form)\n",
    "    return neg_log_lik \n",
    "\n",
    "# =========================================================================\n",
    "# 3. Main Execution Block\n",
    "# =========================================================================\n",
    "if __name__ == '__main__':\n",
    "    # --- 1. Define your parameters and load your data ---\n",
    "    \n",
    "    # Example parameters (on their natural scale)\n",
    "    params = torch.tensor([25.0, 3.0, 4.0, 0.02, -0.08, 0.02, 3.01], dtype=torch.float64)\n",
    "\n",
    "    # ⚠️ ASSUMPTION: 'df_day_aggregated_list' is loaded and available here.\n",
    "    # For example:\n",
    "    # with open(\"path_to_your_data.pkl\", 'rb') as f:\n",
    "    #     df_day_aggregated_list = pickle.load(f)\n",
    "    \n",
    "    # Use the first tensor from your data list\n",
    "    raw_data = df_day_aggregated_list[0].to(torch.float64) # Ensure data is float64 for precision\n",
    "\n",
    "    # --- 2. Subset the data to the desired area ---\n",
    "    print(f\"Original data shape: {raw_data.shape}\")\n",
    "    subset_data = subset_by_area(raw_data)\n",
    "    print(f\"Subset data shape:   {subset_data.shape}\")\n",
    "\n",
    "    # --- 3. Calculate the full likelihood on the subset ---\n",
    "    if subset_data.shape[0] > 0:\n",
    "        # The 'response' is the ozone column (index 2) of the subsetted data\n",
    "        response_y = subset_data[:, 2]\n",
    "\n",
    "        neg_log_lik_result = full_likelihood(\n",
    "            params=params, \n",
    "            input_data=subset_data, \n",
    "            response=response_y, \n",
    "            covariance_function=matern_cov_anisotropy_v05\n",
    "        )\n",
    "\n",
    "        print(f\"\\nCalculated Negative Log Likelihood: {neg_log_lik_result.item():.4f}\")\n",
    "    else:\n",
    "        print(\"\\nNo data points found in the specified area.\")"
=======
=======
>>>>>>> 0a418ac421c02a3cd32b6e4c97b2bdc92cdb79b7
    "start_time = time.time()\n",
    "out2 = instance_ori.vecchia_b2_cache(params, instance_ori.matern_cov_anisotropy_v05)\n",
    "end_time = time.time()\n",
    "epoch_time2 = end_time - start_time\n",
    "print(f'vecc efficient: {out2} took {epoch_time2:.2f}') \n",
    "\n",
    "start_time = time.time()\n",
    "out2 = instance_ori.vecchia_efficient(params, instance_ori.matern_cov_anisotropy_v05)\n",
    "end_time = time.time()\n",
    "epoch_time2 = end_time - start_time\n",
    "print(f'vecc efficient: {out2} took {epoch_time2:.2f}') "
<<<<<<< HEAD
>>>>>>> 98fc71c474ddced6792e89e9ab27c07529da5b48
=======
>>>>>>> 0a418ac421c02a3cd32b6e4c97b2bdc92cdb79b7
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "faiss_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
<<<<<<< HEAD
   "version": "3.12.3"
=======
   "version": "3.12.9"
>>>>>>> 98fc71c474ddced6792e89e9ab27c07529da5b48
=======
   "version": "3.12.9"
>>>>>>> 0a418ac421c02a3cd32b6e4c97b2bdc92cdb79b7
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
