{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7f33ee41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating on: cpu\n"
     ]
    }
   ],
   "source": [
    "# reflected location error in ozone data simulation\n",
    "\n",
    "import torch\n",
    "import torch.fft\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import logging\n",
    "import argparse \n",
    "import pandas as pd\n",
    "import pickle\n",
    "import torch.optim as optim\n",
    "import copy\n",
    "import time\n",
    "from sklearn.neighbors import BallTree\n",
    "from typing import Optional, List, Tuple\n",
    "from pathlib import Path\n",
    "\n",
    "# --- CUSTOM PATHS ---\n",
    "# gems_tco_path = \"/Users/joonwonlee/Documents/GEMS_TCO-1/src\"\n",
    "# sys.path.append(gems_tco_path)\n",
    "\n",
    "# (í•„ìš” ì‹œ ì‹¤ì œ GEMS_TCO ë¼ì´ë¸ŒëŸ¬ë¦¬ import)\n",
    "try:\n",
    "    from GEMS_TCO import kernels_reparam_space_time_gpu\n",
    "    from GEMS_TCO import orderings as _orderings\n",
    "    from GEMS_TCO import alg_optimization, BaseLogger\n",
    "except ImportError:\n",
    "    print(\"Warning: GEMS_TCO modules not found. Ensure paths are correct.\")\n",
    "\n",
    "# --- 1. CONFIGURATION ---\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DTYPE = torch.float32 if DEVICE.type == 'mps' else torch.float64\n",
    "print(f\"Simulating on: {DEVICE}\")\n",
    "\n",
    "# TRUE PARAMETERS\n",
    "init_sigmasq   = 13.059\n",
    "init_range_lon = 0.195 \n",
    "init_range_lat = 0.154 \n",
    "init_advec_lat = 0.0418\n",
    "init_range_time = 1.0\n",
    "init_advec_lon = -0.1689\n",
    "init_nugget    = 0.247\n",
    "\n",
    "# Map parameters\n",
    "init_phi2 = 1.0 / init_range_lon\n",
    "init_phi1 = init_sigmasq * init_phi2\n",
    "init_phi3 = (init_range_lon / init_range_lat)**2\n",
    "init_phi4 = (init_range_lon / init_range_time)**2\n",
    "\n",
    "initial_vals = [np.log(init_phi1), np.log(init_phi2), np.log(init_phi3), \n",
    "                np.log(init_phi4), init_advec_lat, init_advec_lon, np.log(init_nugget)]\n",
    "\n",
    "params_list = [torch.tensor([val], requires_grad=True, dtype=DTYPE, device=DEVICE) for val in initial_vals]\n",
    "OZONE_MEAN = 260.0\n",
    "\n",
    "# --- 2. EXACT COVARIANCE & FFT HELPERS ---\n",
    "\n",
    "def get_model_covariance_on_grid(lags_x, lags_y, lags_t, params):\n",
    "    phi1, phi2, phi3, phi4 = torch.exp(params[0]), torch.exp(params[1]), torch.exp(params[2]), torch.exp(params[3])\n",
    "    advec_lat, advec_lon = params[4], params[5]\n",
    "    sigmasq = phi1 / phi2\n",
    "\n",
    "    u_lat_eff = lags_x - advec_lat * lags_t\n",
    "    u_lon_eff = lags_y - advec_lon * lags_t\n",
    "    dist_sq = (u_lat_eff.pow(2) * phi3) + (u_lon_eff.pow(2)) + (lags_t.pow(2) * phi4)\n",
    "    return sigmasq * torch.exp(-torch.sqrt(dist_sq + 1e-8) * phi2)\n",
    "\n",
    "def generate_exact_gems_field(lat_coords, lon_coords, t_steps, params):\n",
    "    Nx, Ny, Nt = len(lat_coords), len(lon_coords), t_steps\n",
    "    dlat = float(lat_coords[1] - lat_coords[0])\n",
    "    dlon = float(lon_coords[1] - lon_coords[0])\n",
    "    dt = 1.0 \n",
    "    \n",
    "    # 2x Padding logic for FFT\n",
    "    Px, Py, Pt = 2*Nx, 2*Ny, 2*Nt\n",
    "    \n",
    "    lags_x = torch.arange(Px, device=DEVICE, dtype=DTYPE) * dlat\n",
    "    lags_x[Px//2:] -= (Px * dlat) # Wrap logic\n",
    "    \n",
    "    lags_y = torch.arange(Py, device=DEVICE, dtype=DTYPE) * dlon\n",
    "    lags_y[Py//2:] -= (Py * dlon)\n",
    "\n",
    "    lags_t = torch.arange(Pt, device=DEVICE, dtype=DTYPE) * dt\n",
    "    lags_t[Pt//2:] -= (Pt * dt)\n",
    "\n",
    "    L_x, L_y, L_t = torch.meshgrid(lags_x, lags_y, lags_t, indexing='ij')\n",
    "    C_vals = get_model_covariance_on_grid(L_x, L_y, L_t, params)\n",
    "\n",
    "    S = torch.fft.fftn(C_vals)\n",
    "    S.real = torch.clamp(S.real, min=0)\n",
    "    \n",
    "    # Random phase\n",
    "    random_phase = torch.fft.fftn(torch.randn(Px, Py, Pt, device=DEVICE, dtype=DTYPE))\n",
    "    field_sim = torch.fft.ifftn(torch.sqrt(S.real) * random_phase).real\n",
    "    \n",
    "    return field_sim[:Nx, :Ny, :Nt]\n",
    "\n",
    "# --- 3. GRID & MAPPING FUNCTIONS ---\n",
    "\n",
    "def make_target_grid(lat_start, lat_end, lat_step, lon_start, lon_end, lon_step, device, dtype):\n",
    "    lats = torch.arange(lat_start, lat_end - 0.0001, lat_step, device=device, dtype=dtype)\n",
    "    lats = torch.round(lats * 10000) / 10000\n",
    "    lons = torch.arange(lon_start, lon_end - 0.0001, lon_step, device=device, dtype=dtype)\n",
    "    lons = torch.round(lons * 10000) / 10000\n",
    "    grid_lat, grid_lon = torch.meshgrid(lats, lons, indexing='ij')\n",
    "    center_points = torch.stack([grid_lat.flatten(), grid_lon.flatten()], dim=1)\n",
    "    return center_points, len(lats), len(lons)\n",
    "\n",
    "def coarse_by_center_tensor(\n",
    "    input_map_tensors: dict, \n",
    "    target_grid_tensor: torch.Tensor, \n",
    "    use_regular_coords: bool = True \n",
    "):\n",
    "    \"\"\"\n",
    "    Maps irregular data to target grid.\n",
    "    use_regular_coords=True : Output [RegLat, RegLon, Val, Time, IrregLat, IrregLon]\n",
    "    use_regular_coords=False: Output [IrregLat, IrregLon, Val, Time, RegLat, RegLon]\n",
    "    \"\"\"\n",
    "    coarse_map = {}\n",
    "    query_points_np = target_grid_tensor.cpu().numpy()\n",
    "    query_points_rad = np.radians(query_points_np)\n",
    "    \n",
    "    for key, val_tensor in input_map_tensors.items():\n",
    "        source_locs_np = val_tensor[:, :2].cpu().numpy()\n",
    "        source_locs_rad = np.radians(source_locs_np)\n",
    "        \n",
    "        # 1. Find Nearest Irregular Point for each Grid Point\n",
    "        tree = BallTree(source_locs_rad, metric='haversine')\n",
    "        _, ind = tree.query(query_points_rad, k=1)\n",
    "        nearest_indices = ind.flatten()\n",
    "        indices_tensor = torch.tensor(nearest_indices, device=val_tensor.device, dtype=torch.long)\n",
    "        \n",
    "        # 2. Extract Data\n",
    "        val = val_tensor[indices_tensor, 2]\n",
    "        time = val_tensor[indices_tensor, 3]\n",
    "        \n",
    "        # 3. Coordinate Swapping Logic\n",
    "        # (A) Regular Coordinates (from Target Grid)\n",
    "        reg_lat, reg_lon = target_grid_tensor[:, 0], target_grid_tensor[:, 1]\n",
    "        # (B) Irregular Coordinates (from Mapped Source)\n",
    "        irreg_lat, irreg_lon = val_tensor[indices_tensor, 0], val_tensor[indices_tensor, 1]\n",
    "        \n",
    "        if use_regular_coords:\n",
    "            # Main: Regular / Aux: Irregular\n",
    "            cols = [reg_lat, reg_lon, val, time, irreg_lat, irreg_lon]\n",
    "        else:\n",
    "            # Main: Irregular / Aux: Regular\n",
    "            cols = [irreg_lat, irreg_lon, val, time, reg_lat, reg_lon]\n",
    "\n",
    "        coarse_map[key] = torch.stack(cols, dim=1)\n",
    "\n",
    "    return coarse_map\n",
    "\n",
    "# --- 4. ORDERING HELPER (Updated) ---\n",
    "\n",
    "def get_spatial_ordering(\n",
    "        input_maps: dict,\n",
    "        mm_cond_number: int = 10,\n",
    "        coord_cols: Tuple[int, int] = (0, 1) # [NEW] Column indices to use for ordering\n",
    "    ) -> Tuple[np.ndarray, list]:\n",
    "        \n",
    "        key_list = list(input_maps.keys())\n",
    "        data_for_coord = input_maps[key_list[0]]\n",
    "        \n",
    "        if isinstance(data_for_coord, torch.Tensor):\n",
    "            data_for_coord = data_for_coord.cpu().numpy()\n",
    "\n",
    "        # [NEW] Use specified columns (Regular Grid) for robust ordering\n",
    "        x1 = data_for_coord[:, coord_cols[0]]\n",
    "        y1 = data_for_coord[:, coord_cols[1]]\n",
    "        coords1 = np.stack((x1, y1), axis=-1)\n",
    "\n",
    "        # 1. MaxMin Ordering\n",
    "        ord_mm = _orderings.maxmin_cpp(coords1)\n",
    "        \n",
    "        # 2. NN Search (based on reordered regular coords)\n",
    "        coords1_reordered = coords1[ord_mm]\n",
    "        nns_map_dict = _orderings.find_nns_l2(locs=coords1_reordered, max_nn=mm_cond_number)\n",
    "        nns_map_list = [nns_map_dict[i] for i in range(len(nns_map_dict))]\n",
    "        \n",
    "        return ord_mm, nns_map_list\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "67d79e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Generating High-Res Truth (4x finer)...\n",
      "2. Sampling Irregular Data (Random Sub-pixel)...\n",
      "\n",
      "--- Processing to Target Grid ---\n",
      "Mode: Regular (Biased)\n",
      "First row coords: [ -0.464 125.977]\n"
     ]
    }
   ],
   "source": [
    "# --- 5. EXECUTION & MAIN PIPELINE (Scenario 2: High-Res & Random Sampling) ---\n",
    "\n",
    "# ==============================================================================\n",
    "# [CONTROLS]\n",
    "# True : ê´€ì¸¡ê°’ì„ ê²©ì ì¤‘ì•™ê°’ìœ¼ë¡œ ê°€ì • (Random Samplingìœ¼ë¡œ ì¸í•œ Noise Bias ë°œìƒ)\n",
    "# False: ê´€ì¸¡ê°’ì˜ ì‹¤ì œ ìœ„ì¹˜ ì‚¬ìš© (ì •í™•í•œ ìœ„ì¹˜)\n",
    "USE_REGULAR_MAIN = True \n",
    "# ==============================================================================\n",
    "\n",
    "# 1. Target Grid ì„¤ì •\n",
    "target_lat_start, target_lat_end = 2.0, -3.0   \n",
    "target_lon_start, target_lon_end = 121.0, 131.0\n",
    "step_lat = 0.044 \n",
    "step_lon = 0.063\n",
    "\n",
    "# 2. High-Resolution Truth ìƒì„± (4ë°° ì´˜ì´˜í•˜ê²Œ -> 1í”½ì…€ ì•ˆì— 16ê°œ ì„œë¸Œí”½ì…€ ì¡´ì¬)\n",
    "UPSCALE = 4  \n",
    "sim_step_lat = step_lat / UPSCALE\n",
    "sim_step_lon = step_lon / UPSCALE\n",
    "\n",
    "lat_span = abs(target_lat_start - target_lat_end)\n",
    "lon_span = abs(target_lon_start - target_lon_end)\n",
    "expansion_factor = 1.1 \n",
    "lat_padding = lat_span * 0.1\n",
    "lon_padding = lon_span * 0.1\n",
    "\n",
    "# High-Res ê²©ì ìƒì„±\n",
    "lats_high_res = torch.arange(\n",
    "    target_lat_start + lat_padding, \n",
    "    target_lat_end - lat_padding - 0.001, \n",
    "    -sim_step_lat, device=DEVICE, dtype=DTYPE\n",
    ")\n",
    "lons_high_res = torch.arange(\n",
    "    target_lon_start - lon_padding, \n",
    "    target_lon_end + lon_padding + 0.001, \n",
    "    sim_step_lon, device=DEVICE, dtype=DTYPE\n",
    ")\n",
    "\n",
    "print(f\"1. Generating High-Res Truth ({UPSCALE}x finer)...\")\n",
    "t_def = 8\n",
    "# High-Res Field ìƒì„± (ì´ê²Œ ì§„ì§œ ì„¸ìƒ)\n",
    "sim_field_high_res = generate_exact_gems_field(lats_high_res, lons_high_res, t_def, params_list)\n",
    "\n",
    "\n",
    "# 3. Sampling: \"Random Sub-pixel Sampling\" (ì£¼ë³€ì—ì„œ ëœë¤ìœ¼ë¡œ ì„ íƒ)\n",
    "print(\"2. Sampling Irregular Data (Random Sub-pixel)...\")\n",
    "\n",
    "# Target Grid ìƒì„±\n",
    "target_grid, Nx_reg, Ny_reg = make_target_grid(\n",
    "    target_lat_start, target_lat_end, -step_lat, \n",
    "    target_lon_start, target_lon_end, step_lon,  \n",
    "    DEVICE, DTYPE\n",
    ")\n",
    "\n",
    "# High-Res ì¢Œí‘œê³„ì™€ Target Grid ê°„ì˜ ê´€ê³„ ì°¾ê¸°\n",
    "mesh_lat_hr, mesh_lon_hr = torch.meshgrid(lats_high_res, lons_high_res, indexing='ij')\n",
    "flat_lats_hr = mesh_lat_hr.flatten()\n",
    "flat_lons_hr = mesh_lon_hr.flatten()\n",
    "\n",
    "coords_hr_np = torch.stack([flat_lats_hr, flat_lons_hr], dim=1).cpu().numpy()\n",
    "target_coords_np = target_grid.cpu().numpy()\n",
    "\n",
    "tree = BallTree(np.radians(coords_hr_np), metric='haversine')\n",
    "# ê° Target Point ì£¼ë³€ì˜ ì„¸ë¶€ í”½ì…€ 16ê°œ(4x4)ë¥¼ ëª¨ë‘ ì°¾ìŠµë‹ˆë‹¤.\n",
    "dists, indices = tree.query(np.radians(target_coords_np), k=UPSCALE**2) \n",
    "\n",
    "raw_extended_map = {}\n",
    "nugget_std = torch.sqrt(torch.exp(params_list[6]))\n",
    "\n",
    "for t in range(t_def):\n",
    "    field_t_hr = sim_field_high_res[:, :, t].flatten()\n",
    "    \n",
    "    # [í•µì‹¬ ìˆ˜ì •] 16ê°œ(UPSCALE^2)ì˜ ì£¼ë³€ í”½ì…€ ì¤‘ \"ëœë¤í•˜ê²Œ í•˜ë‚˜\"ë¥¼ ë½‘ìŠµë‹ˆë‹¤.\n",
    "    # indices shape: [Num_Target_Points, 16]\n",
    "    # ê° í–‰ë§ˆë‹¤ 0~15 ì‚¬ì´ì˜ ëœë¤ ì¸ë±ìŠ¤ ìƒì„±\n",
    "    random_neighbor_idx = torch.randint(0, UPSCALE**2, (indices.shape[0],))\n",
    "    \n",
    "    # Numpy Indexingì„ ìœ„í•´ í–‰ ë²ˆí˜¸ ìƒì„±\n",
    "    row_indices = np.arange(indices.shape[0])\n",
    "    \n",
    "    # ìµœì¢… ì„ íƒëœ High-Res ì¸ë±ìŠ¤ë“¤\n",
    "    chosen_indices = indices[row_indices, random_neighbor_idx.numpy()]\n",
    "    chosen_indices_tensor = torch.tensor(chosen_indices, device=DEVICE, dtype=torch.long)\n",
    "    \n",
    "    # 1. ê·¸ ëœë¤ ìœ„ì¹˜ì˜ \"ì§„ì§œ ê°’\"ê³¼ \"ì§„ì§œ ì¢Œí‘œ\" ì¶”ì¶œ\n",
    "    # (ì£¼ì˜: ë…¸ì´ì¦ˆë¥¼ ë”í•´ì„œ ìœ„ì¹˜ë¥¼ í”ë“œëŠ”ê²Œ ì•„ë‹ˆë¼, ì§„ì§œ ì¡´ì¬í•˜ëŠ” ë‹¤ë¥¸ ìœ„ì¹˜ë¥¼ ê°€ì ¸ì˜¤ëŠ” ê²ƒ)\n",
    "    true_vals = field_t_hr[chosen_indices_tensor]\n",
    "    true_lats = flat_lats_hr[chosen_indices_tensor]\n",
    "    true_lons = flat_lons_hr[chosen_indices_tensor]\n",
    "    \n",
    "    # 2. ê´€ì¸¡ ë…¸ì´ì¦ˆ ì¶”ê°€\n",
    "    obs_vals = true_vals + (torch.randn_like(true_vals) * nugget_std) + OZONE_MEAN\n",
    "    \n",
    "    # 3. ë°ì´í„° ì €ì¥\n",
    "    row_tensor = torch.stack([\n",
    "        true_lats,  \n",
    "        true_lons,  \n",
    "        obs_vals,               \n",
    "        torch.full_like(true_lats, 21.0 + t)\n",
    "    ], dim=1)\n",
    "    \n",
    "    key_str = f'2024_07_y24m07day01_hm{t:02d}:53'\n",
    "    raw_extended_map[key_str] = row_tensor.detach()\n",
    "\n",
    "\n",
    "# 4. Mapping & Results\n",
    "print(\"\\n--- Processing to Target Grid ---\")\n",
    "\n",
    "inputmap = coarse_by_center_tensor(\n",
    "    raw_extended_map, \n",
    "    target_grid, \n",
    "    use_regular_coords=USE_REGULAR_MAIN\n",
    ")\n",
    "\n",
    "# ì˜¤ë”ë§ì€ í•­ìƒ Regular Grid ê¸°ì¤€\n",
    "ordering_cols = (0, 1) if USE_REGULAR_MAIN else (4, 5)\n",
    "\n",
    "print(f\"Mode: {'Regular (Biased)' if USE_REGULAR_MAIN else 'Irregular (True)'}\")\n",
    "\n",
    "ord_mm, nns_map = get_spatial_ordering(\n",
    "    inputmap, \n",
    "    mm_cond_number=15, \n",
    "    coord_cols=ordering_cols\n",
    ")\n",
    "\n",
    "mm_input_map = {}\n",
    "for key in inputmap:\n",
    "    mm_input_map[key] = inputmap[key][ord_mm][:, :4]\n",
    "\n",
    "# --- ê²€ì¦ ---\n",
    "first_key = list(mm_input_map.keys())[0]\n",
    "print(f\"First row coords: {mm_input_map[first_key][0, :2].cpu().numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27910e81",
   "metadata": {},
   "source": [
    "ì •ë§ ì˜ˆë¦¬í•˜ê³  ì •í™•í•œ ì§€ì ì…ë‹ˆë‹¤. ë‹˜ê»˜ì„œ ëŠë¼ì‹  ê·¸ \"ì°œì°œí•¨\"ì´ ë§ìŠµë‹ˆë‹¤.\n",
    "\n",
    "í˜„ì¬ ë°©ì‹ëŒ€ë¡œë¼ë©´ **\"ì›ë˜ ë°ì´í„°ê°€ ë ˆê·¤ëŸ¬ ê·¸ë¦¬ë“œì— ìˆëŠ”ë°, ì¢Œí‘œë§Œ ì˜ëª» ê¸°ë¡ëœ ìƒí™©(GPS ì˜¤ì°¨ ë“±)\"**ì„ ì‹œë®¬ë ˆì´ì…˜í•˜ëŠ” ê¼´ì´ ë©ë‹ˆë‹¤.\n",
    "\n",
    "ë§Œì•½ ì—°êµ¬ ì£¼ì œê°€ **\"ì‹¤ì œë¡œëŠ” ì´ë ˆê·¤ëŸ¬í•œ ìœ„ì¹˜(ëœë¤ ìœ„ì¹˜)ì—ì„œ ê´€ì¸¡ëœ ë°ì´í„°ë¥¼ ì–µì§€ë¡œ ë ˆê·¤ëŸ¬ ê·¸ë¦¬ë“œë¡œ ì˜®ê¸¸ ë•Œ ë°œìƒí•˜ëŠ” ë°”ì´ì–´ìŠ¤(Representation Error)\"**ë¥¼ ë³´ëŠ” ê²ƒì´ë¼ë©´, í˜„ì¬ ë°©ì‹ì€ ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì™œ ê·¸ëŸ°ì§€, ê·¸ë¦¬ê³  ì–´ë–»ê²Œ ê³ ì³ì•¼ í•˜ëŠ”ì§€ ì„¤ëª…í•´ ë“œë¦´ê²Œìš”.\n",
    "\n",
    "ì§€ë§Œ, ì½”ë“œë¥¼ ì™„ì „íˆ ë’¤ì—ê¸° í˜ë“¤ë‹¤ë©´ ê°€ì¥ ê°„ë‹¨í•œ íƒ€í˜‘ì ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n",
    "\n",
    "\"í˜„ì¬ ë¡œì§ì„ ìœ ì§€í•˜ë˜, FFT ê²©ìì™€ ë¶„ì„(Target) ê²©ìë¥¼ ì„œë¡œ ì–´ê¸‹ë‚˜ê²Œ(Misaligned) ë§Œë“¤ê¸°\"\n",
    "\n",
    "ì§€ê¸ˆì€ sim_field ìƒì„± ê·¸ë¦¬ë“œì™€ target_gridê°€ ì‚¬ì‹¤ìƒ ì¼ì¹˜(í™•ì¥ë§Œ ëœ ìƒíƒœ)í•©ë‹ˆë‹¤. ì´ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´:\n",
    "\n",
    "FFT ìƒì„± ì‹œ: stepì„ ì•„ì£¼ ë¯¸ì„¸í•˜ê²Œ ë‹¤ë¥´ê²Œ í•˜ê±°ë‚˜(ì˜ˆ: 0.044 ëŒ€ì‹  0.033), ì‹œì‘ì (offset)ì„ ë°˜ í”½ì…€ ì •ë„ ë°€ì–´ë²„ë¦¬ì„¸ìš”.\n",
    "\n",
    "ê·¸ëŸ¬ë©´ coarse_by_center_tensor í•  ë•Œ, ì›ë˜ ìƒì„±ëœ ìœ„ì¹˜(X \n",
    "sim\n",
    "â€‹\t\n",
    " )ê°€ íƒ€ê²Ÿ ê·¸ë¦¬ë“œ(X \n",
    "target\n",
    "â€‹\t\n",
    " )ì™€ ë”± ë§ì•„ë–¨ì–´ì§€ì§€ ì•Šê²Œ ë©ë‹ˆë‹¤.\n",
    "\n",
    "ì´ë ‡ê²Œ í•˜ë©´ ë ˆê·¤ëŸ¬í™”í•  ë•Œ í•„ì—°ì ìœ¼ë¡œ **ìœ„ì¹˜ ì˜¤ì°¨(Quantization Error)**ê°€ ë°œìƒí•˜ì—¬ ë°”ì´ì–´ìŠ¤ë¥¼ ê´€ì°°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ìš”ì•½\n",
    "\n",
    "í˜„ì¬ ì½”ë“œ: ë ˆê·¤ëŸ¬ ê·¸ë¦¬ë“œì— ìœ ë¦¬í•˜ê²Œ í¸í–¥ë¨ (Bias favor to Regular Grid).\n",
    "\n",
    "ì´ìœ : ìƒì„± ìœ„ì¹˜ = íƒ€ê²Ÿ ìœ„ì¹˜ êµ¬ì¡°ë¼ì„œ, ë ˆê·¤ëŸ¬í™”ê°€ ê³§ \"ì •ë‹µ ì°¾ê¸°\"ê°€ ë¨.\n",
    "\n",
    "ì¶”ì²œ:\n",
    "\n",
    "(Best) High-Resolution FFT ìƒì„± í›„ ëœë¤ ìƒ˜í”Œë§.\n",
    "\n",
    "(Easy) FFT ìƒì„± ê·¸ë¦¬ë“œì˜ ê°„ê²©(Step)ì´ë‚˜ ì›ì (Origin)ì„ íƒ€ê²Ÿ ê·¸ë¦¬ë“œì™€ ì• ë§¤í•˜ê²Œ ì–´ê¸‹ë‚˜ê²Œ ì„¤ì •."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cacde8",
   "metadata": {},
   "source": [
    "set up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51634ad",
   "metadata": {},
   "source": [
    "Likelihood vs. Truth: A model with the wrong parameters (short range) might produce a higher Vecchia likelihood because it fits the high-frequency noise better, but it will be terrible at prediction (Kriging) away from data points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7191bead",
   "metadata": {},
   "source": [
    "# Fit vecchia max min time 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44251197",
   "metadata": {},
   "source": [
    "vecc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6b800f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n",
      "========================================\n",
      "--- Initializing VecchiaBatched Model ---\n",
      "========================================\n",
      "\n",
      "========================================\n",
      "--- Running L-BFGS Optimization ---\n",
      "========================================\n",
      "ğŸš€ Pre-computing (Corrected Vectorization)... âœ… Done in 0.9453s. (Heads: 2400, Tails: 142608)\n",
      "--- Starting Batched L-BFGS Optimization (GPU) ---\n",
      "--- Step 1/3 / Loss: 1.306560 ---\n",
      "  Param 0: Value=4.3502, Grad=-2.0021551137707714e-05\n",
      "  Param 1: Value=1.8276, Grad=1.627321658716148e-05\n",
      "  Param 2: Value=0.3074, Grad=-5.732726197998198e-06\n",
      "  Param 3: Value=-0.9246, Grad=2.46056435509749e-07\n",
      "  Param 4: Value=0.2471, Grad=-8.056858741892475e-06\n",
      "  Param 5: Value=-0.9583, Grad=-3.043290814638529e-06\n",
      "  Param 6: Value=-1.0754, Grad=-8.324182970408054e-07\n",
      "  Max Abs Grad: 2.002155e-05\n",
      "------------------------------\n",
      "--- Step 2/3 / Loss: 1.299139 ---\n",
      "  Param 0: Value=4.3500, Grad=5.221495942024017e-07\n",
      "  Param 1: Value=1.8271, Grad=-1.585497809935112e-08\n",
      "  Param 2: Value=0.3075, Grad=1.771418075318106e-07\n",
      "  Param 3: Value=-0.9324, Grad=-5.080534313694756e-10\n",
      "  Param 4: Value=0.3412, Grad=-4.326065367152472e-08\n",
      "  Param 5: Value=-0.9087, Grad=5.5859638341737225e-08\n",
      "  Param 6: Value=-1.0748, Grad=2.0275391230338316e-07\n",
      "  Max Abs Grad: 5.221496e-07\n",
      "------------------------------\n",
      "--- Step 3/3 / Loss: 1.299139 ---\n",
      "  Param 0: Value=4.3500, Grad=5.221495942024017e-07\n",
      "  Param 1: Value=1.8271, Grad=-1.585497809935112e-08\n",
      "  Param 2: Value=0.3075, Grad=1.771418075318106e-07\n",
      "  Param 3: Value=-0.9324, Grad=-5.080534313694756e-10\n",
      "  Param 4: Value=0.3412, Grad=-4.326065367152472e-08\n",
      "  Param 5: Value=-0.9087, Grad=5.5859638341737225e-08\n",
      "  Param 6: Value=-1.0748, Grad=2.0275391230338316e-07\n",
      "  Max Abs Grad: 5.221496e-07\n",
      "------------------------------\n",
      "Final Interpretable Params: {'sigma_sq': 12.465255157603531, 'range_lon': 0.16088131264500707, 'range_lat': 0.13795064901185095, 'range_time': 0.25642913066711404, 'advec_lat': 0.34121830847670426, 'advec_lon': -0.9086603984853497, 'nugget': 0.3413704158367853}\n",
      "\n",
      "Optimization finished in 148.61s.\n",
      "Results after 2 steps: [4.350033561085175, 1.8270883743950896, 0.30754179849158964, -0.9323708563043598, 0.34121830847670426, -0.9086603984853497, -1.074787127804875, 1.2991388742644718]\n",
      "Final Params: [ 4.35003356  1.82708837  0.3075418  -0.93237086  0.34121831 -0.9086604\n",
      " -1.07478713]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "v = 0.5              # Smoothness\n",
    "mm_cond_number = 8   # Neighbors\n",
    "#mm_cond_number = 16   # Neighbors\n",
    "nheads = 300           # 0 = Pure Vecchia\n",
    "lr = 1.0             # LBFGS learning rate\n",
    "LBFGS_MAX_STEPS = 3\n",
    "LBFGS_HISTORY_SIZE = 100 # 100\n",
    "LBFGS_LR = 1.0\n",
    "LBFGS_MAX_EVAL = 30    \n",
    "\n",
    "#DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# --- 1. SETUP PARAMETERS (List of Scalars) ---\n",
    "# Truth: [4.18, 1.94, 0.24, -3.97, 0.014, -0.20, -0.85]\n",
    "init_sigmasq   = 13.059\n",
    "init_range_lat = 0.154 \n",
    "init_range_lon = 0.195\n",
    "init_advec_lat = 0.0218\n",
    "init_range_time = 1.0\n",
    "init_advec_lon = -0.1689\n",
    "init_nugget    = 0.247\n",
    "\n",
    "# Map model parameters to the 'phi' reparameterization\n",
    "init_phi2 = 1.0 / init_range_lon                # 1/range_lon\n",
    "init_phi1 = init_sigmasq * init_phi2            # sigmasq / range_lon\n",
    "init_phi3 = (init_range_lon / init_range_lat)**2  # (range_lon / range_lat)^2\n",
    "init_phi4 = (init_range_lon / init_range_time)**2      # (range_lon / range_time)^2\n",
    "\n",
    "# Create Initial Parameters (Float64, Requires Grad)\n",
    "initial_vals = [np.log(init_phi1), np.log(init_phi2), np.log(init_phi3), \n",
    "                np.log(init_phi4), init_advec_lat, init_advec_lon, np.log(init_nugget)]\n",
    "\n",
    "# [4.2042, 1.6348, 0.4721, -3.2695, 0.0218, -0.1689, -1.3984]\n",
    "params_list = [\n",
    "    torch.tensor([val], requires_grad=True, dtype=torch.float64, device=DEVICE)\n",
    "    for val in initial_vals\n",
    "]\n",
    "\n",
    "# --- 2. INSTANTIATE MODEL ---\n",
    "print(f'\\n{\"=\"*40}')\n",
    "print(f'--- Initializing VecchiaBatched Model ---')\n",
    "print(f'{\"=\"*40}')\n",
    "\n",
    "if isinstance(aggregated_data, torch.Tensor):\n",
    "    aggregated_data = aggregated_data.to(DEVICE)\n",
    "\n",
    "# Instantiate\n",
    "model_instance = kernels_reparam_space_time_gpu.fit_vecchia_lbfgs(\n",
    "    smooth=v,\n",
    "    input_map=mm_input_map,\n",
    "    aggregated_data=aggregated_data,\n",
    "    nns_map=nns_map,\n",
    "    mm_cond_number=mm_cond_number,\n",
    "    nheads=nheads\n",
    ")\n",
    "\n",
    "# --- 3. OPTIMIZATION LOOP ---\n",
    "print(f'\\n{\"=\"*40}')\n",
    "print(f'--- Running L-BFGS Optimization ---')\n",
    "print(f'{\"=\"*40}')\n",
    "\n",
    "# Optimizer takes the LIST of scalars\n",
    "optimizer_vecc = model_instance.set_optimizer(\n",
    "            params_list,     \n",
    "            lr=LBFGS_LR,            \n",
    "            max_iter=LBFGS_MAX_EVAL,        \n",
    "            history_size=LBFGS_HISTORY_SIZE \n",
    "        )\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "out, steps_ran = model_instance.fit_vecc_lbfgs(\n",
    "        params_list,\n",
    "        optimizer_vecc,\n",
    "        # covariance_function argument is GONE\n",
    "        max_steps=LBFGS_MAX_STEPS, \n",
    "        grad_tol=1e-7\n",
    "    )\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "epoch_time = end_time - start_time\n",
    "\n",
    "print(f\"\\nOptimization finished in {epoch_time:.2f}s.\")\n",
    "print(f\"Results after {steps_ran} steps: {out}\")\n",
    "print(f\"Final Params: {torch.cat(params_list).detach().cpu().numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c765af78",
   "metadata": {},
   "source": [
    "###\n",
    "\n",
    "Final Interpretable Params: {\n",
    "   'sigma_sq': 12.982146243206834, '\n",
    "   range_lon': 0.1774660571793038, \n",
    "   'range_lat': 0.1377164149996857, \n",
    "   'range_time': 0.8960320754550594, \n",
    "   'advec_lat': 0.03668090767382201, \n",
    "   'advec_lon': -0.16896621297828324, \n",
    "   'nugget': 3.0318146866074696e-14}\n",
    "\n",
    "\n",
    "Final Interpretable Params: {\n",
    "   'sigma_sq': 12.652739121404919, \n",
    "   'range_lon': 0.17664470485305778, \n",
    "   'range_lat': 0.14565426376210802, \n",
    "   'range_time': 0.8720031476394872, \n",
    "   'advec_lat': 0.04466510371597738, \n",
    "   'advec_lon': -0.16447983825003892, 'nugget': 0.31139273714919946}\n",
    "\n",
    "\n",
    "\n",
    "###\n",
    "\n",
    "Final Interpretable Params: {\n",
    "   'sigma_sq': 12.600402314947898, \n",
    "   'range_lon': 0.15632064225879247, \n",
    "   'range_lat': 0.12850412363793687, \n",
    "   'range_time': 0.420237386856305, \n",
    "   'advec_lat': 3.646629197697307, \n",
    "   'advec_lon': -1.82731716498955, \n",
    "   'nugget': 3.3125395377840276e-12}\n",
    "\n",
    "\n",
    "   Final Interpretable Params: {\n",
    "      'sigma_sq': 12.465255157603531,\n",
    "       'range_lon': 0.16088131264500707, \n",
    "       'range_lat': 0.13795064901185095, \n",
    "       'range_time': 0.25642913066711404, \n",
    "       'advec_lat': 0.34121830847670426, \n",
    "       'advec_lon': -0.9086603984853497, 'nugget': 0.3413704158367853}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a644f0",
   "metadata": {},
   "source": [
    "# TRUE PARAMETERS\n",
    "init_sigmasq   = 13.059\n",
    "init_range_lon = 0.195 \n",
    "init_range_lat = 0.154 \n",
    "init_advec_lat = 0.0418\n",
    "init_range_time = 1.0\n",
    "init_advec_lon = -0.1689\n",
    "init_nugget    = 0.247\n",
    "\n",
    "\n",
    "irregular grid\n",
    "\n",
    "Final Interpretable Params: {\n",
    "   'sigma_sq': 13.1581147614216, \n",
    "   'range_lon': 0.1670857937279293, \n",
    "   'range_lat': 0.13532624419142394, \n",
    "   'range_time': 0.662083817877393, \n",
    "   'advec_lat': 4.485362408040999, \n",
    "   'advec_lon': -0.05054465623325784, \n",
    "   'nugget': 3.202037263471046e-05}\n",
    "\n",
    "regular grid\n",
    "\n",
    "Final Interpretable Params: {\n",
    "   'sigma_sq': 13.547646279613172, \n",
    "   'range_lon': 0.2063608511650159, \n",
    "   'range_lat': 0.1698378442441089, \n",
    "   'range_time': 1.122662499886297, \n",
    "   'advec_lat': 0.05415059834603563, \n",
    "   'advec_lon': -0.16640862287821778, \n",
    "   'nugget': 0.48795387825462566}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c961fa4",
   "metadata": {},
   "source": [
    "# fit dw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db9b3e3",
   "metadata": {},
   "source": [
    "difference data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d43435c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([142832, 4])\n",
      "142832\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.8000e-02,  1.2305e+02,  0.0000e+00,  2.1000e+01],\n",
       "        [ 2.8000e-02,  1.2311e+02,  1.9113e+00,  2.1000e+01],\n",
       "        [ 2.8000e-02,  1.2317e+02,  3.1846e+00,  2.1000e+01],\n",
       "        [ 2.8000e-02,  1.2323e+02,  9.3044e+00,  2.1000e+01],\n",
       "        [ 2.8000e-02,  1.2330e+02,  7.5384e+00,  2.1000e+01],\n",
       "        [ 2.8000e-02,  1.2336e+02, -8.2040e-01,  2.1000e+01],\n",
       "        [ 2.8000e-02,  1.2342e+02, -1.2852e+00,  2.1000e+01],\n",
       "        [ 2.8000e-02,  1.2349e+02, -3.2619e+00,  2.1000e+01],\n",
       "        [ 2.8000e-02,  1.2355e+02, -6.2629e-01,  2.1000e+01],\n",
       "        [ 2.8000e-02,  1.2361e+02,  1.3124e+00,  2.1000e+01],\n",
       "        [ 2.8000e-02,  1.2368e+02,  4.2001e-01,  2.1000e+01],\n",
       "        [ 2.8000e-02,  1.2374e+02, -4.3216e-01,  2.1000e+01],\n",
       "        [ 2.8000e-02,  1.2380e+02, -5.5636e+00,  2.1000e+01],\n",
       "        [ 2.8000e-02,  1.2386e+02, -2.0360e+00,  2.1000e+01],\n",
       "        [ 2.8000e-02,  1.2393e+02,  4.5638e+00,  2.1000e+01],\n",
       "        [ 2.8000e-02,  1.2399e+02, -5.2148e-02,  2.1000e+01],\n",
       "        [ 2.8000e-02,  1.2405e+02, -3.7626e+00,  2.1000e+01],\n",
       "        [ 2.8000e-02,  1.2412e+02,  3.4245e+00,  2.1000e+01],\n",
       "        [ 2.8000e-02,  1.2418e+02,  5.3648e+00,  2.1000e+01],\n",
       "        [ 2.8000e-02,  1.2424e+02,  1.9309e+00,  2.1000e+01]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [11.0474, 0.0623, 0.2445, 1.0972, 0.0101, -0.1671, 1.1825]\n",
    "day = 0 # 0 index\n",
    "lat_range= [0,5]\n",
    "lon_range= [123.0, 133.0]\n",
    "#lat_range= [1,3]\n",
    "#lon_range= [125, 129.0]\n",
    "\n",
    "daily_aggregated_tensors_dw = [aggregated_data]\n",
    "daily_hourly_maps_dw = [input_map]\n",
    "\n",
    "db = debiased_whittle.debiased_whittle_preprocess(daily_aggregated_tensors_dw, daily_hourly_maps_dw, day_idx=day, params_list=a, lat_range=lat_range, lon_range=lon_range)\n",
    "\n",
    "\n",
    "subsetted_aggregated_day = db.generate_spatially_filtered_days(0,5,123,133)\n",
    "print(subsetted_aggregated_day.shape)\n",
    "N2= subsetted_aggregated_day.shape[0]\n",
    "print(N2)\n",
    "subsetted_aggregated_day[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2497b8d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Pre-computing J-vector (Hamming taper)...\n",
      "Pre-computing sample periodogram...\n",
      "Pre-computing Hamming taper autocorrelation...\n",
      "Data grid: 113x158, 8 time points. J-vector, Periodogram, Taper Autocorr on cpu.\n",
      "\n",
      "============================== Initialization Run 1/1 ==============================\n",
      "Starting with FIXED params (raw log-scale): [4.2042, 1.6348, 0.4721, -2.5562, 0.0218, -0.1689, -1.3984]\n",
      "Starting optimization run 1 on device cpu (Hamming, 7-param ST kernel, L-BFGS)...\n",
      "--- Step 1/20 ---\n",
      " Loss: 1.906929 | Max Grad: 6.274846e-04\n",
      "  Params (Raw Log): log_phi1: 4.3182, log_phi2: 1.7745, log_phi3: 0.0776, log_phi4: -3.5323, advec_lat: 0.0363, advec_lon: -0.1510, log_nugget: -1.0186\n",
      "--- Step 2/20 ---\n",
      " Loss: 1.817385 | Max Grad: 4.095367e-05\n",
      "  Params (Raw Log): log_phi1: 4.3182, log_phi2: 1.7744, log_phi3: 0.0775, log_phi4: -3.5320, advec_lat: 0.0363, advec_lon: -0.1510, log_nugget: -1.0177\n",
      "--- Step 3/20 ---\n",
      " Loss: 1.817385 | Max Grad: 4.095367e-05\n",
      "  Params (Raw Log): log_phi1: 4.3182, log_phi2: 1.7744, log_phi3: 0.0775, log_phi4: -3.5320, advec_lat: 0.0363, advec_lon: -0.1510, log_nugget: -1.0177\n",
      "--- Step 4/20 ---\n",
      " Loss: 1.817385 | Max Grad: 4.095367e-05\n",
      "  Params (Raw Log): log_phi1: 4.3182, log_phi2: 1.7744, log_phi3: 0.0775, log_phi4: -3.5320, advec_lat: 0.0363, advec_lon: -0.1510, log_nugget: -1.0177\n",
      "\n",
      "--- Converged on loss change (change < 1e-12) at step 4 ---\n",
      "\n",
      "--- Training Complete ---\n",
      "\n",
      "FINAL BEST STATE ACHIEVED (during training):\n",
      "Best Loss: 1.817\n",
      "\n",
      "\n",
      "========================= Overall Result from Run ========================= =========================\n",
      "Best Run Loss: 1.817 (after 4 steps)\n",
      "Final Parameters (Natural Scale): sigmasq: 12.7277, range_lat: 0.1631, range_lon: 0.1696, range_time: 0.9917, advec_lat: 0.0363, advec_lon: -0.1510, nugget: 0.3614\n",
      "Final Parameters (Phi Scale)    : phi1: 75.0512, phi2: 5.8967, phi3: 1.0806, phi4: 0.0292, advec_lat: 0.0363, advec_lon: -0.1510, nugget: 0.3614\n",
      "Final Parameters (Raw Log Scale): log_phi1: 4.3182, log_phi2: 1.7744, log_phi3: 0.0775, log_phi4: -3.5320, advec_lat: 0.0363, advec_lon: -0.1510, log_nugget: -1.0177\n",
      "\n",
      "Total execution time: 40.40 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dwl = debiased_whittle.debiased_whittle_likelihood()\n",
    "if __name__ == '__main__':\n",
    "    start_time = time.time()\n",
    "\n",
    "    # --- Configuration ---\n",
    "    DAY_TO_RUN = 3 # data is decided above\n",
    "    TAPERING_FUNC = dwl.cgn_hamming # Use Hamming taper\n",
    "    NUM_RUNS = 1\n",
    "    MAX_STEPS = 20 # L-BFGS usually converges in far fewer steps\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "    DELTA_LAT, DELTA_LON = 0.044, 0.063 \n",
    "\n",
    "    LAT_COL, LON_COL = 0, 1\n",
    "    VAL_COL = 2 # Spatially differenced value\n",
    "    TIME_COL = 3\n",
    "\n",
    "\n",
    "    cur_df =subsetted_aggregated_day\n",
    "    \n",
    "    if cur_df.numel() == 0 or cur_df.shape[1] <= max(LAT_COL, LON_COL, VAL_COL, TIME_COL):\n",
    "        print(f\"Error: Data for Day {DAY_TO_RUN} is empty or invalid.\")\n",
    "        exit()\n",
    "\n",
    "    unique_times = torch.unique(cur_df[:, TIME_COL])\n",
    "    time_slices_list = [cur_df[cur_df[:, TIME_COL] == t_val] for t_val in unique_times]\n",
    "\n",
    "    # --- 1. Pre-compute J-vector, Taper Grid, and Taper Autocorrelation ---\n",
    "    print(\"Pre-computing J-vector (Hamming taper)...\")\n",
    "    \n",
    "    # --- ğŸ’¥ REVISED: Renamed 'p' to 'p_time' ğŸ’¥ ---\n",
    "    J_vec, n1, n2, p_time, taper_grid = dwl.generate_Jvector_tapered( \n",
    "        time_slices_list,\n",
    "        tapering_func=TAPERING_FUNC, \n",
    "        lat_col=LAT_COL, lon_col=LON_COL, val_col=VAL_COL,\n",
    "        device=DEVICE\n",
    "    )\n",
    "\n",
    "    if J_vec is None or J_vec.numel() == 0 or n1 == 0 or n2 == 0 or p_time == 0:\n",
    "       print(f\"Error: J-vector generation failed for Day {DAY_TO_RUN}.\")\n",
    "       exit()\n",
    "       \n",
    "    print(\"Pre-computing sample periodogram...\")\n",
    "    I_sample = dwl.calculate_sample_periodogram_vectorized(J_vec)\n",
    "\n",
    "    print(\"Pre-computing Hamming taper autocorrelation...\")\n",
    "    taper_autocorr_grid = dwl.calculate_taper_autocorrelation_fft(taper_grid, n1, n2, DEVICE)\n",
    "\n",
    "    if torch.isnan(I_sample).any() or torch.isinf(I_sample).any():\n",
    "        print(\"Error: NaN/Inf in sample periodogram.\")\n",
    "        exit()\n",
    "    if torch.isnan(taper_autocorr_grid).any() or torch.isinf(taper_autocorr_grid).any():\n",
    "        print(\"Error: NaN/Inf in taper autocorrelation.\")\n",
    "        exit()\n",
    "\n",
    "    print(f\"Data grid: {n1}x{n2}, {p_time} time points. J-vector, Periodogram, Taper Autocorr on {DEVICE}.\")\n",
    "    # --- END REVISION ---\n",
    "\n",
    "    # --- 2. Optimization Loop ---\n",
    "    all_final_results = []\n",
    "    all_final_losses = []\n",
    "\n",
    "    for i in range(NUM_RUNS):\n",
    "        print(f\"\\n{'='*30} Initialization Run {i+1}/{NUM_RUNS} {'='*30}\")\n",
    "\n",
    "        # --- 7-PARAMETER initialization ---\n",
    "        ''' \n",
    "        init_sigmasq   = 15.0\n",
    "        init_range_lat = 0.66 \n",
    "        init_range_lon = 0.7 \n",
    "        init_nugget    = 1.5\n",
    "        init_beta      = 0.1  # Temporal range ratio\n",
    "        init_advec_lat = 0.02\n",
    "        init_advec_lon = -0.08\n",
    "        '''\n",
    "        init_sigmasq   = 13.059\n",
    "        init_range_lat = 0.154 \n",
    "        init_range_lon = 0.195\n",
    "        init_advec_lat = 0.0218\n",
    "        init_range_time = 0.7\n",
    "        init_advec_lon = -0.1689\n",
    "        init_nugget    = 0.247\n",
    "\n",
    "        init_phi2 = 1.0 / init_range_lon\n",
    "        init_phi1 = init_sigmasq * init_phi2\n",
    "        init_phi3 = (init_range_lon / init_range_lat)**2\n",
    "        # Change needed to match the spatial-temporal distance formula:\n",
    "        init_phi4 = (init_range_lon / init_range_time)**2      # (range_lon / range_time)^2\n",
    "\n",
    "        initial_params_values = [\n",
    "            np.log(init_phi1),    # [0] log_phi1\n",
    "            np.log(init_phi2),    # [1] log_phi2\n",
    "            np.log(init_phi3),    # [2] log_phi3\n",
    "            np.log(init_phi4),    # [3] log_phi4\n",
    "            init_advec_lat,       # [4] advec_lat (NOT log)\n",
    "            init_advec_lon,       # [5] advec_lon (NOT log)\n",
    "            np.log(init_nugget)   # [6] log_nugget\n",
    "        ]\n",
    "        \n",
    "        print(f\"Starting with FIXED params (raw log-scale): {[round(p, 4) for p in initial_params_values]}\")\n",
    "\n",
    "        params_list = [\n",
    "            Parameter(torch.tensor([val], dtype=torch.float64))\n",
    "            for val in initial_params_values\n",
    "        ]\n",
    "\n",
    "        # Helper to define the boundary globally for clarity\n",
    "        NUGGET_LOWER_BOUND = 0.05\n",
    "        LOG_NUGGET_LOWER_BOUND = np.log(NUGGET_LOWER_BOUND) # Approx -2.9957\n",
    "\n",
    "        # --- ğŸ’¥ REVISED: Use L-BFGS Optimizer ğŸ’¥ ---\n",
    "        optimizer = torch.optim.LBFGS(\n",
    "            params_list,\n",
    "            lr=1.0,           # Initial step length for line search\n",
    "            max_iter=20,      # Iterations per step\n",
    "            history_size=100,\n",
    "            line_search_fn=\"strong_wolfe\", # Often more robust\n",
    "            tolerance_grad=1e-5\n",
    "        )\n",
    "        # --- END REVISION ---\n",
    "\n",
    "        print(f\"Starting optimization run {i+1} on device {DEVICE} (Hamming, 7-param ST kernel, L-BFGS)...\")\n",
    "        \n",
    "        # --- ğŸ’¥ REVISED: Call L-BFGS trainer, pass p_time ğŸ’¥ ---\n",
    "        nat_params_str, phi_params_str, raw_params_str, loss, steps_run = dwl.run_lbfgs_tapered(\n",
    "            params_list=params_list,\n",
    "            optimizer=optimizer,\n",
    "            I_sample=I_sample,\n",
    "            n1=n1, n2=n2, p_time=p_time,\n",
    "            taper_autocorr_grid=taper_autocorr_grid, \n",
    "            max_steps=MAX_STEPS,\n",
    "            device=DEVICE\n",
    "        )\n",
    "        # --- END REVISION ---\n",
    "        \n",
    "        if loss is not None:\n",
    "            all_final_results.append((nat_params_str, phi_params_str, raw_params_str))\n",
    "            all_final_losses.append(loss)\n",
    "        else:\n",
    "            all_final_losses.append(float('inf'))\n",
    "\n",
    "    print(f\"\\n\\n{'='*25} Overall Result from Run {'='*25} {'='*25}\")\n",
    "    \n",
    "    valid_losses = [l for l in all_final_losses if l is not None and l != float('inf')]\n",
    "\n",
    "    if not valid_losses:\n",
    "        print(f\"The run failed or resulted in an invalid loss for Day {DAY_TO_RUN}.\")\n",
    "    else:\n",
    "        best_loss = min(valid_losses)\n",
    "        best_run_index = all_final_losses.index(best_loss)\n",
    "        best_results = all_final_results[best_run_index]\n",
    "        \n",
    "        print(f\"Best Run Loss: {best_loss} (after {steps_run} steps)\")\n",
    "        print(f\"Final Parameters (Natural Scale): {best_results[0]}\")\n",
    "        print(f\"Final Parameters (Phi Scale)    : {best_results[1]}\")\n",
    "        print(f\"Final Parameters (Raw Log Scale): {best_results[2]}\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"\\nTotal execution time: {end_time - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61060411",
   "metadata": {},
   "source": [
    "init_sigmasq   = 13.059\n",
    "init_range_lon = 0.195 \n",
    "init_range_lat = 0.154 \n",
    "init_advec_lat = 0.0418\n",
    "init_range_time = 1.0\n",
    "init_advec_lon = -0.1689\n",
    "init_nugget    = 0.247\n",
    "\n",
    "1 st simulation (1 vs 3)\n",
    "\n",
    "Final Interpretable Params: {'sigma_sq': 12.939260896610579, 'range_lon': 0.17242543281507933, 'range_lat': 0.1631231346200311, 'range_time': 1.1358209227858689, 'advec_lat': 0.045119029109988974, 'advec_lon': -0.17809677784942035, 'nugget': 0.3009582276680578}\n",
    "\n",
    "Final Parameters (Natural Scale): sigmasq: 13.2415, range_lat: 0.1685, range_lon: 0.1739, range_time: 0.9681, advec_lat: 0.0395, advec_lon: -0.1732, nugget: 0.3216\n",
    "\n",
    "2nd simulation (1 vs 3)\n",
    "\n",
    "Final Interpretable Params: {'sigma_sq': 12.765293287952144, 'range_lon': 0.17039368470743024, 'range_lat': 0.16152132799710625, 'range_time': 1.081124889959751, 'advec_lat': 0.04635511983762563, 'advec_lon': -0.1775715292039452, 'nugget': 0.31503884896742074}\n",
    "\n",
    "\n",
    "sigmasq: 13.2415, range_lat: 0.1685, range_lon: 0.1739, range_time: 0.9681, advec_lat: 0.0395, advec_lon: -0.1732, nugget: 0.3216\n",
    "\n",
    "3nd simulation (mm 15 two times)\n",
    "\n",
    "Final Interpretable Params: {'sigma_sq': 12.292570063933866, 'range_lon': 0.16170186578939172, 'range_lat': 0.1537053192245325, 'range_time': 0.9671689003322674, 'advec_lat': 0.04155171168950867, 'advec_lon': -0.16218073366456207, 'nugget': 0.29945872751676345}\n",
    "\n",
    "Final Parameters (Natural Scale): sigmasq: 12.7277, range_lat: 0.1631, range_lon: 0.1696, range_time: 0.9917, advec_lat: 0.0363, advec_lon: -0.1510, nugget: 0.3614\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "faiss_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
