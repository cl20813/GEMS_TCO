{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5872717f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import sys\n",
    "# Add your custom path\n",
    "gems_tco_path = \"/Users/joonwonlee/Documents/GEMS_TCO-1/src\"\n",
    "sys.path.append(gems_tco_path)\n",
    "\n",
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from GEMS_TCO import kernels\n",
    "from GEMS_TCO import data_preprocess \n",
    "from GEMS_TCO import kernels_new, kernels_reparam_space_time as kernels_reparam_space_time\n",
    "from GEMS_TCO import orderings as _orderings \n",
    "from GEMS_TCO import load_data\n",
    "from GEMS_TCO import alg_optimization, alg_opt_Encoder\n",
    "from GEMS_TCO import configuration as config\n",
    "\n",
    "from typing import Optional, List, Tuple\n",
    "from pathlib import Path\n",
    "from json import JSONEncoder\n",
    "\n",
    "from GEMS_TCO.data_loader import load_data2\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d14b8b",
   "metadata": {},
   "source": [
    "Load monthly data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "29373ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subsetting data to lat: [0.0, 5.0], lon: [123.0, 133.0]\n"
     ]
    }
   ],
   "source": [
    "space: List[str] = ['4', '4']\n",
    "lat_lon_resolution = [int(s) for s in space]\n",
    "mm_cond_number: int = 20\n",
    "years = ['2024']\n",
    "month_range = [7] \n",
    "\n",
    "output_path = input_path = Path(config.mac_estimates_day_path)\n",
    "data_load_instance = load_data2(config.mac_data_load_path)\n",
    "\n",
    "\n",
    "df_map, ord_mm, nns_map = data_load_instance.load_maxmin_ordered_data_bymonthyear(\n",
    "lat_lon_resolution=lat_lon_resolution, \n",
    "mm_cond_number=mm_cond_number,\n",
    "years_=years, \n",
    "months_=month_range,\n",
    "lat_range=[0.0, 5.0],      \n",
    "lon_range=[123.0, 133.0] \n",
    ")\n",
    "\n",
    "#days: List[str] = ['0', '31']\n",
    "#days_s_e = [int(d) for d in days]\n",
    "#days_list = list(range(days_s_e[0], days_s_e[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c06c8d",
   "metadata": {},
   "source": [
    "Load daily data applying max-min ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b7677058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8960, 4])\n"
     ]
    }
   ],
   "source": [
    "daily_aggregated_tensors = [] \n",
    "daily_hourly_maps = []        \n",
    "\n",
    "analysis_hour =2\n",
    "k=0\n",
    "for day_index in range(31):\n",
    "  \n",
    "    hour_start_index = day_index * 8 + k \n",
    "\n",
    "\n",
    "    hour_end_index = (day_index + 1) * 8 + k\n",
    "    #hour_end_index = day_index*8 + 1\n",
    "    #hour_end_index = day_index*8 + analysis_hour + k\n",
    "\n",
    "    hour_indices = [hour_start_index, hour_end_index]\n",
    "    \n",
    "    # Load the data for the current day\n",
    "    day_hourly_map, day_aggregated_tensor = data_load_instance.load_working_data(\n",
    "        df_map, \n",
    "        hour_indices, \n",
    "        ord_mm=None,  \n",
    "        dtype=torch.float \n",
    "    )\n",
    "    # Append the day's data to their respective lists\n",
    "    daily_aggregated_tensors.append(day_aggregated_tensor)\n",
    "    daily_hourly_maps.append(day_hourly_map) \n",
    "\n",
    "print(daily_aggregated_tensors[0].shape)\n",
    "#print(daily_hourly_maps[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46f2f21",
   "metadata": {},
   "source": [
    "Hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b8c81076",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = 0.5 # smooth\n",
    "mm_cond_number = 8\n",
    "nheads = 300\n",
    "#nheads = 1230\n",
    "#lr = 0.01\n",
    "#step = 80\n",
    "#gamma_par = 0.5\n",
    "\n",
    "# --- Placeholder Global Variables ---\n",
    "# ðŸ’¥ REVISED: Added lr, patience, factor. Removed step, gamma_par\n",
    "lr=0.1\n",
    "patience = 5       # Scheduler: Epochs to wait for improvement\n",
    "factor = 0.5         # Scheduler: Factor to reduce LR by (e.g., 0.5 = 50% cut)\n",
    "epochs=150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3baceb31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000 448400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cal(a):\n",
    "    day_indices = [0] \n",
    "    for day_idx in day_indices:  \n",
    "\n",
    "        daily_hourly_map = daily_hourly_maps[day_idx]\n",
    "        daily_aggregated_tensor = daily_aggregated_tensors[day_idx]\n",
    "\n",
    "        # Convert initial parameters to a list of 1-element tensors\n",
    "        params_list = [\n",
    "            torch.tensor([val], dtype=torch.float64, requires_grad=True, device=device_str) for val in a\n",
    "        ]\n",
    "        \n",
    "        # ðŸ’¡ CRITICAL: Concatenate the list into a single tensor\n",
    "        # The full_likelihood function expects a single tensor, not a list\n",
    "        params_tensor = torch.cat(params_list)\n",
    "\n",
    "        # Assuming 'kernels_repar_space' has your 'fit_vecchia_adams' class\n",
    "  \n",
    "        model_instance = kernels_reparam_space_time.fit_vecchia_adams(\n",
    "                smooth = v,\n",
    "                input_map = daily_hourly_map,\n",
    "                aggregated_data = daily_aggregated_tensor,\n",
    "                nns_map = nns_map,\n",
    "                mm_cond_number = mm_cond_number,\n",
    "                nheads = nheads\n",
    "            )\n",
    "    \n",
    "        # ðŸ’¡ Pass the single 'params_tensor' and the correct 4-parameter spatial covariance function\n",
    "        bb = model_instance.full_likelihood_avg(\n",
    "            params = params_tensor, \n",
    "            input_data = daily_aggregated_tensor, \n",
    "            y = daily_aggregated_tensor[:,2], \n",
    "            covariance_function = model_instance.matern_cov_aniso_STABLE_log_reparam\n",
    "        )\n",
    "     \n",
    "        cov_map = model_instance.cov_structure_saver(params_tensor, model_instance.matern_cov_aniso_STABLE_log_reparam)\n",
    "        vecchia_nll = model_instance.vecchia_space_time_fullbatch( # Change this to your chosen Vecchia implementation\n",
    "            params = params_tensor, \n",
    "            covariance_function = model_instance.matern_cov_aniso_STABLE_log_reparam, \n",
    "            cov_map = cov_map # Assuming cov_map is precomputed or computed internally\n",
    "        )\n",
    " \n",
    "    return bb, vecchia_nll\n",
    "\n",
    "device_str = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# adams and lfgs\n",
    "#a= [3.2691297610712176, 0.6684659526552683, 0.4027674047362919, 0.8989261051578574, 6521.4909959990455]\n",
    "\n",
    "#bb, nll_value = cal(a)\n",
    "#print(f\"Full Negative Log-Likelihood: {bb.item()*1120, nll_value.item()}\")\n",
    "\n",
    "def cc(n,nheads,mm):\n",
    "    print(n**2 , nheads**2 + (n-nheads)*mm**3)\n",
    "    return n**2 >nheads**2 + (n-nheads)*mm**3\n",
    "\n",
    "cc(1000,300,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48fcbe4",
   "metadata": {},
   "source": [
    "# 8 hours 1120"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5281f0",
   "metadata": {},
   "source": [
    "###  vecchia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cc13744a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Negative Log-Likelihood: (29432.74468523959, 30591.837590380615)\n",
      "Full Negative Log-Likelihood: (29526.910924277436, 30683.88178585764)\n",
      "Full Negative Log-Likelihood: (29424.180472720167, 30585.618627548574)\n"
     ]
    }
   ],
   "source": [
    "a = [4.286645422792349, 1.7396404064146764, 0.48907270259813174, -3.7770937316117275, 0.02048493270070447, -0.16411459496379438, -12.055733094871497]\n",
    " # estimates\n",
    "bb, nll_value = cal(a)\n",
    "print(f\"Full Negative Log-Likelihood: {bb.item()*18162, nll_value.item()*18162}\")\n",
    "\n",
    "a = [4.386645422792349, 1.7396404064146764, 0.48907270259813174, -3.7770937316117275, 0.02048493270070447, -0.16411459496379438, -12.055733094871497]\n",
    "bb, nll_value = cal(a)\n",
    "\n",
    "print(f\"Full Negative Log-Likelihood: {bb.item()*18162, nll_value.item()*18162}\")\n",
    "\n",
    "a = [4.186645422792349, 1.7396404064146764, 0.48907270259813174, -3.7770937316117275, 0.02048493270070447, -0.16411459496379438, -12.055733094871497]\n",
    "bb, nll_value = cal(a)\n",
    "\n",
    "print(f\"Full Negative Log-Likelihood: {bb.item()*18162, nll_value.item()*18162}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a7f46e",
   "metadata": {},
   "source": [
    "### dw adams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "43b4102d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Negative Log-Likelihood: (29660.142481601535, 30665.408140860818)\n",
      "Full Negative Log-Likelihood: (29739.981851793724, 30721.93854034474)\n",
      "Full Negative Log-Likelihood: (29667.41189446016, 30698.437968010054)\n"
     ]
    }
   ],
   "source": [
    "a = [4.2739, 1.8060, 0.7948, -3.3599, 0.0223, -0.1672, -11.8381]\n",
    " # estimates\n",
    "bb, nll_value = cal(a)\n",
    "print(f\"Full Negative Log-Likelihood: {bb.item()*18162, nll_value.item()*18162}\")\n",
    "\n",
    "a = [4.3739, 1.8060, 0.7948, -3.3599, 0.0223, -0.1672, -11.8381]\n",
    "bb, nll_value = cal(a)\n",
    "\n",
    "print(f\"Full Negative Log-Likelihood: {bb.item()*18162, nll_value.item()*18162}\")\n",
    "\n",
    "a =[4.1739, 1.8060, 0.7948, -3.3599, 0.0223, -0.1672, -11.8381]\n",
    "bb, nll_value = cal(a)\n",
    "\n",
    "print(f\"Full Negative Log-Likelihood: {bb.item()*18162, nll_value.item()*18162}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "faiss_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
