{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for path in sys.path:\n",
    "#   print(path)\n",
    "\n",
    "import sys\n",
    "gems_tco_path = \"/Users/joonwonlee/Documents/GEMS_TCO-1/src\"\n",
    "sys.path.append(gems_tco_path)\n",
    "\n",
    "import logging\n",
    "import argparse # Argument parsing\n",
    "import math\n",
    "# from collections import defaultdict\n",
    "# import concurrent\n",
    "# from concurrent.futures import ThreadPoolExecutor  # Importing specific executor for clarity\n",
    "# import time\n",
    "\n",
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Nearest neighbor search\n",
    "import sklearn\n",
    "from sklearn.neighbors import BallTree\n",
    "# Type hints\n",
    "from typing import Callable, Union, Tuple\n",
    "\n",
    "# Add your custom path\n",
    "# sys.path.append(\"/cache/home/jl2815/tco\")\n",
    "\n",
    "# Custom imports\n",
    "\n",
    "from GEMS_TCO import orbitmap \n",
    "from GEMS_TCO import kernels \n",
    "from GEMS_TCO import evaluate\n",
    "from GEMS_TCO import orderings as _orderings\n",
    "from GEMS_TCO import load_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "gems_tco_path = \"/Users/joonwonlee/Documents/GEMS_TCO-1/src\"\n",
    "sys.path.append(gems_tco_path)\n",
    "\n",
    "import GEMS_TCO\n",
    "from GEMS_TCO import kernels \n",
    "from GEMS_TCO import orderings as _orderings\n",
    "from GEMS_TCO import load_data_local_computer\n",
    "\n",
    "import torch\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_lon_resolution = [10,10]\n",
    "mm_cond_number = 20\n",
    "years = ['2024']\n",
    "month_range =[7,8]\n",
    "idx_for_datamap= [0,8]\n",
    "\n",
    "params= [20, 8.25, 5.25, 0.2, 0.5, 5]\n",
    "\n",
    "instance = load_data_local_computer()\n",
    "map, ord_mm, nns_map= instance.load_mm20k_data_bymonthyear( lat_lon_resolution= lat_lon_resolution, mm_cond_number=mm_cond_number,years_=years, months_=month_range)\n",
    "\n",
    "analysis_data_map, aggregated_data = instance.load_working_data_byday( map, ord_mm, nns_map, idx_for_datamap=[0,8])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLE using full likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLE using vecchia likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mm_cond_number:  10\n",
      "tensor(2542.7729, grad_fn=<MulBackward0>)\n",
      "tensor(2640.7498, grad_fn=<AddBackward0>)\n",
      "tensor(2563.9333, grad_fn=<AddBackward0>)\n",
      "mm_cond_number:  11\n",
      "tensor(2542.7729, grad_fn=<MulBackward0>)\n",
      "tensor(2641.1089, grad_fn=<AddBackward0>)\n",
      "tensor(2564.2854, grad_fn=<AddBackward0>)\n",
      "mm_cond_number:  12\n",
      "tensor(2542.7729, grad_fn=<MulBackward0>)\n",
      "tensor(2642.1238, grad_fn=<AddBackward0>)\n",
      "tensor(2565.2751, grad_fn=<AddBackward0>)\n",
      "mm_cond_number:  13\n",
      "tensor(2542.7729, grad_fn=<MulBackward0>)\n",
      "tensor(2641.7437, grad_fn=<AddBackward0>)\n",
      "tensor(2564.9167, grad_fn=<AddBackward0>)\n",
      "mm_cond_number:  14\n",
      "tensor(2542.7729, grad_fn=<MulBackward0>)\n",
      "tensor(2640.4329, grad_fn=<AddBackward0>)\n",
      "tensor(2563.6133, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "instance = kernels.likelihood_function(smooth=0.5, input_map=analysis_data_map, aggregated_data=aggregated_data,nns_map=nns_map, mm_cond_number=mm_cond_number)\n",
    "\n",
    "# Define your initial parameters\n",
    "params = [21.8, 1.09, 1.17, 0.2, .2, 0.5, 1]\n",
    "params = [52.627, 4, 5.685, 6.77e-2, -4.19e-3, 0.0585, 3.143]  # 50x8 lr=0.01  24.42 1.92, 1.92, 0.001, -0.045, -.237, 3.34\n",
    "params = [51.79, 3.894, 4.135, -2.08e-2, -7.71e-2, 0.061, 3.5]\n",
    "params = torch.tensor(params, requires_grad=True)\n",
    "torch_smooth = torch.tensor(0.5, dtype=torch.float32)\n",
    "\n",
    "\n",
    "for i in range(10,15):\n",
    "    mm_cond_number = i \n",
    "    print(\"mm_cond_number: \", mm_cond_number)\n",
    "    instance = kernels.likelihood_function(smooth=torch_smooth , input_map=analysis_data_map,aggregated_data=aggregated_data, nns_map=nns_map, mm_cond_number=mm_cond_number)\n",
    "\n",
    "    out0 = instance.full_likelihood(params, aggregated_data[:,:4],aggregated_data[:,2], instance.matern_cov_anisotropy_v05)\n",
    "    print(out0)\n",
    "    out0 = instance.vecchia_like_local_computer(params, instance.matern_cov_anisotropy_v05)\n",
    "    print(out0)\n",
    "\n",
    "    out0 = instance.vecchia_like_amarel(params, instance.matern_cov_anisotropy_v05)\n",
    "    print(out0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimization full likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 200 x 8\n",
    "\n",
    "lr 0.001 without scheduler  same as lr, step_size, gamma  0.01 40 0.5  (9.8s)\n",
    "\n",
    " Loss: 2549.066650390625, full Parameters: [ 2.48777485e+01  2.05998826e+00  2.16013098e+00  2.20775465e-03\n",
    " -7.89414570e-02  1.05411254e-01  3.75236106e+00]\n",
    "\n",
    " lr 0.01  step size 40  betas 0.9 , 0.8 gamma 0.9  30 s\n",
    "\n",
    "  Loss: 2547.1728515625, full Parameters: [ 2.7377291e+01  2.2077193e+00  2.3204505e+00  1.0307773e-03\n",
    " -8.0311157e-02  9.8579854e-02  3.6677265e+00]\n",
    "\n",
    " lr 0.01  step size 10 betas 0.9 , 0.8 gamma 0.9  30 s\n",
    "  Loss: 2548.87841796875, full Parameters: [ 2.5092268e+01  2.0689390e+00  2.1694989e+00  2.0285936e-03\n",
    " -7.9028614e-02  1.0501490e-01  3.7373385e+00]\n",
    "Training full likelihood complete.   11.8 sc\n",
    "\n",
    " lr 0.01  step size 20 betas 0.9 , 0.8 gamma 0.9  30 s\n",
    " Loss: 2548.15283203125, full Parameters: [ 2.59814014e+01  2.12175608e+00  2.22699022e+00  1.73025124e-03\n",
    " -7.93599486e-02  1.02427535e-01  3.70715070e+00]\n",
    "\n",
    "\n",
    "\n",
    "lr 0.01  step size 20 beta 0.9 0.99 gamma 0.9\n",
    " Loss: 2548.18603515625, full Parameters: [ 2.5938652e+01  2.1110108e+00  2.2155209e+00  1.5893303e-03\n",
    " -7.9482891e-02  1.0297947e-01  3.6958976e+00]\n",
    " 21.6\n",
    "\n",
    "lr 0.01  step size 20 beta 0.9 0.8 gamma 0.9\n",
    " Loss: 2548.15283203125, full Parameters: [ 2.59814014e+01  2.12175608e+00  2.22699022e+00  1.73025124e-03\n",
    " -7.93599486e-02  1.02427535e-01  3.70715070e+00]\n",
    " 22.9 s\n",
    "\n",
    "lr 0.01  step size 10 beta 0.9 0.99 gamma 0.9\n",
    "Loss: 2548.95361328125, full Parameters: [ 2.5118145e+01  1.9827319e+00  2.0768294e+00  1.0898338e-03\n",
    " -8.0070712e-02  1.1034889e-01  3.5647078e+00]\n",
    "\n",
    "\n",
    "## 1250 x 8\n",
    "\n",
    "1250* 8 55m using constant learning rate 0.0001 \n",
    "Loss: 14068.798828125, full Parameters: [ 2.46198387e+01  1.61719894e+00  1.76454413e+00  8.55297223e-03\n",
    " -1.08275235e-01  1.28809512e-01  2.80795789e+00]\n",
    "\n",
    "1250* 8 10m 32s\n",
    "lr 0.01  step size 40 beta 0.9 0.8 gamma 0.9\n",
    "  Loss: 14068.1953125, full Parameters: [ 2.5030930e+01  1.6107724e+00  1.7573007e+00  8.8407323e-03\n",
    " -1.0820019e-01  1.2936097e-01  2.7430327e+00]\n",
    "Training full likelihood complete.\n",
    "\n",
    "9m 33s\n",
    "lr 0.01  step size 20 beta 0.9 0.8 gamma 0.9\n",
    " Loss: 14068.29296875, full Parameters: \n",
    " [ 2.4933689e+01  1.6009743e+00  1.7502663e+00  9.2404895e-03 -1.0737537e-01  1.2953614e-01 \n",
    "  2.7420275e+00]\n",
    "Training full likelihood complete.\n",
    "\n",
    "#### high resolution data might benefits from larger step size high resolution data often provides \n",
    "#### more stable gradients, so larger step size less likely to cause significant fluctuations\n",
    "14n 41.8s\n",
    "lr 0.01  step size 10 beta 0.9 0.99 gamma 0.9\n",
    "\n",
    "FINAL STATE: Epoch 199, \n",
    " Loss: 14068.8828125, full Parameters: \n",
    " [ 2.4707581e+01  1.6489888e+00  1.7993137e+00  8.4043797e-03 -1.0836436e-01  1.2655504e-01  \n",
    " 2.8416286e+00]\n",
    "\n",
    "#### beta 0.9 0.99 might be too conservative for high resolution data\n",
    "13m 44.8s\n",
    "lr 0.01  step size 20 beta 0.9 0.99 gamma 0.9\n",
    "\n",
    " Loss: 14068.318359375, full Parameters: [ 2.4938175e+01  1.6203119e+00  1.7678342e+00  8.6686825e-03\n",
    " -1.0813228e-01  1.2845081e-01  2.7731323e+00]\n",
    "\n",
    "\n",
    "18m\n",
    "lr 0.01  step size 40 beta 0.9 0.99 gamma 0.9\n",
    "\n",
    " Loss: 14067.970703125, full Parameters: [ 2.5205673e+01  1.6159834e+00  1.7630767e+00  8.7957922e-03\n",
    " -1.0802399e-01  1.2862283e-01  2.7390635e+00]\n",
    "\n",
    "9m 52s\n",
    "lr 0.01  step size 20 beta 0.9 0.8 gamma 0.9\n",
    "\n",
    "Loss: 14068.29296875, full Parameters: [ 2.4933689e+01  1.6009743e+00  1.7502663e+00  9.2404895e-03\n",
    " -1.0737537e-01  1.2953614e-01  2.7420275e+00]\n",
    "Training full likelihood complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Gradients: [  0.5812483  19.981602   11.618286    2.1514587  18.508026  447.89014\n",
      "   5.896081 ]\n",
      " Loss: 2588.835693359375, Parameters: [ 2.442e+01  1.920e+00  1.920e+00  1.000e-03 -4.500e-02  2.370e-01\n",
      "  3.340e+00]\n",
      "Epoch 101, Gradients: [-0.84959674 -0.43359375 -0.36999512 -0.29135132 -3.8077698  -6.9865723\n",
      "  0.06155443]\n",
      " Loss: 2548.97900390625, Parameters: [ 2.49888325e+01  2.04243159e+00  2.14122796e+00  1.22757768e-03\n",
      " -8.13331604e-02  1.05529346e-01  3.72364473e+00]\n",
      "Epoch 201, Gradients: [-0.8188605   0.02231026  0.02679443  0.00822449 -0.38000488  1.8916016\n",
      "  0.03283119]\n",
      " Loss: 2548.55615234375, Parameters: [ 2.5473244e+01  2.0911043e+00  2.1936471e+00  1.8002884e-03\n",
      " -7.9336733e-02  1.0402137e-01  3.7235968e+00]\n",
      "Epoch 301, Gradients: [-0.7940925  -0.02832031 -0.019104   -0.11378479  0.20098877 -1.6644287\n",
      " -0.02568793]\n",
      " Loss: 2548.3251953125, Parameters: [ 2.5759418e+01  2.1081748e+00  2.2122281e+00  1.7022894e-03\n",
      " -7.9268247e-02  1.0296774e-01  3.7139628e+00]\n",
      "Epoch 401, Gradients: [-0.7732562   0.00411797 -0.00164795  0.09942627  0.14627075  0.3297119\n",
      "  0.0049901 ]\n",
      " Loss: 2548.193115234375, Parameters: [ 2.59282646e+01  2.11855030e+00  2.22339797e+00  1.75939058e-03\n",
      " -7.92920068e-02  1.02613755e-01  3.70893717e+00]\n",
      "Converged at epoch 446\n",
      "Epoch 447, Gradients: [-0.7697732  -0.01019478 -0.00305176 -0.04103088  0.03244019 -0.5115967\n",
      " -0.00895929]\n",
      " Loss: 2548.15283203125, full Parameters: [ 2.59814014e+01  2.12175608e+00  2.22699022e+00  1.73025124e-03\n",
      " -7.93599486e-02  1.02427535e-01  3.70715070e+00]\n",
      "FINAL STATE: Epoch 447, Gradients: [-0.7697732  -0.01019478 -0.00305176 -0.04103088  0.03244019 -0.5115967\n",
      " -0.00895929]\n",
      " Loss: 2548.15283203125, full Parameters: [ 2.59814014e+01  2.12175608e+00  2.22699022e+00  1.73025124e-03\n",
      " -7.93599486e-02  1.02427535e-01  3.70715070e+00]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([ 2.59814014e+01,  2.12175608e+00,  2.22699022e+00,  1.73025124e-03,\n",
       "        -7.93599486e-02,  1.02427535e-01,  3.70715070e+00], dtype=float32),\n",
       " 2548.15283203125]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = [24.42, 1.92, 1.92, 0.001, -0.045, 0.237, 3.34]\n",
    "params = torch.tensor(params, requires_grad=True)\n",
    "\n",
    "instance = kernels.model_fitting(\n",
    "    smooth=0.5,\n",
    "    input_map=analysis_data_map,\n",
    "    aggregated_data=aggregated_data,\n",
    "    nns_map=nns_map,\n",
    "    mm_cond_number=mm_cond_number\n",
    ")\n",
    "\n",
    "# optimizer = optim.Adam([params], lr=0.01)  # For Adam\n",
    "optimizer, scheduler = instance.optimizer_fun( params, lr=0.01, betas=(0.9, 0.8), eps=1e-8, step_size=20, gamma=0.9)    \n",
    "instance.run_full(params, optimizer,scheduler, epochs=3000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimization vecchia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Gradients: [ -1.6978278  -0.9539037  -1.479125    3.4490952  -5.6188226 330.39474\n",
      "   5.3998504]\n",
      " Loss: 2712.965087890625, Parameters: [ 2.442e+01  1.920e+00  1.920e+00  1.000e-03 -4.500e-02  2.370e-01\n",
      "  3.340e+00]\n",
      "Epoch 101, Gradients: [-3.4247541  -3.7539387  -1.4407252   0.03527291  0.06073171  2.6250286\n",
      " -5.4605947 ]\n",
      " Loss: 2672.85546875, Parameters: [ 2.5097479e+01  2.4877543e+00  2.4300516e+00 -1.8351343e-02\n",
      " -4.6579365e-02  9.3222268e-02  3.6997967e+00]\n",
      "Epoch 201, Gradients: [-3.2743526e+00 -2.7421007e+00 -9.4392323e-01 -2.3616329e-03\n",
      " -8.1175491e-03  1.4762225e+00 -4.5513015e+00]\n",
      " Loss: 2670.449462890625, Parameters: [ 2.5319967e+01  2.6379328e+00  2.5545406e+00 -1.8168207e-02\n",
      " -4.4459570e-02  8.5046709e-02  3.9019041e+00]\n",
      "Epoch 301, Gradients: [-3.2300038e+00 -2.3868585e+00 -7.5216478e-01 -2.8929859e-04\n",
      " -2.2552311e-03  9.1798401e-01 -4.2692261e+00]\n",
      " Loss: 2669.697509765625, Parameters: [ 2.5397436e+01  2.6949124e+00  2.6013494e+00 -1.8095888e-02\n",
      " -4.3703701e-02  8.2216956e-02  3.9727142e+00]\n",
      "Epoch 401, Gradients: [-3.2177718e+00 -2.2451696e+00 -6.5890563e-01 -6.5369532e-04\n",
      "  1.7166436e-03  5.9644508e-01 -4.1892672e+00]\n",
      " Loss: 2669.4306640625, Parameters: [ 2.5424706e+01  2.7172644e+00  2.6200290e+00 -1.8078679e-02\n",
      " -4.3422855e-02  8.1155591e-02  3.9985397e+00]\n",
      "Converged at epoch 421\n",
      "Epoch 422, Gradients: [-3.2167971e+00 -2.2289884e+00 -6.4536059e-01 -1.1688881e-03\n",
      "  4.5510381e-04  5.3790855e-01 -4.1828480e+00]\n",
      " Loss: 2669.4072265625, vecc Parameters: [ 2.5427727e+01  2.7199132e+00  2.6222990e+00 -1.8077407e-02\n",
      " -4.3385971e-02  8.1031397e-02  4.0014672e+00]\n",
      "FINAL STATE: Epoch 422, Gradients: [-3.2167971e+00 -2.2289884e+00 -6.4536059e-01 -1.1688881e-03\n",
      "  4.5510381e-04  5.3790855e-01 -4.1828480e+00]\n",
      " Loss: 2669.4072265625, vecc Parameters: [ 2.5427727e+01  2.7199132e+00  2.6222990e+00 -1.8077407e-02\n",
      " -4.3385971e-02  8.1031397e-02  4.0014672e+00]\n",
      "Training vecchia likelihood complete.\n"
     ]
    }
   ],
   "source": [
    "params = [24.42, 1.92, 1.92, 0.001, -0.045, 0.237, 3.34]\n",
    "params = torch.tensor(params, requires_grad=True)\n",
    "\n",
    "instance = kernels.model_fitting(\n",
    "    smooth=0.5,\n",
    "    input_map=analysis_data_map,\n",
    "    aggregated_data=aggregated_data,\n",
    "    nns_map=nns_map,\n",
    "    mm_cond_number=mm_cond_number\n",
    ")\n",
    "\n",
    "# optimizer = optim.Adam([params], lr=0.01)  # For Adam\n",
    "optimizer, scheduler = instance.optimizer_fun( params, lr=0.01, betas=(0.9, 0.99), eps=1e-8, step_size=10, gamma=0.9)  \n",
    "instance.run_vecc_local(params, optimizer, scheduler,epochs=3000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "faiss_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
