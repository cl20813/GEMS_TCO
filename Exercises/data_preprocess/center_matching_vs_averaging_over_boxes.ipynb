{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# work environment: jl2815\n",
    "# Standard libraries\n",
    "import sys\n",
    "import logging\n",
    "import argparse # Argument parsing\n",
    "import math\n",
    "from collections import defaultdict\n",
    "import concurrent\n",
    "from concurrent.futures import ThreadPoolExecutor  # Importing specific executor for clarity\n",
    "import time\n",
    "\n",
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Nearest neighbor search\n",
    "import sklearn\n",
    "from sklearn.neighbors import BallTree\n",
    "\n",
    "# Special functions and optimizations\n",
    "from scipy.special import gamma, kv  # Bessel function and gamma function\n",
    "from scipy.stats import multivariate_normal  # Simulation\n",
    "from scipy.optimize import minimize\n",
    "from scipy.spatial.distance import cdist  # For space and time distance\n",
    "from scipy.spatial import distance  # Find closest spatial point\n",
    "from scipy.optimize import differential_evolution\n",
    "\n",
    "# Plotting and visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Type hints\n",
    "from typing import Callable, Union, Tuple\n",
    "\n",
    "# Add your custom path\n",
    "sys.path.append(\"/cache/home/jl2815/tco\")\n",
    "\n",
    "# Custom imports\n",
    "from GEMS_TCO import orbitmap \n",
    "from GEMS_TCO import kernels \n",
    "from GEMS_TCO import smoothspace\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "The problem was largely due to how the data was pre-processed.\n",
    "\n",
    "I should have used center-matching process. It makes huge difference. Also it makes less singularity problem which \n",
    "also affects the performance of Vecchia likelihoods. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test averaging processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:\\\\Users\\\\joonw\\\\TCO\\\\data_engineering\\\\data_2024\\\\data_24_07_0131_N510_E110120.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = orbitmap.MakeOrbitdata(df = df,lat_s=5,lat_e=10,lon_s=110,lon_e=120,lat_resolution=.4,lon_resolution=.4)\n",
    "\n",
    "filepath =\"C:\\\\Users\\\\joonw\\\\TCO\\\\data_engineering\\\\data_2024\\\\orbit_map24_07.pkl\"\n",
    "with open(filepath,'rb') as pickle_file:\n",
    "    coarse_dict_24_1 = pickle.load(pickle_file)\n",
    "\n",
    "sparse_map24_7 = instance.make_sparsemap(coarse_dict_24_1, .4 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "sample_df = sparse_map24_7['y24m07day01_hm01:00']\n",
    "coarse_dicts = sparse_map24_7\n",
    "\n",
    "mm_cond_number=10\n",
    "key_for_dict = 2\n",
    "\n",
    "key_idx = sorted(coarse_dicts)\n",
    "if not key_idx:\n",
    "    raise ValueError(\"coarse_dicts is empty\")\n",
    "\n",
    "# extract first hour data because all data shares the same spatial grid\n",
    "data_for_coord = coarse_dicts[key_idx[0]]\n",
    "x1 = data_for_coord['Longitude'].values\n",
    "y1 = data_for_coord['Latitude'].values \n",
    "coords1 = np.stack((x1, y1), axis=-1)\n",
    "\n",
    "instance = orbitmap.MakeOrbitdata()\n",
    "s_dist = cdist(coords1, coords1, 'euclidean')\n",
    "ord_mm, _ = instance.maxmin_naive(s_dist, 0)\n",
    "\n",
    "data_for_coord = data_for_coord.iloc[ord_mm].reset_index(drop=True)\n",
    "coords1_reordered = np.stack((data_for_coord['Longitude'].values, data_for_coord['Latitude'].values), axis=-1)\n",
    "nns_map = instance.find_nns_naive(locs=coords1_reordered, dist_fun='euclidean', max_nn=mm_cond_number)\n",
    "\n",
    "\n",
    "\n",
    "analysis_data_map = {}\n",
    "for i in range(key_for_dict):\n",
    "    tmp = coarse_dicts[key_idx[i]]\n",
    "    tmp = tmp.iloc[ord_mm].reset_index(drop=True)  \n",
    "    analysis_data_map[key_idx[i]] = tmp\n",
    "\n",
    "aggregated_data = pd.DataFrame()\n",
    "for i in range((key_for_dict)):\n",
    "    tmp = coarse_dicts[key_idx[i]]\n",
    "    tmp = tmp.iloc[ord_mm].reset_index(drop=True)  \n",
    "    aggregated_data = pd.concat((aggregated_data, tmp), axis=0)\n",
    "\n",
    "lat_n = sample_df['Latitude'].unique()\n",
    "lon_n = sample_df['Longitude'].unique()\n",
    "\n",
    "lat_number = len(lat_n)\n",
    "lon_number = len(lon_n)\n",
    "\n",
    "print(lat_number)\n",
    "print(lon_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aggregated_data (600, 5)\n",
      "grid 12*25:Full likelihood using [0.5, 0.5, 0.5, 0.5, 0.5, 0.5] is 3741.598955706946\n",
      "full likelihood 2time points took 2.8065 seconds\n",
      "grid 12*25:Vecchia approximation likelihood using condition size 10, [0.5, 0.5, 0.5, 0.5, 0.5, 0.5] is 3109.36234130164\n",
      "vecchia 2time points took 0.0000 seconds\n"
     ]
    }
   ],
   "source": [
    "params = [0.5,0.5,0.5,0.5,0.5,0.5]\n",
    "\n",
    "print(f'aggregated_data {aggregated_data.shape}')\n",
    "#####################################################################\n",
    "\n",
    "instance = kernels.matern_spatio_temporal(smooth = 0.5, input_map = analysis_data_map, nns_map = nns_map, mm_cond_number = mm_cond_number )\n",
    "# data = data.iloc[ord,:]\n",
    "out = instance.vecchia_likelihood(params)\n",
    "\n",
    "start_time = time.time()\n",
    "print(f'grid {lat_number}*{lon_number}:Full likelihood using {params} is {instance.full_likelihood(params, aggregated_data, aggregated_data[\"ColumnAmountO3\"])}')\n",
    "end_time = time.time()  # Record the end time\n",
    "iteration_time = end_time - start_time  # Calculate the time spent\n",
    "print(f\"full likelihood {key_for_dict}time points took {iteration_time:.4f} seconds\")\n",
    "\n",
    "start_time = time.time()\n",
    "print(f'grid {lat_number}*{lon_number}:Vecchia approximation likelihood using condition size {mm_cond_number}, {params} is {out}')\n",
    "end_time = time.time()  # Record the end time\n",
    "iteration_time = end_time - start_time  # Calculate the time spent\n",
    "print(f\"vecchia {key_for_dict}time points took {iteration_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Center matching data preprocessing\n",
    "\n",
    "filepath = \"C:\\\\Users\\\\joonw\\\\TCO\\\\data_engineering\\\\data_2024\\\\sparse_cen_map24_07.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.025 6.025 7.025 8.025 9.025]\n",
      "[110.025 111.025 112.025 113.025 114.025 115.025 116.025 117.025 118.025\n",
      " 119.025]\n",
      "5\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# Load the one dictionary to set spaital coordinates\n",
    "filepath = \"C:\\\\Users\\\\joonw\\\\TCO\\\\data_engineering\\\\data_2024\\\\sparse_cen_map24_07.pkl\"\n",
    "\n",
    "with open(filepath, 'rb') as pickle_file:\n",
    "    coarse_dict_24_1 = pickle.load(pickle_file)\n",
    "\n",
    "\n",
    "sample_df = coarse_dict_24_1['y24m07day01_hm01:00']\n",
    "\n",
    "\n",
    "lat_lon_resolution = [20,20]\n",
    "\n",
    "# { (20,20):(5,1), (5,5):(20,40) }\n",
    "rho_lat = lat_lon_resolution[0]          \n",
    "rho_lon = lat_lon_resolution[1]\n",
    "lat_n = sample_df['Latitude'].unique()[::rho_lat]\n",
    "lon_n = sample_df['Longitude'].unique()[::rho_lon]\n",
    "\n",
    "lat_number = len(lat_n)\n",
    "print(lat_n)\n",
    "print(lon_n)\n",
    "lon_number = len(lon_n)\n",
    "\n",
    "# Set spatial coordinates for each dataset\n",
    "coarse_dicts = {}\n",
    "for key in coarse_dict_24_1:\n",
    "    tmp_df = coarse_dict_24_1[key]\n",
    "    coarse_filter = (tmp_df['Latitude'].isin(lat_n)) & (tmp_df['Longitude'].isin(lon_n))\n",
    "    coarse_dicts[f\"{2024}_{7:02d}_{key}\"] = tmp_df[coarse_filter].reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(lat_number)\n",
    "print(lon_number)\n",
    "key_idx = sorted(coarse_dicts)\n",
    "if not key_idx:\n",
    "    raise ValueError(\"coarse_dicts is empty\")\n",
    "\n",
    "# extract first hour data because all data shares the same spatial grid\n",
    "data_for_coord = coarse_dicts[key_idx[0]]\n",
    "x1 = data_for_coord['Longitude'].values\n",
    "y1 = data_for_coord['Latitude'].values \n",
    "coords1 = np.stack((x1, y1), axis=-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aggregated_data (100, 5)\n",
      "    Latitude  Longitude  ColumnAmountO3  Hours_elapsed                 Time\n",
      "0      5.025    110.025       273.39870       477721.0  2024-07-01 01:00:00\n",
      "1      9.025    119.025       276.24142       477721.0  2024-07-01 01:00:00\n",
      "2      5.025    116.025       261.51453       477721.0  2024-07-01 01:00:00\n",
      "3      9.025    113.025       268.22525       477721.0  2024-07-01 01:00:00\n",
      "4      6.025    113.025       272.66770       477721.0  2024-07-01 01:00:00\n",
      "5      6.025    119.025       259.94556       477721.0  2024-07-01 01:00:00\n",
      "6      8.025    110.025       269.52832       477721.0  2024-07-01 01:00:00\n",
      "7      8.025    116.025       267.32480       477721.0  2024-07-01 01:00:00\n",
      "8      5.025    112.025       271.26544       477721.0  2024-07-01 01:00:00\n",
      "9      5.025    114.025       268.74588       477721.0  2024-07-01 01:00:00\n",
      "10     5.025    118.025       265.10030       477721.0  2024-07-01 01:00:00\n",
      "11     6.025    111.025       273.67868       477721.0  2024-07-01 01:00:00\n",
      "12     6.025    115.025       268.95825       477721.0  2024-07-01 01:00:00\n",
      "13     6.025    117.025       261.12778       477721.0  2024-07-01 01:00:00\n",
      "14     7.025    112.025       274.86423       477721.0  2024-07-01 01:00:00\n",
      "15     7.025    114.025       272.88828       477721.0  2024-07-01 01:00:00\n",
      "16     7.025    118.025       269.09628       477721.0  2024-07-01 01:00:00\n",
      "17     9.025    111.025       269.09780       477721.0  2024-07-01 01:00:00\n",
      "18     9.025    115.025       271.46658       477721.0  2024-07-01 01:00:00\n",
      "19     9.025    117.025       265.59488       477721.0  2024-07-01 01:00:00\n",
      "20     7.025    110.025       275.12805       477721.0  2024-07-01 01:00:00\n",
      "21     7.025    116.025       268.78418       477721.0  2024-07-01 01:00:00\n",
      "22     8.025    112.025       274.91150       477721.0  2024-07-01 01:00:00\n",
      "23     8.025    114.025       266.06332       477721.0  2024-07-01 01:00:00\n",
      "24     8.025    118.025       269.48280       477721.0  2024-07-01 01:00:00\n",
      "25     5.025    111.025       267.80420       477721.0  2024-07-01 01:00:00\n",
      "26     5.025    113.025       274.71400       477721.0  2024-07-01 01:00:00\n",
      "27     5.025    115.025       269.61200       477721.0  2024-07-01 01:00:00\n",
      "28     5.025    117.025       258.26500       477721.0  2024-07-01 01:00:00\n",
      "29     5.025    119.025       262.53802       477721.0  2024-07-01 01:00:00\n",
      "30     6.025    110.025       272.76187       477721.0  2024-07-01 01:00:00\n",
      "31     6.025    112.025       274.80887       477721.0  2024-07-01 01:00:00\n",
      "32     6.025    114.025       265.47000       477721.0  2024-07-01 01:00:00\n",
      "33     6.025    116.025       262.25824       477721.0  2024-07-01 01:00:00\n",
      "34     6.025    118.025       259.33054       477721.0  2024-07-01 01:00:00\n",
      "35     7.025    111.025       275.46300       477721.0  2024-07-01 01:00:00\n",
      "36     7.025    113.025       273.38373       477721.0  2024-07-01 01:00:00\n",
      "37     7.025    115.025       271.54614       477721.0  2024-07-01 01:00:00\n",
      "38     7.025    117.025       263.11853       477721.0  2024-07-01 01:00:00\n",
      "39     7.025    119.025       269.98206       477721.0  2024-07-01 01:00:00\n",
      "40     8.025    111.025       275.03190       477721.0  2024-07-01 01:00:00\n",
      "41     8.025    113.025       269.39932       477721.0  2024-07-01 01:00:00\n",
      "42     8.025    115.025       267.76382       477721.0  2024-07-01 01:00:00\n",
      "43     8.025    117.025       271.00890       477721.0  2024-07-01 01:00:00\n",
      "44     8.025    119.025       267.10547       477721.0  2024-07-01 01:00:00\n",
      "45     9.025    110.025       265.85100       477721.0  2024-07-01 01:00:00\n",
      "46     9.025    112.025       270.07193       477721.0  2024-07-01 01:00:00\n",
      "47     9.025    114.025       267.41187       477721.0  2024-07-01 01:00:00\n",
      "48     9.025    116.025       270.16638       477721.0  2024-07-01 01:00:00\n",
      "49     9.025    118.025       275.22860       477721.0  2024-07-01 01:00:00\n",
      "0      5.025    110.025       271.97120       477722.0  2024-07-01 02:00:00\n",
      "1      9.025    119.025       275.13210       477722.0  2024-07-01 02:00:00\n",
      "2      5.025    116.025       267.07678       477722.0  2024-07-01 02:00:00\n",
      "3      9.025    113.025       274.01013       477722.0  2024-07-01 02:00:00\n",
      "4      6.025    113.025       273.90906       477722.0  2024-07-01 02:00:00\n",
      "5      6.025    119.025       265.39484       477722.0  2024-07-01 02:00:00\n",
      "6      8.025    110.025       268.24207       477722.0  2024-07-01 02:00:00\n",
      "7      8.025    116.025       267.43265       477722.0  2024-07-01 02:00:00\n",
      "8      5.025    112.025       268.11240       477722.0  2024-07-01 02:00:00\n",
      "9      5.025    114.025       269.70486       477722.0  2024-07-01 02:00:00\n",
      "10     5.025    118.025       259.71732       477722.0  2024-07-01 02:00:00\n",
      "11     6.025    111.025       270.60520       477722.0  2024-07-01 02:00:00\n",
      "12     6.025    115.025       266.83417       477722.0  2024-07-01 02:00:00\n",
      "13     6.025    117.025       258.50574       477722.0  2024-07-01 02:00:00\n",
      "14     7.025    112.025       272.37460       477722.0  2024-07-01 02:00:00\n",
      "15     7.025    114.025       272.28983       477722.0  2024-07-01 02:00:00\n",
      "16     7.025    118.025       264.22394       477722.0  2024-07-01 02:00:00\n",
      "17     9.025    111.025       266.61148       477722.0  2024-07-01 02:00:00\n",
      "18     9.025    115.025       271.38705       477722.0  2024-07-01 02:00:00\n",
      "19     9.025    117.025       266.54935       477722.0  2024-07-01 02:00:00\n",
      "20     7.025    110.025       274.39227       477722.0  2024-07-01 02:00:00\n",
      "21     7.025    116.025       266.89825       477722.0  2024-07-01 02:00:00\n",
      "22     8.025    112.025       274.81204       477722.0  2024-07-01 02:00:00\n",
      "23     8.025    114.025       266.18180       477722.0  2024-07-01 02:00:00\n",
      "24     8.025    118.025       270.51254       477722.0  2024-07-01 02:00:00\n",
      "25     5.025    111.025       267.91803       477722.0  2024-07-01 02:00:00\n",
      "26     5.025    113.025       273.69888       477722.0  2024-07-01 02:00:00\n",
      "27     5.025    115.025       267.31940       477722.0  2024-07-01 02:00:00\n",
      "28     5.025    117.025       262.33942       477722.0  2024-07-01 02:00:00\n",
      "29     5.025    119.025       262.34775       477722.0  2024-07-01 02:00:00\n",
      "30     6.025    110.025       274.09958       477722.0  2024-07-01 02:00:00\n",
      "31     6.025    112.025       273.17007       477722.0  2024-07-01 02:00:00\n",
      "32     6.025    114.025       267.18130       477722.0  2024-07-01 02:00:00\n",
      "33     6.025    116.025       264.55917       477722.0  2024-07-01 02:00:00\n",
      "34     6.025    118.025       258.30252       477722.0  2024-07-01 02:00:00\n",
      "35     7.025    111.025       273.95370       477722.0  2024-07-01 02:00:00\n",
      "36     7.025    113.025       270.30795       477722.0  2024-07-01 02:00:00\n",
      "37     7.025    115.025       273.31018       477722.0  2024-07-01 02:00:00\n",
      "38     7.025    117.025       261.75385       477722.0  2024-07-01 02:00:00\n",
      "39     7.025    119.025       267.54270       477722.0  2024-07-01 02:00:00\n",
      "40     8.025    111.025       274.11243       477722.0  2024-07-01 02:00:00\n",
      "41     8.025    113.025       273.81723       477722.0  2024-07-01 02:00:00\n",
      "42     8.025    115.025       265.74982       477722.0  2024-07-01 02:00:00\n",
      "43     8.025    117.025       268.27216       477722.0  2024-07-01 02:00:00\n",
      "44     8.025    119.025       270.90940       477722.0  2024-07-01 02:00:00\n",
      "45     9.025    110.025       265.47540       477722.0  2024-07-01 02:00:00\n",
      "46     9.025    112.025       267.14304       477722.0  2024-07-01 02:00:00\n",
      "47     9.025    114.025       273.08112       477722.0  2024-07-01 02:00:00\n",
      "48     9.025    116.025       270.16122       477722.0  2024-07-01 02:00:00\n",
      "49     9.025    118.025       272.31113       477722.0  2024-07-01 02:00:00\n"
     ]
    }
   ],
   "source": [
    "mm_cond_number = 10\n",
    "key_for_dict = 2\n",
    "\n",
    "instance = orbitmap.MakeOrbitdata()\n",
    "s_dist = cdist(coords1, coords1, 'euclidean')\n",
    "ord_mm, _ = instance.maxmin_naive(s_dist, 0)\n",
    "\n",
    "data_for_coord = data_for_coord.iloc[ord_mm].reset_index(drop=True)\n",
    "coords1_reordered = np.stack((data_for_coord['Longitude'].values, data_for_coord['Latitude'].values), axis=-1)\n",
    "nns_map = instance.find_nns_naive(locs=coords1_reordered, dist_fun='euclidean', max_nn=mm_cond_number)\n",
    "\n",
    "\n",
    "\n",
    "analysis_data_map = {}\n",
    "for i in range(key_for_dict):\n",
    "    tmp = coarse_dicts[key_idx[i]]\n",
    "    tmp = tmp.iloc[ord_mm].reset_index(drop=True)  \n",
    "    analysis_data_map[key_idx[i]] = tmp\n",
    "\n",
    "aggregated_data = pd.DataFrame()\n",
    "for i in range((key_for_dict)):\n",
    "    tmp = coarse_dicts[key_idx[i]]\n",
    "    tmp = tmp.iloc[ord_mm].reset_index(drop=True)  \n",
    "    aggregated_data = pd.concat((aggregated_data, tmp), axis=0)\n",
    "\n",
    "\n",
    "print(f'aggregated_data {aggregated_data.shape}')\n",
    "print(aggregated_data.to_string())\n",
    "\n",
    "\n",
    "#####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid 5*10:Full likelihood using [60, 8.25, 8.25, 0.5, 0.5, 0.5] is 274.19630949798125\n",
      "full likelihood 2time points took 0.0768 seconds\n",
      "grid 5*10:Vecchia approximation likelihood using condition size 10, [60, 8.25, 8.25, 0.5, 0.5, 0.5] is 291.7490506399612\n",
      "vecchia 2time points took 0.0000 seconds\n"
     ]
    }
   ],
   "source": [
    "params = [60,8.25,8.25,0.5,0.5,0.5]\n",
    "\n",
    "instance = kernels.matern_spatio_temporal(smooth = 0.5, input_map = analysis_data_map, nns_map = nns_map, mm_cond_number = mm_cond_number )\n",
    "# data = data.iloc[ord,:]\n",
    "out = instance.vecchia_likelihood(params)\n",
    "\n",
    "start_time = time.time()\n",
    "print(f'grid {lat_number}*{lon_number}:Full likelihood using {params} is {instance.full_likelihood(params, aggregated_data, aggregated_data[\"ColumnAmountO3\"])}')\n",
    "end_time = time.time()  # Record the end time\n",
    "iteration_time = end_time - start_time  # Calculate the time spent\n",
    "print(f\"full likelihood {key_for_dict}time points took {iteration_time:.4f} seconds\")\n",
    "\n",
    "start_time = time.time()\n",
    "print(f'grid {lat_number}*{lon_number}:Vecchia approximation likelihood using condition size {mm_cond_number}, {params} is {out}')\n",
    "end_time = time.time()  # Record the end time\n",
    "iteration_time = end_time - start_time  # Calculate the time spent\n",
    "print(f\"vecchia {key_for_dict}time points took {iteration_time:.4f} seconds\")\n",
    "\n",
    "# 2137.099\n",
    "# 2499.2030"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jl2815",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
