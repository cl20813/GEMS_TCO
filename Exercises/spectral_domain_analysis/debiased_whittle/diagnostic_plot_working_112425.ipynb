{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0584eb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "gems_tco_path = \"/Users/joonwonlee/Documents/GEMS_TCO-1/src\"\n",
    "\n",
    "# --- Standard Libraries ---\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import copy\n",
    "import cmath\n",
    "import pickle\n",
    "import logging\n",
    "import argparse\n",
    "\n",
    "# Path configuration (only run once)\n",
    "sys.path.append(gems_tco_path)\n",
    "\n",
    "# --- Third-Party Libraries ---\n",
    "from pathlib import Path\n",
    "from typing import Optional, List, Tuple, Dict, Any, Callable\n",
    "from json import JSONEncoder\n",
    "\n",
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import BallTree\n",
    "import typer\n",
    "\n",
    "# Torch and Numerical Libraries\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.fft\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Parameter\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# --- Custom (GEMS_TCO) Imports ---\n",
    "import GEMS_TCO\n",
    "from GEMS_TCO import kernels_reparam_space_time \n",
    "from GEMS_TCO import data_preprocess, data_preprocess as dmbh\n",
    "from GEMS_TCO import orderings as _orderings \n",
    "\n",
    "from GEMS_TCO import alg_optimization, alg_opt_Encoder\n",
    "from GEMS_TCO import configuration as config\n",
    "from GEMS_TCO.data_loader import load_data2\n",
    "from GEMS_TCO import debiased_whittle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9357e181",
   "metadata": {},
   "source": [
    "load monthly data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e0734e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subsetting data to lat: [3, 5], lon: [129, 133.0]\n"
     ]
    }
   ],
   "source": [
    "space: List[str] = ['1', '1']\n",
    "lat_lon_resolution = [int(s) for s in space]\n",
    "mm_cond_number: int = 8\n",
    "years = ['2024']\n",
    "month_range = [7] \n",
    "\n",
    "output_path = input_path = Path(config.mac_estimates_day_path)\n",
    "data_load_instance = load_data2(config.mac_data_load_path)\n",
    "\n",
    "#lat_range_input = [1, 3]\n",
    "#lon_range_input = [125.0, 129.0]\n",
    "\n",
    "lat_range_input=[3,5]      \n",
    "lon_range_input=[129, 133.0] \n",
    "\n",
    "df_map, ord_mm, nns_map = data_load_instance.load_maxmin_ordered_data_bymonthyear(\n",
    "lat_lon_resolution=lat_lon_resolution, \n",
    "mm_cond_number=mm_cond_number,\n",
    "years_=years, \n",
    "months_=month_range,\n",
    "\n",
    "lat_range=lat_range_input,   \n",
    "lon_range=lon_range_input\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e49bbcdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([23040, 4])\n"
     ]
    }
   ],
   "source": [
    "daily_aggregated_tensors_dw = [] \n",
    "daily_hourly_maps_dw = []      \n",
    "\n",
    "daily_aggregated_tensors_vecc = [] \n",
    "daily_hourly_maps_vecc = []   \n",
    "\n",
    "\n",
    "for day_index in range(31):\n",
    "    hour_start_index = day_index * 8\n",
    "    hour_end_index = (day_index + 1) * 8\n",
    "    #hour_end_index = day_index*8 + 1\n",
    "    hour_indices = [hour_start_index, hour_end_index]\n",
    "\n",
    "    day_hourly_map, day_aggregated_tensor = data_load_instance.load_working_data(\n",
    "    df_map, \n",
    "    hour_indices, \n",
    "    ord_mm= None,  # or just omit it\n",
    "    dtype=torch.float64, # or just omit it \n",
    "    keep_ori=False  #keep_exact_loc\n",
    "    )\n",
    "\n",
    "    daily_aggregated_tensors_dw.append( day_aggregated_tensor )\n",
    "    daily_hourly_maps_dw.append( day_hourly_map )\n",
    "\n",
    "    day_hourly_map, day_aggregated_tensor = data_load_instance.load_working_data(\n",
    "    df_map, \n",
    "    hour_indices, \n",
    "    ord_mm= ord_mm,  # or just omit it\n",
    "    dtype=torch.float64, # or just omit it \n",
    "    keep_ori=False  #keep_exact_loc\n",
    "    )\n",
    "\n",
    "    daily_aggregated_tensors_vecc.append( day_aggregated_tensor )\n",
    "    daily_hourly_maps_vecc.append( day_hourly_map )\n",
    "print(daily_aggregated_tensors_vecc[0].shape)\n",
    "#print(daily_hourly_maps[0])\n",
    "nn = daily_aggregated_tensors_vecc[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13031962",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.fft import fftshift\n",
    "import cmath\n",
    "\n",
    "# =========================================================================\n",
    "# 1. Tapering and Modeling Functions\n",
    "# =========================================================================\n",
    "def cgn_hamming(u, n1, n2):\n",
    "    \"\"\"Computes a 2D Hamming window.\"\"\"\n",
    "    u1, u2 = u\n",
    "    u1_tensor = u1 if isinstance(u1, torch.Tensor) else torch.tensor(u1, dtype=torch.float32)\n",
    "    u2_tensor = u2 if isinstance(u2, torch.Tensor) else torch.tensor(u2, dtype=torch.float32)\n",
    "    hamming1 = 0.54 + 0.46 * torch.cos(2 * torch.pi * u1_tensor / n1)\n",
    "    hamming2 = 0.54 + 0.46 * torch.cos(2 * torch.pi * u2_tensor / n2)\n",
    "    return hamming1 * hamming2\n",
    "\n",
    "def cgn_2dbartlett(u, n1, n2):\n",
    "    \"\"\"Computes a 2D Bartlett window function (triangular window).\"\"\"\n",
    "    u1, u2 = u\n",
    "    return (1 - torch.abs(u1) / n1) * (1 - torch.abs(u2) / n2) \n",
    "\n",
    "# ✅ CHANGE: Replaced the old cov_x with the new, pure PyTorch Matérn model.\n",
    "def cov_x(u1, u2, t, params, nu):\n",
    "    \"\"\"\n",
    "    Covariance function for PLOTTING using the Matérn model (nu=1.5).\n",
    "    It expects parameters in their natural space.\n",
    "    \"\"\"\n",
    "    if nu != 1.5:\n",
    "        raise ValueError(\"This implementation of cov_x is only for nu=1.5\")\n",
    "\n",
    "    sigmasq, range_lat, range_lon, advec_lat, advec_lon, beta, nugget = params\n",
    "    \n",
    "    distance_sq = (u1 / range_lat - advec_lat * t)**2 + (u2 / range_lon - advec_lon * t)**2 + (beta * t)**2\n",
    "    distance = torch.sqrt(distance_sq + 1e-9)\n",
    "    \n",
    "    matern_cov = sigmasq * (1 + distance) * torch.exp(-distance)\n",
    "    \n",
    "    return torch.where(distance_sq > 1e-9, matern_cov, sigmasq + nugget)\n",
    "\n",
    "def cov_first_difference(u1, u2, t, params, nu):\n",
    "    \"\"\"Computes the autocovariance of the first-difference-filtered process.\"\"\"\n",
    "    delta1, delta2 = 0.044, 0.063\n",
    "    stencil_weights = {(0, 0): -2, (1, 0): 1, (0, 1): 1}\n",
    "    cov = torch.zeros_like(u1, dtype=torch.float32)\n",
    "    for (a, b), w_ab in stencil_weights.items():\n",
    "        for (c, d), w_cd in stencil_weights.items():\n",
    "            lag_x = (u1 + a - c) * delta1\n",
    "            lag_y = (u2 + b - d) * delta2\n",
    "            cov += w_ab * w_cd * cov_x(lag_x, lag_y, t, params, nu)\n",
    "    return cov\n",
    "\n",
    "def cn_bar(u1, u2, t, params, n1, n2, taper_func, nu):\n",
    "    \"\"\"Computes the tapered covariance for the filtered field.\"\"\"\n",
    "    u = (u1, u2)\n",
    "    return cov_first_difference(u1, u2, t, params, nu) * taper_func(u, n1, n2)\n",
    "\n",
    "def expected_periodogram_fft_multivariate(params, n1, n2, p, taper_func, nu):\n",
    "    \"\"\"Calculates the expected periodogram for the FILTERED field.\"\"\"\n",
    "    product_tensor = torch.zeros((n1, n2, p, p), dtype=torch.complex64)\n",
    "    t_lags = torch.arange(p, dtype=torch.float32)\n",
    "    u1_mesh, u2_mesh = torch.meshgrid(torch.arange(n1, dtype=torch.float32), torch.arange(n2, dtype=torch.float32), indexing='ij')\n",
    "\n",
    "    for q in range(p):\n",
    "        for r in range(p):\n",
    "            t = t_lags[q] - t_lags[r]\n",
    "            product_tensor[:, :, q, r] = cn_bar(u1_mesh, u2_mesh, t, params, n1, n2, taper_func, nu)\n",
    "\n",
    "    fft_result = torch.fft.fft2(product_tensor, dim=(-4, -3))\n",
    "    normalization_factor = 1 / (2 * cmath.pi)**2\n",
    "    return fft_result * normalization_factor\n",
    "\n",
    "# =========================================================================\n",
    "# 2. Data Processing Functions\n",
    "# =========================================================================\n",
    "def generate_Jvector_final(tensor_list, taper_func, lat_col=0, lon_col=1, val_col=2):\n",
    "    p = len(tensor_list)\n",
    "    if p == 0:\n",
    "        return torch.empty(0, 0, 0), 0, 0, 0\n",
    "\n",
    "    all_lats = torch.cat([t[:, lat_col] for t in tensor_list])\n",
    "    all_lons = torch.cat([t[:, lon_col] for t in tensor_list])\n",
    "    unique_lats, unique_lons = torch.unique(all_lats), torch.unique(all_lons)\n",
    "    n1, n2 = len(unique_lats), len(unique_lons)\n",
    "\n",
    "    lat_map = {lat.item(): i for i, lat in enumerate(unique_lats)}\n",
    "    lon_map = {lon.item(): i for i, lon in enumerate(unique_lons)}\n",
    "\n",
    "    u1_mesh, u2_mesh = torch.meshgrid(torch.arange(n1, dtype=torch.float32), torch.arange(n2, dtype=torch.float32), indexing='ij')\n",
    "    taper_grid = taper_func((u1_mesh, u2_mesh), n1, n2)\n",
    "\n",
    "    fft_results = []\n",
    "    for tensor in tensor_list:\n",
    "        data_grid = torch.zeros((n1, n2), dtype=torch.float32)\n",
    "        for row in tensor:\n",
    "             i = lat_map[row[lat_col].item()]\n",
    "             j = lon_map[row[lon_col].item()]\n",
    "             data_grid[i, j] = row[val_col]\n",
    "        \n",
    "        data_grid_tapered = data_grid * taper_grid\n",
    "        fft_results.append(torch.fft.fft2(data_grid_tapered))\n",
    "\n",
    "    J_vector_tensor = torch.stack(fft_results, dim=2)\n",
    "\n",
    "    H = torch.sum(taper_grid**2)\n",
    "    norm_factor = torch.sqrt(1 / H) / (2 * cmath.pi)\n",
    "    \n",
    "    return J_vector_tensor * norm_factor, n1, n2, p\n",
    "\n",
    "\n",
    "def calculate_sample_periodogram_vectorized(J_vector_tensor):\n",
    "    \"\"\"Efficient vectorized version.\"\"\"\n",
    "    J_col = J_vector_tensor.unsqueeze(-1)\n",
    "    J_row_conj = J_vector_tensor.unsqueeze(-2).conj()\n",
    "    return J_col @ J_row_conj\n",
    "\n",
    "# =========================================================================\n",
    "# 3. Main Execution Logic for Plotting\n",
    "# =========================================================================\n",
    "if __name__ == '__main__':\n",
    "    # --- IMPORTANT ---\n",
    "    # Before running, ensure your `processed_df_diff1` list of tensors is loaded.\n",
    "    \n",
    "    # --- Configuration ---\n",
    "    DAY_TO_RUN = 1\n",
    "    TAMPERING_FUNC = cgn_2dbartlett\n",
    "    # ✅ Make sure this matches the nu used during training\n",
    "    NU_SMOOTHNESS = 1.5\n",
    "    \n",
    "    print(f\"--- Day {DAY_TO_RUN} Diagnostic Plot for Matérn (nu=1.5) Model ---\")\n",
    "    \n",
    "    # --- Define the parameters you want to test ---\n",
    "    # ✅ Use the final, optimized parameters from your Matérn model training run\n",
    "    best_params = [22.54, 3.00, 4.00, 0.004, -0.08, 0.01, 2.36] # Example parameters\n",
    "    print(f\"Using pre-defined parameters: {best_params}\")\n",
    "    \n",
    "    # --- Data Preparation ---\n",
    "    cur_df = processed_df_diff1[DAY_TO_RUN - 1]\n",
    "    unique_times = torch.unique(cur_df[:, 3])\n",
    "    tensor_list = [cur_df[cur_df[:, 3] == t_val] for t_val in unique_times]\n",
    "    \n",
    "    # --- Calculation ---\n",
    "    J_vec, n1, n2, p = generate_Jvector_final(tensor_list, TAMPERING_FUNC, lat_col=0, lon_col=1, val_col=2)\n",
    "    print(f\"Data grid: {n1}x{n2} spatial points, {p} time points.\")\n",
    "    \n",
    "    I_sample = calculate_sample_periodogram_vectorized(J_vec)\n",
    "    # ✅ Pass the nu parameter to the calculation\n",
    "    I_expected = expected_periodogram_fft_multivariate(best_params, n1, n2, p, TAMPERING_FUNC, nu=NU_SMOOTHNESS)\n",
    "\n",
    "    I_sample_shifted = torch.fft.fftshift(I_sample, dim=(-4, -3))\n",
    "    I_expected_shifted = torch.fft.fftshift(I_expected, dim=(-4, -3))\n",
    "    \n",
    "    epsilon = 1e-15\n",
    "    ratio_complex = I_sample_shifted / (I_expected_shifted + epsilon)\n",
    "    \n",
    "    diagonal_ratio = torch.diagonal(ratio_complex, dim1=-2, dim2=-1) \n",
    "    ratio_magnitude_avg = torch.mean(torch.abs(diagonal_ratio), dim=-1)\n",
    "    \n",
    "    # --- Plotting Data Preparation ---\n",
    "    freq_lat = np.fft.fftfreq(n1)\n",
    "    freq_lon = np.fft.fftfreq(n2)\n",
    "    freq_lon_shifted, freq_lat_shifted = fftshift(freq_lon), fftshift(freq_lat)\n",
    "    freq_grid_lon, freq_grid_lat = np.meshgrid(freq_lon_shifted, freq_lat_shifted)\n",
    "    frequency_norm = np.sqrt(freq_grid_lat**2 + freq_grid_lon**2)\n",
    "    \n",
    "    norm_flat = frequency_norm.flatten()\n",
    "    ratio_flat = ratio_magnitude_avg.detach().numpy().flatten()\n",
    "\n",
    "    # --- Plotting ---\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    plt.scatter(norm_flat, ratio_flat, s=10, alpha=0.6)\n",
    "    plt.axhline(1.0, color='r', linestyle='--', linewidth=2, label='Ideal Ratio (1.0)')\n",
    "    plt.yscale('log')\n",
    "    plt.ylim(1e-2, 1e2)\n",
    "    plt.title(f'Diagnostic Plot for Matérn Model (nu={NU_SMOOTHNESS}, Day {DAY_TO_RUN})')\n",
    "    plt.xlabel(r'Frequency Norm $||\\boldsymbol{\\lambda}||$')\n",
    "    plt.ylabel(r'Average Diagonal Ratio $|\\mathbf{I} / E[\\mathbf{I}]|$ (Log Scale)')\n",
    "    plt.legend()\n",
    "    plt.grid(True, which=\"both\", ls=\"--\")\n",
    "    \n",
    "    print(f\"\\nRatio Statistics: Max={np.max(ratio_flat):.2e}, Min={np.min(ratio_flat):.2e}, Mean={np.mean(ratio_flat):.2f}\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "faiss_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
