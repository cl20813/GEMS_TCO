{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joonw\\TCO\\GEMS_TCO-1\\GEMS_TCO\\kernels.py:60: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  '''\n"
     ]
    }
   ],
   "source": [
    "# work environment: jl2815\n",
    "# Standard libraries\n",
    "import sys\n",
    "import logging\n",
    "import argparse # Argument parsing\n",
    "import math\n",
    "from collections import defaultdict\n",
    "import concurrent\n",
    "from concurrent.futures import ThreadPoolExecutor  # Importing specific executor for clarity\n",
    "import time\n",
    "\n",
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Nearest neighbor search\n",
    "import sklearn\n",
    "from sklearn.neighbors import BallTree\n",
    "\n",
    "# Special functions and optimizations\n",
    "from scipy.special import gamma, kv  # Bessel function and gamma function\n",
    "from scipy.stats import multivariate_normal  # Simulation\n",
    "from scipy.optimize import minimize\n",
    "from scipy.spatial.distance import cdist  # For space and time distance\n",
    "from scipy.spatial import distance  # Find closest spatial point\n",
    "from scipy.optimize import differential_evolution\n",
    "\n",
    "# Plotting and visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Type hints\n",
    "from typing import Callable, Union, Tuple\n",
    "\n",
    "# Add your custom path\n",
    "sys.path.append(\"/cache/home/jl2815/tco\")\n",
    "\n",
    "# Custom imports\n",
    "from GEMS_TCO import orbitmap \n",
    "from GEMS_TCO import kernels \n",
    "from GEMS_TCO import evaluate\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated data shape: (1600, 5)\n"
     ]
    }
   ],
   "source": [
    "lat_lon_resolution = [10,10]\n",
    "mm_cond_number = 10\n",
    "params= [60, 5.25, 5.25, 0.2, 0.5, 5]\n",
    "# params= [20, 8.25, 5.25, 0.2, 0.5, 5]\n",
    "key_for_dict= 8\n",
    "\n",
    "\n",
    "# Load the one dictionary to set spaital coordinates\n",
    "filepath = \"C:/Users/joonw/TCO/GEMS_data/data_2023/sparse_cen_map23_01.pkl\"\n",
    "\n",
    "with open(filepath, 'rb') as pickle_file:\n",
    "    coarse_dict_24_1 = pickle.load(pickle_file)\n",
    "\n",
    "sample_df = coarse_dict_24_1['y23m01day01_hm02:12']\n",
    "\n",
    "sample_key = coarse_dict_24_1.get('y23m01day01_hm02:12')\n",
    "if sample_key is None:\n",
    "    print(\"Key 'y23m01day01_hm02:12' not found in the dictionary.\")\n",
    "\n",
    "# { (20,20):(5,1), (5,5):(20,40) }\n",
    "rho_lat = lat_lon_resolution[0]          \n",
    "rho_lon = lat_lon_resolution[1]\n",
    "lat_n = sample_df['Latitude'].unique()[::rho_lat]\n",
    "lon_n = sample_df['Longitude'].unique()[::rho_lon]\n",
    "\n",
    "lat_number = len(lat_n)\n",
    "lon_number = len(lon_n)\n",
    "\n",
    "# Set spatial coordinates for each dataset\n",
    "coarse_dicts = {}\n",
    "\n",
    "years = ['2024']\n",
    "for year in years:\n",
    "    for month in range(7, 8):  # Iterate over all months\n",
    "        filepath = f\"C:/Users/joonw/TCO/GEMS_data/data_{year}/sparse_cen_map{year[2:]}_{month:02d}.pkl\"\n",
    "        with open(filepath, 'rb') as pickle_file:\n",
    "            loaded_map = pickle.load(pickle_file)\n",
    "            for key in loaded_map:\n",
    "                tmp_df = loaded_map[key]\n",
    "                coarse_filter = (tmp_df['Latitude'].isin(lat_n)) & (tmp_df['Longitude'].isin(lon_n))\n",
    "                coarse_dicts[f\"{year}_{month:02d}_{key}\"] = tmp_df[coarse_filter].reset_index(drop=True)\n",
    "\n",
    "\n",
    "key_idx = sorted(coarse_dicts)\n",
    "if not key_idx:\n",
    "    raise ValueError(\"coarse_dicts is empty\")\n",
    "\n",
    "# extract first hour data because all data shares the same spatial grid\n",
    "data_for_coord = coarse_dicts[key_idx[0]]\n",
    "x1 = data_for_coord['Longitude'].values\n",
    "y1 = data_for_coord['Latitude'].values \n",
    "coords1 = np.stack((x1, y1), axis=-1)\n",
    "\n",
    "instance = orbitmap.MakeOrbitdata(data_for_coord, lat_s=5, lat_e=10, lon_s=110, lon_e=120)\n",
    "s_dist = cdist(coords1, coords1, 'euclidean')\n",
    "ord_mm, _ = instance.maxmin_naive(s_dist, 0)\n",
    "\n",
    "data_for_coord = data_for_coord.iloc[ord_mm].reset_index(drop=True)\n",
    "coords1_reordered = np.stack((data_for_coord['Longitude'].values, data_for_coord['Latitude'].values), axis=-1)\n",
    "nns_map = instance.find_nns_naive(locs=coords1_reordered, dist_fun='euclidean', max_nn=mm_cond_number)\n",
    "\n",
    "\n",
    "key_for_dict= 8\n",
    "analysis_data_map = {}\n",
    "for i in range(key_for_dict):\n",
    "    tmp = coarse_dicts[key_idx[i]]\n",
    "    tmp['Hours_elapsed'] = np.round(tmp['Hours_elapsed'])\n",
    "    # tmp = tmp.iloc[ord_mm].reset_index(drop=True)  \n",
    "    tmp = tmp.iloc[ord_mm, :4].to_numpy()\n",
    "    # Sort by the first two columns\n",
    "    sorted_indices = np.lexsort((tmp[:, 0], tmp[:, 1]))\n",
    "    tmp = tmp[sorted_indices]\n",
    "    analysis_data_map[key_idx[i]] = tmp\n",
    "\n",
    "aggregated_data = pd.DataFrame()\n",
    "for i in range((key_for_dict)):\n",
    "    tmp = coarse_dicts[key_idx[i]]\n",
    "    tmp = tmp.iloc[ord_mm].reset_index(drop=True)  \n",
    "    tmp = tmp.iloc[ord_mm].reset_index(drop=True)  \n",
    "    aggregated_data = pd.concat((aggregated_data, tmp), axis=0)\n",
    "          \n",
    "aggregated_np = aggregated_data.iloc[:,:4].to_numpy()\n",
    "sorted_indices = np.lexsort((aggregated_np[:, 0], aggregated_np[:, 1]))\n",
    "aggregated_np = aggregated_np[sorted_indices]\n",
    "print(f'Aggregated data shape: {aggregated_data.shape}')\n",
    "\n",
    "\n",
    "\n",
    "instance = kernels.likelihood_function(smooth=0.5, input_map=analysis_data_map, nns_map=nns_map, mm_cond_number=mm_cond_number)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Initialize the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Select the columns to scale (0, 1, and 3)\n",
    "columns_to_scale = [ 3]\n",
    "\n",
    "aggregated_np2 = aggregated_np.copy()\n",
    "# Fit and transform the selected columns\n",
    "aggregated_np2[:, columns_to_scale] = scaler.fit_transform(aggregated_np2[:, columns_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(4312.9922255818)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance.full_likelihood(params, aggregated_np[:,:4],aggregated_np[:,2], instance.matern_cov_yx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-07 s\n",
      "\n",
      "Total time: 0.733604 s\n",
      "File: c:\\Users\\joonw\\TCO\\GEMS_TCO-1\\GEMS_TCO\\kernels.py\n",
      "Function: matern_cov_yx at line 162\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   162                                               def matern_cov_yx(self,params: Tuple[float,float,float,float,float,float], y: np.ndarray, x: np.ndarray) -> np.ndarray:\n",
      "   163                                               \n",
      "   164         1         11.0     11.0      0.0          sigmasq, range_lat, range_lon, advec, beta, nugget  = params\n",
      "   165                                                   # Validate inputs\n",
      "   166         1          7.0      7.0      0.0          if y is None or x is None:\n",
      "   167                                                       raise ValueError(\"Both y and x_df must be provided.\")\n",
      "   168                                                   # Extract values\n",
      "   169         1         24.0     24.0      0.0          x1 = x[:, 0]\n",
      "   170         1          6.0      6.0      0.0          y1 = x[:, 1]\n",
      "   171         1          6.0      6.0      0.0          t1 = x[:, 3]\n",
      "   172                                           \n",
      "   173         1          6.0      6.0      0.0          x2 = y[:, 0]\n",
      "   174         1          7.0      7.0      0.0          y2 = y[:, 1]\n",
      "   175         1          5.0      5.0      0.0          t2 = y[:, 3] # hour\n",
      "   176                                           \n",
      "   177         1        888.0    888.0      0.0          spat_coord1 = np.stack((x1- advec*t1, y1 - advec*t1), axis=-1)\n",
      "   178         1        340.0    340.0      0.0          spat_coord2 = np.stack((x2- advec*t2, y2 - advec*t2), axis=-1)\n",
      "   179                                           \n",
      "   180         1        401.0    401.0      0.0          coords1 = np.hstack ((spat_coord1, (beta * t1).reshape(-1,1) ))\n",
      "   181         1        297.0    297.0      0.0          coords2 = np.hstack ((spat_coord2, (beta * t2).reshape(-1,1) ))\n",
      "   182                                           \n",
      "   183         1        287.0    287.0      0.0          sqrt_range_mat = np.diag([ 1/np.sqrt(range_lat), 1/np.sqrt(range_lon)])\n",
      "   184         1         11.0     11.0      0.0          self.sqrt_range_mat = sqrt_range_mat\n",
      "   185                                           \n",
      "   186         1    1030967.0    1e+06     14.1          distance = self.custom_distance_matrix(coords1, coords2, self.sqrt_range_mat)\n",
      "   187                                                   # Initialize the covariance matrix with zeros\n",
      "   188         1         12.0     12.0      0.0          out = distance\n",
      "   189                                                   \n",
      "   190                                                   # Compute the covariance for non-zero distances\n",
      "   191         1      16313.0  16313.0      0.2          non_zero_indices = distance != 0\n",
      "   192         1       1091.0   1091.0      0.0          if np.any(non_zero_indices):\n",
      "   193         3     166458.0  55486.0      2.3              out[non_zero_indices] = (sigmasq * (2**(1-self.smooth)) / gamma(self.smooth) *\n",
      "   194         1     109796.0 109796.0      1.5                                      (distance[non_zero_indices] )**self.smooth *\n",
      "   195         1    5842963.0    6e+06     79.6                                      kv(self.smooth, distance[non_zero_indices]))\n",
      "   196         1      11220.0  11220.0      0.2          out[~non_zero_indices] = sigmasq\n",
      "   197                                           \n",
      "   198                                                   # Add a small jitter term to the diagonal for numerical stability\n",
      "   199         1     154888.0 154888.0      2.1          out += np.eye(out.shape[0]) * nugget\n",
      "   200                                           \n",
      "   201         1         35.0     35.0      0.0          return out\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from line_profiler import LineProfiler\n",
    "lp = LineProfiler()\n",
    "lp_wrapper = lp(instance.matern_cov_yx)\n",
    "lp_wrapper(params, aggregated_np2[:,:4],aggregated_np2[:,:4])\n",
    "lp.print_stats()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jl2815",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
