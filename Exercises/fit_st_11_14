### copy ozone data and python file to Amarel HPC
scp "C:\\Users\\joonw\\TCO\\data_engineering\\data_24_07_0130_N510_E110120.csv" jl2815@amarel.rutgers.edu:/home/jl2815/tco/data/data_N510_E110120
scp "C:\Users\joonw\TCO\newpipeline\Exercises\fit_st_11_14.py" jl2815@amarel.rutgers.edu:/home/jl2815/tco/exercise

### Copy python from Amarel HPC to my computer
scp jl2815@amarel.rutgers.edu:/home/jl2815/tco/exercise/fit_st_11_14.py "C:\Users\joonw\TCO\newpipeline\Exercises"

### Quick run using srun

ssh jl2815@amarel.rutgers.edu
module use /projects/community/modulefiles            # # Ensure the module path is added. Without this, I can't load 2024.06-ts840
module load anaconda/2024.06-ts840 
conda activate gems_tco             #sigmasq (0.05,600), range_ (0.05,600), advec (-200,200), beta (0,600), nugget (0,600)

srun --cpus-per-task=32 --mem=100G --time=05:00:00 python /home/jl2815/tco/exercise/fit_st_11_14.py --key 1 --rho 8 --v 1 --params 10 10 10 10 5 --mm_cond_number 10 --bounds 0.05 600 0.05 600 -200 200 0.05 600 0.05 600  

## sbatch 

nano fit_st_11_res04.sh                  # open a new text editor

'''
#!/bin/bash
#SBATCH --job-name=fit_st_11_res04        # Job name
#SBATCH --output=/home/jl2815/GEMS/fit_st_11_res04_%j.out            # Standard output file (%j = JobID)
#SBATCH --error=/home/jl2815/GEMS/fit_st_11_res04_%j.err              # Standard error file (%j = JobID)
#SBATCH --time=72:00:00                   # Maximum time 
#SBATCH --ntasks=1                        # Number of tasks
#SBATCH --cpus-per-task=32                 # Number of CPU cores per task
#SBATCH --mem=220G                          # Memory per node
#SBATCH --partition=main               # Partition to submit to

# Load the Anaconda module to use srun 

module purge                                     # unload every other environment to avoid conflict
module use /projects/community/modulefiles                  # without this, I can't load 2024.06-ts840
module load anaconda/2024.06-ts840 

# Initialize Conda
eval "$(conda shell.bash hook)"                  # Initialize Conda for SLURM environment
conda activate gems_tco
# Add the GEMS_TCO package directory to PYTHONPATH
export PYTHONPATH=$PYTHONPATH:/home/jl2815/tco/GEMS_TCO

#
echo "Current date and time: $(date)"
# export OMP_NUM_THREADS=1

# rho 1: 20000 4: 1250 5: 800 6:556 7:409 8:313
# Run the Python script

echo "rho 10 then 8 python /home/jl2815/tco/exercise/fit_st_11_14.py --key 1 --rho 8 --v 0.5 --params 50 5.19 -200 600 0.5 --mm_cond_number 10 --bounds 0.05 800 0.05 50 -250 250 0.05 800 0.05 10"
srun python /home/jl2815/tco/exercise/fit_st_bylat_11_14.py --key 1 --rho 10 --v 0.5 --params 50 5.19 -200 600 0.5 --mm_cond_number 10 --bounds 0.05 800 0.05 50 -250 250 0.05 800 0.05 10
srun python /home/jl2815/tco/exercise/fit_st_bylat_11_14.py --key 1 --rho 8 --v 0.5 --params 50 5.19 -200 600 0.5 --mm_cond_number 10 --bounds 0.05 800 0.05 50 -250 250 0.05 800 0.05 10


# Store the job ID in a variable
JOBID=$SLURM_JOBID

# Run sacct to get resource usage details
sacct --units=G --format=MaxRSS,MaxDiskRead,MaxDiskWrite,Elapsed,NodeList -j $JOBID

```
sbatch fit_st_11_res04.sh




##################################################################################################
##################################################################################################

<by latitude>
scp "C:\Users\joonw\TCO\newpipeline\Exercises\fit_st_bylat_11_16.py" jl2815@amarel.rutgers.edu:/home/jl2815/tco/exercise

### Copy python from Amarel HPC to my computer
scp jl2815@amarel.rutgers.edu:/home/jl2815/tco/exercise/fit_st_bylat_11_16.py "C:\Users\joonw\TCO\newpipeline\Exercises"


ssh jl2815@amarel.rutgers.edu
module use /projects/community/modulefiles            # # Ensure the module path is added. Without this, I can't load 2024.06-ts840
module load anaconda/2024.06-ts840 
conda activate gems_tco             #sigmasq (0.05,600), range_ (0.05,600), advec (-200,200), beta (0,600), nugget (0,600)

## Note that key 1 means I ran only 0 day data (up to k-1 days) and key2 can take 5,6,7,8,9 so that it means I take a slice of latitude between 5 and 5+1    # --params 33.43 1.46 -200 600 0.5
srun --cpus-per-task=32 --mem=150G --time=05:00:00 python /home/jl2815/tco/exercise/fit_st_bylat_11_16.py --key 1 --lat_idx 5 --rho 8 --v 0.5 --params 33.43 1.46 -200 600 0.5 --mm_cond_number 10 --bounds 0.05 50 0.05 50 -50 50 0.05 60 0.05 10 


nano fit_st_11_lat1.sh                  # open a new text editor

'''
#!/bin/bash
#SBATCH --job-name=fit_st_11_ver1        # Job name
#SBATCH --output=/home/jl2815/GEMS/fit_st_11_lat_v1_%j.out            # Standard output file (%j = JobID)
#SBATCH --error=/home/jl2815/GEMS/fit_st_11_lat_v1%j.err              # Standard error file (%j = JobID)
#SBATCH --time=72:00:00                   # Maximum time 
#SBATCH --ntasks=1                        # Number of tasks
#SBATCH --cpus-per-task=40                 # Number of CPU cores per task
#SBATCH --mem=300G                          # Memory per node
#SBATCH --partition=mem               # Partition to submit to

# Load the Anaconda module to use srun 

module purge                                     # unload every other environment to avoid conflict
module use /projects/community/modulefiles                  # without this, I can't load 2024.06-ts840
module load anaconda/2024.06-ts840 

# Initialize Conda
eval "$(conda shell.bash hook)"                  # Initialize Conda for SLURM environment
conda activate gems_tco
# Add the GEMS_TCO package directory to PYTHONPATH
export PYTHONPATH=$PYTHONPATH:/home/jl2815/tco/GEMS_TCO

#
echo "Current date and time: $(date)"
# export OMP_NUM_THREADS=1

# rho 1: 20000 4: 1250 5: 800 6:556 7:409 8:313
# Run the Python script

# This is to study if a fitting process is too smooth that enforcing sigmasq and beta to goes up
echo "lat_idx 5,6,7,8,9 --key 1 --lat_idx 5 --rho 4 --v 0.2 --params 42.8 16.4 10 10 5 --mm_cond_number 10 --bounds 0.05 800 0.05 50 -250 250 0.05 800 0.05 10"
srun python /home/jl2815/tco/exercise/fit_st_bylat_11_16.py.py --key 1 --lat_idx 5 --rho 4 --v 0.2 --params 42.8 16.4 10 10 5 --mm_cond_number 10 --bounds 0.05 800 0.05 50 -250 250 0.05 800 0.05 10 
srun python /home/jl2815/tco/exercise/fit_st_bylat_11_16.py.py --key 1 --lat_idx 6 --rho 4 --v 0.2 --params 42.8 16.4 10 10 5 --mm_cond_number 10 --bounds 0.05 800 0.05 50 -250 250 0.05 800 0.05 10
srun python /home/jl2815/tco/exercise/fit_st_bylat_11_16.py.py --key 1 --lat_idx 7 --rho 4 --v 0.2 --params 42.8 16.4 10 10 5 --mm_cond_number 10 --bounds 0.05 800 0.05 50 -250 250 0.05 800 0.05 10
srun python /home/jl2815/tco/exercise/fit_st_bylat_11_16.py.py --key 1 --lat_idx 8 --rho 4 --v 0.2 --params 42.8 16.4 10 10 5 --mm_cond_number 10 --bounds 0.05 800 0.05 50 -250 250 0.05 800 0.05 10
srun python /home/jl2815/tco/exercise/fit_st_bylat_11_16.py.py --key 1 --lat_idx 9 --rho 4 --v 0.2 --params 42.8 16.4 10 10 5 --mm_cond_number 10 --bounds 0.05 800 0.05 50 -250 250 0.05 800 0.05 10

# Store the job ID in a variable
JOBID=$SLURM_JOBID

# Run sacct to get resource usage details
sacct --units=G --format=MaxRSS,MaxDiskRead,MaxDiskWrite,Elapsed,NodeList -j $JOBID
```

sbatch fit_st_11_lat1.sh 
##################################################################################################
##################################################################################################




testing  

### Update a signle .py file

# 2024-11-14 Update a function to generate coarse set
scp "C:\Users\joonw\anaconda3\envs\jl2815\Lib\site-packages\GEMS_TCO\orbitmap.py" jl2815@amarel.rutgers.edu:/home/jl2815/tco/GEMS_TCO

scp "C:\Users\joonw\anaconda3\envs\jl2815\Lib\site-packages\GEMS_TCO\kernels.py" jl2815@amarel.rutgers.edu:/home/jl2815/tco/GEMS_TCO

scp "C:\Users\joonw\TCO\newpipeline\Exercises\fit_spacematern.py" jl2815@amarel.rutgers.edu:/home/jl2815/tco/exercise

scp "C:\Users\joonw\TCO\newpipeline\Exercises\fit_st_11_16.py" jl2815@amarel.rutgers.edu:/home/jl2815/tco/exercise



nano testing2                 # open a new text editor

'''
#!/bin/bash
#SBATCH --job-name=testing2       # Job name
#SBATCH --output=/home/jl2815/GEMS/testing2_%j.out            # Standard output file (%j = JobID)
#SBATCH --error=/home/jl2815/GEMS/testing2%j.err              # Standard error file (%j = JobID)
#SBATCH --time=72:00:00                   # Maximum time 
#SBATCH --ntasks=1                        # Number of tasks
#SBATCH --cpus-per-task=40                 # Number of CPU cores per task
#SBATCH --mem=300G                          # Memory per node
#SBATCH --partition=mem               # Partition to submit to

# Load the Anaconda module to use srun 

module purge                                     # unload every other environment to avoid conflict
module use /projects/community/modulefiles                  # without this, I can't load 2024.06-ts840
module load anaconda/2024.06-ts840 

# Initialize Conda
eval "$(conda shell.bash hook)"                  # Initialize Conda for SLURM environment
conda activate gems_tco
# Add the GEMS_TCO package directory to PYTHONPATH
export PYTHONPATH=$PYTHONPATH:/home/jl2815/tco/GEMS_TCO

#
echo "Current date and time: $(date)"
# export OMP_NUM_THREADS=1

# rho 1: 20000 4: 1250 5: 800 6:556 7:409 8:313
# Run the Python script

# space matern
echo "/home/jl2815/tco/exercise/fit_spacematern.py --key 1 --lat_idx 5 --rho 4 --params 42.8 16.4 10 10 5 --mm_cond_number 10 --bounds 0.05 800 0.05 50 -250 250 0.05 800 0.05 10 "
srun python /home/jl2815/tco/exercise/fit_spacematern.py --key 1 --lat_idx 5 --rho 4 --params 42.8 16.4 10 10 5 --mm_cond_number 10 --bounds 0.05 800 0.05 50 -250 250 0.05 800 0.05 10 

echo "/home/jl2815/tco/exercise/fit_st_11_16.py --key 1 --rho 4 --v 0.2 --params 42.8 16.4 10 10 5 --mm_cond_number 10 --bounds 0.05 800 0.05 50 -250 250 0.05 800 0.05 10 "
srun python /home/jl2815/tco/exercise/fit_st_11_16.py --key 1 --rho 4 --v 0.2 --params 42.8 16.4 10 10 5 --mm_cond_number 10 --bounds 0.05 800 0.05 50 -250 250 0.05 800 0.05 10 


# Store the job ID in a variable
JOBID=$SLURM_JOBID

# Run sacct to get resource usage details
sacct --units=G --format=MaxRSS,MaxDiskRead,MaxDiskWrite,Elapsed,NodeList -j $JOBID
```

sbatch testing2 


