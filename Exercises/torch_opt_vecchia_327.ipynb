{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "# gems_tco_path = \"/Users/joonwonlee/Documents/GEMS_TCO-1/src\"\n",
    "# sys.path.append(gems_tco_path)\n",
    "\n",
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle \n",
    "\n",
    "import GEMS_TCO\n",
    "from GEMS_TCO import kernels \n",
    "from GEMS_TCO import orderings as _orderings\n",
    "from GEMS_TCO import load_data_local_computer\n",
    "\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import copy                    # clone tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_lon_resolution = [15,15]\n",
    "day = 1\n",
    "mm_cond_number = 20\n",
    "\n",
    "years = ['2024']\n",
    "month_range =[7,8]\n",
    "idx_for_datamap= [ 8*(day-1),8*day]\n",
    "\n",
    "instance = load_data_local_computer()\n",
    "map, ord_mm, nns_map= instance.load_mm20k_data_bymonthyear( lat_lon_resolution= lat_lon_resolution, mm_cond_number=mm_cond_number,years_=years, months_=month_range)\n",
    "analysis_data_map, aggregated_data = instance.load_working_data_byday( map, ord_mm, nns_map, idx_for_datamap=[0,8])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### quick load from amarel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              sigmasq  range_lat  range_lon  advec_lat  advec_lon      beta  \\\n",
      "2024-07-01  24.793444   1.584529   1.718248   0.009089  -0.107299  0.131038   \n",
      "2024-07-02  24.424301   1.997055   1.942683   0.043588  -0.072679  0.137124   \n",
      "2024-07-03  26.009497   1.215236   1.558868   0.023392  -0.150548  0.199850   \n",
      "2024-07-04  24.701347   1.612308   1.822960  -0.164069  -0.237443  0.131595   \n",
      "2024-07-05  22.598671   2.901185   3.722327  -0.011729  -0.152072  0.072866   \n",
      "2024-07-06  25.594908   1.702692   2.255174   0.017462  -0.158125  0.098684   \n",
      "2024-07-07  26.030510   1.261084   2.831952   0.054831  -0.343255  0.103045   \n",
      "2024-07-08  26.043682   0.995279   1.629503  -0.019824  -0.411626  0.164296   \n",
      "2024-07-09  24.052071   1.377774   2.357721   0.021439  -0.220316  0.142847   \n",
      "2024-07-10  25.766109   1.392051   2.358171   0.026684  -0.077366  0.150648   \n",
      "2024-07-11  23.945438   1.490333   2.470762  -0.009915   0.027429  0.137959   \n",
      "2024-07-12  23.036034   2.299998   3.346955  -0.054281   0.114976  0.110155   \n",
      "2024-07-13  22.790960   2.072518   3.616723  -0.130206   0.076944  0.135628   \n",
      "2024-07-14  24.079025   2.077914   2.578654  -0.035028   0.072091  0.144720   \n",
      "2024-07-15  22.556171   3.047949   3.821722  -0.051073   0.067158  0.109084   \n",
      "2024-07-16  23.403471   2.888016   3.056899  -0.004253   0.005845  0.104761   \n",
      "2024-07-17  24.978308   1.371159   2.236580  -0.068871  -0.126589  0.137412   \n",
      "2024-07-18  23.328363   1.295417   3.319158  -0.079007  -0.109866  0.131408   \n",
      "2024-07-19  23.913704   1.824143   2.503119   0.020213   0.016007  0.142548   \n",
      "2024-07-20  23.171667   2.521096   3.594732   0.032805  -0.026624  0.092923   \n",
      "2024-07-21  23.972263   2.328973   3.350626  -0.002169  -0.070489  0.109454   \n",
      "2024-07-22  23.484762   1.773483   3.144358   0.106800  -0.146150  0.170165   \n",
      "2024-07-23  22.399940   2.525347   3.945889  -0.004455   0.073785  0.144858   \n",
      "2024-07-24  22.485428   1.960177   3.856450   0.042581  -0.149502  0.134382   \n",
      "2024-07-25  22.398106   3.968451   3.945307   0.006230  -0.013954  0.047208   \n",
      "2024-07-26  22.393942   2.544035   3.943803  -0.004113   0.031536  0.084661   \n",
      "2024-07-27  22.484076   2.263680   3.848698  -0.026536  -0.070513  0.085162   \n",
      "2024-07-28  22.687857   1.915375   3.615973  -0.024074  -0.078118  0.091293   \n",
      "2024-07-29  22.405510   2.753298   3.919266   0.003522  -0.051619  0.069307   \n",
      "2024-07-30  23.821211   2.505870   3.378460  -0.030410  -0.199047  0.127340   \n",
      "2024-07-31  24.262573   3.082172   2.880464   0.059405  -0.190543  0.197513   \n",
      "\n",
      "              nugget          loss  \n",
      "2024-07-01  2.717239  14068.529297  \n",
      "2024-07-02  1.513148  12357.715820  \n",
      "2024-07-03  2.890678  14948.140625  \n",
      "2024-07-04  3.636499  14786.204102  \n",
      "2024-07-05  2.397249  12096.261719  \n",
      "2024-07-06  3.850205  14690.248047  \n",
      "2024-07-07  4.596346  15342.459961  \n",
      "2024-07-08  2.751402  14857.195312  \n",
      "2024-07-09  1.675457  12666.991211  \n",
      "2024-07-10  3.821218  14987.769531  \n",
      "2024-07-11  2.066264  13000.419922  \n",
      "2024-07-12  1.604898  11485.496094  \n",
      "2024-07-13  1.441895  11315.873047  \n",
      "2024-07-14  2.405799  13138.958984  \n",
      "2024-07-15  1.462631  10808.830078  \n",
      "2024-07-16  2.019670  12012.943359  \n",
      "2024-07-17  3.044259  14286.230469  \n",
      "2024-07-18  2.737964  13417.033203  \n",
      "2024-07-19  2.095682  12876.714844  \n",
      "2024-07-20  2.846266  12944.312500  \n",
      "2024-07-21  2.806951  13142.653320  \n",
      "2024-07-22  2.292179  12951.943359  \n",
      "2024-07-23  1.340997  10006.291016  \n",
      "2024-07-24  1.423066  11153.117188  \n",
      "2024-07-25  1.345503   8595.869141  \n",
      "2024-07-26  1.334278  10097.978516  \n",
      "2024-07-27  1.953647  11613.490234  \n",
      "2024-07-28  2.331802  12408.534180  \n",
      "2024-07-29  3.181403  12968.927734  \n",
      "2024-07-30  2.945880  13282.449219  \n",
      "2024-07-31  5.303008  15539.535156  \n"
     ]
    }
   ],
   "source": [
    "input_path = \"/Users/joonwonlee/Documents/GEMS_TCO-1/Exercises/st_model/estimates\"\n",
    "\n",
    "# input_filename = \"vecc_extra_estimates_50_july24.pkl\"\n",
    "# input_filename = \"vecc_inter_estimates_1250_july24.pkl\"\n",
    "\n",
    "input_filename = \"vecc_inter_estimates_5000_july24.pkl\"\n",
    "# input_filename = \"estimation_200_july24.pkl\"\n",
    "input_filename = \"full_estimation_1250_july24.pkl\"\n",
    "input_filepath = os.path.join(input_path, input_filename)\n",
    "# Load pickle\n",
    "with open(input_filepath, 'rb') as pickle_file:\n",
    "    amarel_map1250= pickle.load(pickle_file)\n",
    "\n",
    "# Assuming df_1250 is your DataFrame\n",
    "df_1250 = pd.DataFrame()\n",
    "for key in amarel_map1250:\n",
    "    tmp = pd.DataFrame(amarel_map1250[key][0].reshape(1, -1), columns=['sigmasq', 'range_lat', 'range_lon', 'advec_lat', 'advec_lon', 'beta', 'nugget'])\n",
    "    tmp['loss'] = amarel_map1250[key][1]\n",
    "    df_1250 = pd.concat((df_1250, tmp), axis=0)\n",
    "\n",
    "# Generate date range\n",
    "date_range = pd.date_range(start='07-01-24', end='07-31-24')\n",
    "\n",
    "# Ensure the number of dates matches the number of rows in df_1250\n",
    "if len(date_range) == len(df_1250):\n",
    "    df_1250.index = date_range\n",
    "else:\n",
    "    print(\"The number of dates does not match the number of rows in the DataFrame.\")\n",
    "\n",
    "print(df_1250)\n",
    "df = df_1250\n",
    "# Save DataFrame to CSV\n",
    "output_filename = 'vecchia_inter_estimates_1250_july24.csv'\n",
    "output_csv_path = os.path.join(input_path, output_filename)\n",
    "df.to_csv(output_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investigate conditioning number\n",
    "\n",
    "10 seems best no more no less"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(tensor(110.0250, dtype=torch.float64), tensor(5.0250, dtype=torch.float64)), (tensor(110.0250, dtype=torch.float64), tensor(9.5250, dtype=torch.float64)), (tensor(114.5250, dtype=torch.float64), tensor(5.0250, dtype=torch.float64)), (tensor(114.5250, dtype=torch.float64), tensor(9.5250, dtype=torch.float64)), (tensor(119.7750, dtype=torch.float64), tensor(5.0250, dtype=torch.float64)), (tensor(119.7750, dtype=torch.float64), tensor(9.5250, dtype=torch.float64))]\n",
      "Indices in Tensor Frame:\n",
      "tensor([ 2,  4, 34, 23, 58,  1])\n"
     ]
    }
   ],
   "source": [
    "sd = analysis_data_map['2024_07_y24m07day01_hm01:00']\n",
    "# Compute the required statistics\n",
    "# Compute the required statistics\n",
    "max_lat = torch.max(sd[:, 0])\n",
    "min_lat = torch.min(sd[:, 0])\n",
    "median_lat = torch.median(sd[:, 0])\n",
    "\n",
    "max_lon = torch.max(sd[:, 1])\n",
    "min_lon = torch.min(sd[:, 1])\n",
    "median_lon = torch.median(sd[:, 1])\n",
    "\n",
    "# Extract the 9 points along with their locations (indices)\n",
    "points = [\n",
    "    (min_lon, min_lat),\n",
    "    #(min_lon, median_lat),\n",
    "    (min_lon, max_lat),\n",
    "    (median_lon, min_lat),\n",
    "    #(median_lon, median_lat),\n",
    "    (median_lon, max_lat),\n",
    "    (max_lon, min_lat),\n",
    "    #(max_lon, median_lat),\n",
    "    (max_lon, max_lat)\n",
    "]\n",
    "print(points)\n",
    "\n",
    "indices = []\n",
    "for lon, lat in points:\n",
    "    condition = (sd[:, 0] == lat) & (sd[:, 1] == lon)\n",
    "    indices.append(torch.where(condition)[0])\n",
    "\n",
    "# Create the indices tensor\n",
    "indices_tensor = torch.cat(indices)\n",
    "\n",
    "print(\"Indices in Tensor Frame:\")\n",
    "print(indices_tensor)\n",
    "\n",
    "base_list = indices_tensor.clone().detach().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimization vecchia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Gradients: [ -1.3326471   8.336545    8.248343    1.1889187 -22.827368  156.88463\n",
      "  -4.3982906]\n",
      " Loss: 1392.2698413676826, Parameters: [ 2.442e+01  1.920e+00  1.920e+00  1.000e-03 -4.500e-02  2.370e-01\n",
      "  3.340e+00]\n",
      "Epoch 101, Gradients: [-1.107125   -0.5147504  -0.47899917  0.07260671  0.08510882  0.7917246\n",
      " -4.671282  ]\n",
      " Loss: 1380.1237077083488, Parameters: [ 2.5032843e+01  1.9060638e+00  1.9065046e+00  3.2319639e-02\n",
      " -4.5225099e-03  1.5137248e-01  3.9493012e+00]\n",
      "Epoch 201, Gradients: [-1.0376558  -0.33904245 -0.31325305  0.00763449  0.02609369  0.5318126\n",
      " -4.314434  ]\n",
      " Loss: 1378.8810748151973, Parameters: [ 2.5243359e+01  1.9969851e+00  1.9936196e+00  3.0165290e-02\n",
      " -8.7977173e-03  1.4283817e-01  4.1580939e+00]\n",
      "Epoch 301, Gradients: [-1.0181451  -0.25514698 -0.23454788  0.00464322  0.01523542  0.32809535\n",
      " -4.204841  ]\n",
      " Loss: 1378.4630975548898, Parameters: [ 2.5318895e+01  2.0331385e+00  2.0284278e+00  2.9587768e-02\n",
      " -1.0144518e-02  1.3979135e-01  4.2329245e+00]\n",
      "Epoch 401, Gradients: [-1.0136549e+00 -2.0831181e-01 -1.9038503e-01  3.1341515e-03\n",
      "  9.1351243e-03  2.1344519e-01 -4.1782804e+00]\n",
      " Loss: 1378.3166111534902, Parameters: [ 2.5345860e+01  2.0478263e+00  2.0426152e+00  2.9372413e-02\n",
      " -1.0611329e-02  1.3865511e-01  4.2597318e+00]\n",
      "Epoch 501, Gradients: [-1.0133171e+00 -1.8276542e-01 -1.6601467e-01  2.1953827e-03\n",
      "  5.6395074e-03  1.4258076e-01 -4.1758776e+00]\n",
      " Loss: 1378.2649614640927, Parameters: [ 2.5355377e+01  2.0538800e+00  2.0484912e+00  2.9286351e-02\n",
      " -1.0775848e-02  1.3822059e-01  4.2692347e+00]\n",
      "Epoch 601, Gradients: [-1.0137413e+00 -1.7011003e-01 -1.5373921e-01  1.5055262e-03\n",
      "  3.7121945e-03  9.6792422e-02 -4.1782074e+00]\n",
      " Loss: 1378.2467503915568, Parameters: [ 2.5358734e+01  2.0563629e+00  2.0509169e+00  2.9251533e-02\n",
      " -1.0835542e-02  1.3805167e-01  4.2725773e+00]\n",
      "Converged at epoch 601\n",
      "Epoch 602, Gradients: [-1.0137455e+00 -1.7002901e-01 -1.5366404e-01  1.5010581e-03\n",
      "  3.7003225e-03  9.6443936e-02 -4.1782308e+00]\n",
      " Loss: 1378.246652550341, vecc Parameters: [ 2.5358768e+01  2.0563920e+00  2.0509453e+00  2.9251132e-02\n",
      " -1.0836218e-02  1.3804974e-01  4.2726135e+00]\n",
      "FINAL STATE: Epoch 602, Gradients: [-1.0137455e+00 -1.7002901e-01 -1.5366404e-01  1.5010581e-03\n",
      "  3.7003225e-03  9.6443936e-02 -4.1782308e+00]\n",
      " Loss: 1378.246652550341, vecc Parameters: [ 2.5358768e+01  2.0563920e+00  2.0509453e+00  2.9251132e-02\n",
      " -1.0836218e-02  1.3804974e-01  4.2726135e+00]\n",
      "Training vecchia likelihood complete.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([ 2.5358768e+01,  2.0563920e+00,  2.0509453e+00,  2.9251132e-02,\n",
       "        -1.0836218e-02,  1.3804974e-01,  4.2726135e+00], dtype=float32),\n",
       " 1378.246652550341]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = [24.42, 1.92, 1.92, 0.001, -0.045, 0.237, 3.34]\n",
    "params = torch.tensor(params, requires_grad=True)\n",
    "\n",
    "instance = kernels.model_fitting(\n",
    "    smooth=0.5,\n",
    "    input_map=analysis_data_map,\n",
    "    aggregated_data=aggregated_data,\n",
    "    nns_map=nns_map,\n",
    "    mm_cond_number=mm_cond_number\n",
    ")\n",
    "\n",
    "# optimizer = optim.Adam([params], lr=0.01)  # For Adam\n",
    "optimizer, scheduler = instance.optimizer_fun( params, lr=0.01, betas=(0.9, 0.99), eps=1e-8, step_size=10, gamma=0.9)  \n",
    "instance.run_vecc_interpolate(params, optimizer, scheduler,epochs=3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vecchia experiments here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_for_datamap = [0,8]\n",
    "\n",
    "class matern_advec_beta_torch_vecchia:\n",
    "    def __init__(self, analaysis_data_map: torch.Tensor, params: torch.Tensor, nns_map=nns_map, mm_cond_number=mm_cond_number):\n",
    "        \n",
    "        self.key_list = sorted(analysis_data_map)\n",
    "        self.input_map = analysis_data_map\n",
    "\n",
    "        self.mm_cond_number = mm_cond_number\n",
    "        self.nns_map = nns_map \n",
    "        self.input_map = analaysis_data_map\n",
    "        self.smooth = 0.5  \n",
    "        sample_df = analaysis_data_map[self.key_list[0]]\n",
    "\n",
    "        self.size_per_hour = len(sample_df)\n",
    "\n",
    "    def custom_distance_matrix(self, U, V):\n",
    "        # Efficient distance computation with broadcasting\n",
    "        spatial_diff = torch.norm(U[:, :2].unsqueeze(1) - V[:, :2].unsqueeze(0), dim=2)\n",
    "\n",
    "        temporal_diff = torch.abs(U[:, 2].unsqueeze(1) - V[:, 2].unsqueeze(0))\n",
    "        distance = (spatial_diff**2 + temporal_diff**2)  # move torch.sqrt to covariance function to track gradients of beta and avec\n",
    "        return distance\n",
    "    \n",
    "    def precompute_coords_ani(self, params, y: torch.Tensor, x: torch.Tensor)-> torch.Tensor:\n",
    "        sigmasq, range_lat, range_lon, advec_lat, advec_lon, beta, nugget = params\n",
    "\n",
    "        if y is None or x is None:\n",
    "            raise ValueError(\"Both y and x_df must be provided.\")\n",
    "\n",
    "        x1 = x[:, 0]\n",
    "        y1 = x[:, 1]\n",
    "        t1 = x[:, 3]\n",
    "\n",
    "        x2 = y[:, 0]\n",
    "        y2 = y[:, 1]\n",
    "        t2 = y[:, 3]\n",
    "\n",
    "        # spat_coord1 = torch.stack((self.x1 , self.y1 - advec * self.t1), dim=-1)\n",
    "        spat_coord1 = torch.stack(( (x1 - advec_lat * t1)/range_lat, (y1 - advec_lon * t1)/range_lon ), dim=-1)\n",
    "        spat_coord2 = torch.stack(( (x2 - advec_lat * t2)/range_lat, (y2 - advec_lon * t2)/range_lon ), dim=-1)\n",
    "\n",
    "        U = torch.cat((spat_coord1, (beta * t1).reshape(-1, 1)), dim=1)\n",
    "        V = torch.cat((spat_coord2, (beta * t2).reshape(-1, 1)), dim=1)\n",
    "\n",
    "        distance = self.custom_distance_matrix(U,V)\n",
    "        non_zero_indices = distance != 0\n",
    "        return distance, non_zero_indices\n",
    "    \n",
    "    # anisotropic in three \n",
    "    def matern_cov_ani(self,params: torch.Tensor, x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "        sigmasq, range_lat, range_lon, advec_lat, advec_lon, beta, nugget = params\n",
    "        \n",
    "\n",
    "        distance, non_zero_indices = self.precompute_coords_ani(params, x,y)\n",
    "        out = torch.zeros_like(distance)\n",
    "\n",
    "        non_zero_indices = distance != 0\n",
    "        if torch.any(non_zero_indices):\n",
    "            out[non_zero_indices] = sigmasq * torch.exp(- torch.sqrt(distance[non_zero_indices]))\n",
    "        out[~non_zero_indices] = sigmasq\n",
    "\n",
    "        # Add a small jitter term to the diagonal for numerical stability\n",
    "        out += torch.eye(out.shape[0], dtype=torch.float64) * nugget \n",
    "\n",
    "        return out\n",
    "    \n",
    "    def full_likelihood(self,params: torch.Tensor, input_np: torch.Tensor, y: torch.Tensor, covariance_function) -> torch.Tensor:\n",
    "        input_arr = input_np[:, :4]\n",
    "        y_arr = y\n",
    "\n",
    "        # Compute the covariance matrix\n",
    "        cov_matrix = covariance_function(params=params, y=input_arr, x=input_arr)\n",
    "        \n",
    "        # Compute the log determinant of the covariance matrix\n",
    "        sign, log_det = torch.slogdet(cov_matrix)\n",
    "        #log_det = torch.log(torch.linalg.det(cov_matrix))\n",
    "        #if sign <= 0:\n",
    "        #    raise ValueError(\"Covariance matrix is not positive definite\")\n",
    "        \n",
    "        # Extract locations\n",
    "        locs = input_arr[:, :2]\n",
    "\n",
    "        # Compute beta\n",
    "        tmp1 = torch.matmul(locs.T, torch.linalg.solve(cov_matrix, locs))\n",
    "        tmp2 = torch.matmul(locs.T, torch.linalg.solve(cov_matrix, y_arr))\n",
    "        beta = torch.linalg.solve(tmp1, tmp2)\n",
    "\n",
    "        # Compute the mean\n",
    "        mu = torch.matmul(locs, beta)\n",
    "        y_mu = y_arr - mu\n",
    "\n",
    "        # Compute the quadratic form\n",
    "        quad_form = torch.matmul(y_mu, torch.linalg.solve(cov_matrix, y_mu))\n",
    "\n",
    "        # Compute the negative log likelihood\n",
    "        neg_log_lik = 0.5 * (log_det + quad_form)\n",
    "        # neg_log_lik = 0.5 * ( log_det )\n",
    "        return  neg_log_lik \n",
    "\n",
    "\n",
    "    def vecchia_local_full_cond(self, params: torch.Tensor, covariance_function) -> torch.Tensor:\n",
    "        neg_log_lik = 0.0\n",
    "\n",
    "                # Use below when working on local computer to avoid singular matrix\n",
    "        cur_heads = aggregated_data[:20, :]\n",
    "        neg_log_lik += self.full_likelihood(params, cur_heads, cur_heads[:, 2], covariance_function)\n",
    "\n",
    "        for idx in range(20,len(aggregated_data)):\n",
    "            current_row = aggregated_data[idx,:4]\n",
    "            current_y = aggregated_data[idx,2]\n",
    "            conditioning_data = aggregated_data[:idx,:4]\n",
    "\n",
    "            torch_arr = torch.vstack((current_row, conditioning_data))\n",
    "            y_and_neighbors = torch_arr[:, 2]\n",
    "            locs = torch_arr[:, :2]\n",
    "\n",
    "            cov_matrix = covariance_function(params=params, y= torch_arr, x= torch_arr)\n",
    "            # print(f'Condition number: {torch.linalg.cond(cov_matrix)}')\n",
    "            cov_xx = cov_matrix[1:, 1:]\n",
    "            # cov_xx_inv = torch.linalg.inv(cov_xx)\n",
    "\n",
    "            cov_yx = cov_matrix[0, 1:]\n",
    "\n",
    "                    # Compute the log determinant of the covariance matrix\n",
    "            # sign, log_det = torch.slogdet(cov_matrix)\n",
    "            # if sign <= 0:\n",
    "            #     raise ValueError(\"Covariance matrix is not positive definite\")\n",
    "        \n",
    "            # Compute beta\n",
    "\n",
    "\n",
    "            tmp1 = torch.matmul(locs.T, torch.linalg.solve(cov_matrix, locs))\n",
    "            tmp2 = torch.matmul(locs.T, torch.linalg.solve(cov_matrix, y_and_neighbors))\n",
    "            \n",
    "\n",
    "            beta = torch.linalg.solve(tmp1, tmp2)\n",
    "\n",
    "            mu = torch.matmul(locs, beta)\n",
    "            mu_current = mu[0]\n",
    "            mu_neighbors = mu[1:]\n",
    "\n",
    "            # Mean and variance of y|x\n",
    "            sigma = cov_matrix[0, 0]\n",
    "            \n",
    "            # cov_ygivenx = sigma - torch.matmul(cov_yx, torch.matmul(cov_xx_inv, cov_yx))\n",
    "            cov_ygivenx = sigma - torch.matmul(cov_yx, torch.linalg.solve(cov_xx, cov_yx))\n",
    "            # cond_mean_tmp = torch.matmul(cov_yx, cov_xx_inv)\n",
    "            cond_mean = mu_current + torch.matmul(cov_yx, torch.linalg.solve( cov_xx,(y_and_neighbors[1:] - mu_neighbors) ) )\n",
    "            \n",
    "            alpha = current_y - cond_mean\n",
    "            quad_form = alpha**2 * (1 / cov_ygivenx)\n",
    "            log_det = torch.log(cov_ygivenx)\n",
    "     \n",
    "            neg_log_lik += 0.5 * (log_det + quad_form) \n",
    "        return neg_log_lik\n",
    "\n",
    "\n",
    "    def vecchia_like_local_computer(self, params: torch.Tensor, covariance_function) -> torch.Tensor:\n",
    "        self.cov_map = defaultdict(list)\n",
    "        neg_log_lik = 0.0\n",
    "        \n",
    "        for time_idx in range(len(self.input_map)):\n",
    "            current_np = self.input_map[self.key_list[time_idx]]\n",
    "\n",
    "            # Use below when working on local computer to avoid singular matrix\n",
    "            #cur_heads = current_np[:21, :]\n",
    "            #neg_log_lik += self.full_likelihood(params, cur_heads, cur_heads[:, 2], covariance_function)\n",
    "\n",
    "            for index in range(0, self.size_per_hour):\n",
    "                current_row = current_np[index].reshape(1, -1)\n",
    "                current_y = current_row[0, 2]\n",
    "\n",
    "                # Construct conditioning set\n",
    "                mm_neighbors = self.nns_map[index]\n",
    "                past = list(mm_neighbors)\n",
    "                data_list = []\n",
    "\n",
    "                if past:\n",
    "                    data_list.append(current_np[past])\n",
    "\n",
    "                if time_idx > 1:\n",
    "                    cov_matrix = self.cov_map[index]['cov_matrix']\n",
    "                    tmp_for_beta = self.cov_map[index]['tmp_for_beta']\n",
    "                    cov_xx_inv = self.cov_map[index]['cov_xx_inv']\n",
    "                    L_inv = self.cov_map[index]['L_inv']\n",
    "                    cov_ygivenx = self.cov_map[index]['cov_ygivenx']\n",
    "                    cond_mean_tmp = self.cov_map[index]['cond_mean_tmp']\n",
    "                    log_det = self.cov_map[index]['log_det']\n",
    "                    locs = self.cov_map[index]['locs']\n",
    "                    \n",
    "                    last_hour_np = self.input_map[self.key_list[time_idx - 1]]\n",
    "                    past_conditioning_data = last_hour_np[past + [index], :]\n",
    "                    data_list.append(past_conditioning_data)\n",
    "\n",
    "                    if data_list:\n",
    "                        conditioning_data = torch.vstack(data_list)\n",
    "                    else:\n",
    "                        conditioning_data = torch.empty((0, current_row.shape[1]), dtype=torch.float32)\n",
    "\n",
    "                    np_arr = torch.vstack((current_row, conditioning_data))\n",
    "                    y_and_neighbors = np_arr[:, 2]\n",
    "\n",
    "                    cov_yx = cov_matrix[0, 1:]\n",
    "\n",
    "                    tmp2 = torch.matmul(torch.matmul(L_inv, locs).T, torch.matmul(L_inv, y_and_neighbors))\n",
    "                    beta = torch.linalg.solve(tmp_for_beta, tmp2)\n",
    "\n",
    "                    mu = torch.matmul(locs, beta)\n",
    "                    mu_current = mu[0]\n",
    "                    mu_neighbors = mu[1:]\n",
    "                    \n",
    "                    # Mean and variance of y|x\n",
    "                    cond_mean = mu_current + torch.matmul(cond_mean_tmp, (y_and_neighbors[1:] - mu_neighbors))\n",
    "                    alpha = current_y - cond_mean\n",
    "                    quad_form = alpha**2 * (1 / cov_ygivenx)\n",
    "                    neg_log_lik += 0.5 * (log_det + quad_form)\n",
    "\n",
    "                    continue\n",
    "\n",
    "                if time_idx > 0:\n",
    "                    last_hour_np = self.input_map[self.key_list[time_idx - 1]]\n",
    "                    past_conditioning_data = last_hour_np[past + [index], :]\n",
    "                    data_list.append(past_conditioning_data)\n",
    "\n",
    "                if data_list:\n",
    "                    conditioning_data = torch.vstack(data_list)\n",
    "                else:\n",
    "                    conditioning_data = torch.empty((0, current_row.shape[1]), dtype=torch.float32)\n",
    "\n",
    "                np_arr = torch.vstack((current_row, conditioning_data))\n",
    "                y_and_neighbors = np_arr[:, 2]\n",
    "                locs = np_arr[:, :2]\n",
    "\n",
    "                cov_matrix = covariance_function(params=params, y= np_arr, x= np_arr)\n",
    "                # print(f'Condition number: {torch.linalg.cond(cov_matrix)}')\n",
    "                L = torch.linalg.cholesky(cov_matrix)\n",
    "                L11 = L[:1, :1]\n",
    "                L12 = torch.zeros(L[:1, 1:].shape)\n",
    "                L21 = L[1:, :1]\n",
    "                L22 = L[1:, 1:]\n",
    "                L11_inv = torch.linalg.inv(L11)\n",
    "                L22_inv = torch.linalg.inv(L22)\n",
    "\n",
    "                # First block: [L11_inv, L12]\n",
    "                upper_block = torch.cat((L11_inv, L12), dim=1)  # Concatenate along columns (dim=1)\n",
    "\n",
    "                # Second block: [-torch.matmul(torch.matmul(L22_inv, L21), L11_inv), L22_inv]\n",
    "                lower_left = -torch.matmul(torch.matmul(L22_inv, L21), L11_inv)\n",
    "                lower_block = torch.cat((lower_left, L22_inv), dim=1)  # Concatenate along columns (dim=1)\n",
    "\n",
    "                # Combine the upper and lower blocks\n",
    "                L_inv = torch.cat((upper_block, lower_block), dim=0)  # Concatenate along rows (dim=0)\n",
    "\n",
    "                cov_yx = cov_matrix[0, 1:]\n",
    "\n",
    "                tmp1 = torch.matmul(L_inv, locs)\n",
    "                tmp2 = torch.matmul(torch.matmul(L_inv, locs).T, torch.matmul(L_inv, y_and_neighbors))\n",
    "                tmp_for_beta = torch.matmul(tmp1.T, tmp1)\n",
    "                beta = torch.linalg.solve(tmp_for_beta, tmp2)\n",
    "\n",
    "                mu = torch.matmul(locs, beta)\n",
    "                mu_current = mu[0]\n",
    "                mu_neighbors = mu[1:]\n",
    "\n",
    "                # Mean and variance of y|x\n",
    "                sigma = cov_matrix[0, 0]\n",
    "                cov_xx = cov_matrix[1:, 1:]\n",
    "                cov_xx_inv = torch.linalg.inv(cov_xx)\n",
    "\n",
    "                cov_ygivenx = sigma - torch.matmul(cov_yx, torch.matmul(cov_xx_inv, cov_yx))\n",
    "                cond_mean_tmp = torch.matmul(cov_yx, cov_xx_inv)\n",
    "                cond_mean = mu_current + torch.matmul(cond_mean_tmp, (y_and_neighbors[1:] - mu_neighbors))\n",
    "                \n",
    "                alpha = current_y - cond_mean\n",
    "                quad_form = alpha**2 * (1 / cov_ygivenx)\n",
    "                log_det = torch.log(cov_ygivenx)\n",
    "                neg_log_lik += 0.5 * (log_det + quad_form)\n",
    "\n",
    "             \n",
    "                if time_idx == 1:\n",
    "                    self.cov_map[index] = {\n",
    "                        'tmp_for_beta': tmp_for_beta,\n",
    "                        'cov_xx_inv': cov_xx_inv,\n",
    "                        'cov_matrix': cov_matrix,\n",
    "                        'L_inv': L_inv,\n",
    "                        'cov_ygivenx': cov_ygivenx,\n",
    "                        'cond_mean_tmp': cond_mean_tmp,\n",
    "                        'log_det': log_det,\n",
    "                        'locs': locs\n",
    "                    }\n",
    "\n",
    "        return neg_log_lik  \n",
    "\n",
    "## add base_list three times  when time_idx =0 1 >0\n",
    "\n",
    "    def vecchia_extrapolate(self, params: torch.Tensor, covariance_function, cut_line=200) -> torch.Tensor:\n",
    "        self.cov_map = defaultdict(list)\n",
    "        neg_log_lik = 0.0\n",
    "\n",
    "        key_list = sorted(analysis_data_map)\n",
    "        cut_line = cut_line\n",
    "        heads = analysis_data_map[key_list[0]][:cut_line,:]\n",
    "        for time_idx in range(1, len(analysis_data_map)):\n",
    "            tmp = analysis_data_map[key_list[time_idx]][:cut_line,:]\n",
    "            heads = torch.cat( (heads,tmp), dim=0)\n",
    "\n",
    "        neg_log_lik += self.full_likelihood(params, heads, heads[:, 2], covariance_function)          \n",
    "        \n",
    "        for time_idx in range(len(self.input_map)):\n",
    "            current_np = self.input_map[self.key_list[time_idx]]\n",
    "\n",
    "            # Use below when working on local computer to avoid singular matrix\n",
    "            # cur_heads = current_np[:5, :]\n",
    "            # neg_log_lik += self.full_likelihood(params, cur_heads, cur_heads[:, 2], covariance_function)\n",
    "\n",
    "            for index in range(cut_line, self.size_per_hour):\n",
    "                current_row = current_np[index].reshape(1, -1)\n",
    "                current_y = current_row[0, 2]\n",
    "\n",
    "                # Construct conditioning set\n",
    "                mm_neighbors = self.nns_map[index]\n",
    "                past = list(mm_neighbors) \n",
    "                data_list = []\n",
    "\n",
    "                if past:\n",
    "                    data_list.append(current_np[past])\n",
    "\n",
    "                if time_idx > 1:\n",
    "                    cov_matrix = self.cov_map[index]['cov_matrix']\n",
    "                    tmp_for_beta = self.cov_map[index]['tmp_for_beta']\n",
    "                    cov_xx_inv = self.cov_map[index]['cov_xx_inv']\n",
    "            \n",
    "                    cov_ygivenx = self.cov_map[index]['cov_ygivenx']\n",
    "                    cond_mean_tmp = self.cov_map[index]['cond_mean_tmp']\n",
    "                    log_det = self.cov_map[index]['log_det']\n",
    "                    locs = self.cov_map[index]['locs']\n",
    "                    \n",
    "                    last_hour_np = self.input_map[self.key_list[time_idx - 1]]\n",
    "                    past_conditioning_data = last_hour_np[past + [index] , :]\n",
    "                    data_list.append(past_conditioning_data)\n",
    "\n",
    "                    if data_list:\n",
    "                        conditioning_data = torch.vstack(data_list)\n",
    "                    else:\n",
    "                        conditioning_data = torch.empty((0, current_row.shape[1]), dtype=torch.float32)\n",
    "\n",
    "                    np_arr = torch.vstack((current_row, conditioning_data))\n",
    "                    y_and_neighbors = np_arr[:, 2]\n",
    "\n",
    "                    cov_yx = cov_matrix[0, 1:]\n",
    "\n",
    "                    y_arr = y_and_neighbors\n",
    "                    tmp1 = tmp_for_beta\n",
    "                    tmp2 = torch.matmul(locs.T, torch.linalg.solve(cov_matrix, y_arr))\n",
    "                    beta = torch.linalg.solve(tmp1, tmp2)\n",
    "\n",
    "                    mu = torch.matmul(locs, beta)\n",
    "                    mu_current = mu[0]\n",
    "                    mu_neighbors = mu[1:]\n",
    "                    \n",
    "                    # Mean and variance of y|x\n",
    "                    cond_mean = mu_current + torch.matmul(cond_mean_tmp, (y_and_neighbors[1:] - mu_neighbors))\n",
    "                    alpha = current_y - cond_mean\n",
    "                    quad_form = alpha**2 * (1 / cov_ygivenx)\n",
    "                    neg_log_lik += 0.5 * (log_det + quad_form)\n",
    "\n",
    "                    continue\n",
    "\n",
    "                if time_idx > 0:\n",
    "                    last_hour_np = self.input_map[self.key_list[time_idx - 1]]\n",
    "                    past_conditioning_data = last_hour_np[past + [index], :]\n",
    "                    data_list.append(past_conditioning_data)\n",
    "\n",
    "                if data_list:\n",
    "                    conditioning_data = torch.vstack(data_list)\n",
    "                else:\n",
    "                    conditioning_data = torch.empty((0, current_row.shape[1]), dtype=torch.float32)\n",
    "\n",
    "                np_arr = torch.vstack((current_row, conditioning_data))\n",
    "                y_and_neighbors = np_arr[:, 2]\n",
    "                locs = np_arr[:, :2]\n",
    "\n",
    "                cov_matrix = covariance_function(params=params, y= np_arr, x= np_arr)\n",
    "                # print(f'Condition number: {torch.linalg.cond(cov_matrix)}')\n",
    "                cov_yx = cov_matrix[0, 1:]\n",
    "                        # Compute the log determinant of the covariance matrix\n",
    "                sign, log_det = torch.slogdet(cov_matrix)\n",
    "                # if sign <= 0:\n",
    "                #     raise ValueError(\"Covariance matrix is not positive definite\")\n",
    "            \n",
    "                y_arr = y_and_neighbors\n",
    "                # Compute beta\n",
    "                tmp1 = torch.matmul(locs.T, torch.linalg.solve(cov_matrix, locs))\n",
    "                tmp2 = torch.matmul(locs.T, torch.linalg.solve(cov_matrix, y_arr))\n",
    "                beta = torch.linalg.solve(tmp1, tmp2)\n",
    "\n",
    "                mu = torch.matmul(locs, beta)\n",
    "                mu_current = mu[0]\n",
    "                mu_neighbors = mu[1:]\n",
    "\n",
    "                # Mean and variance of y|x\n",
    "                sigma = cov_matrix[0, 0]\n",
    "                cov_xx = cov_matrix[1:, 1:]\n",
    "                cov_xx_inv = torch.linalg.inv(cov_xx)\n",
    "\n",
    "                cov_ygivenx = sigma - torch.matmul(cov_yx, torch.matmul(cov_xx_inv, cov_yx))\n",
    "                cond_mean_tmp = torch.matmul(cov_yx, cov_xx_inv)\n",
    "                cond_mean = mu_current + torch.matmul(cond_mean_tmp, (y_and_neighbors[1:] - mu_neighbors))\n",
    "                \n",
    "                alpha = current_y - cond_mean\n",
    "                quad_form = alpha**2 * (1 / cov_ygivenx)\n",
    "                log_det = torch.log(cov_ygivenx)\n",
    "                neg_log_lik += 0.5 * (log_det + quad_form)\n",
    " \n",
    "                if time_idx == 1:\n",
    "                    self.cov_map[index] = {\n",
    "                        'tmp_for_beta': tmp1,\n",
    "                        'cov_xx_inv': cov_xx_inv,\n",
    "                        'cov_matrix': cov_matrix,\n",
    "               \n",
    "                        'cov_ygivenx': cov_ygivenx,\n",
    "                        'cond_mean_tmp': cond_mean_tmp,\n",
    "                        'log_det': log_det,\n",
    "                        'locs': locs\n",
    "                    }\n",
    "        return neg_log_lik\n",
    "\n",
    "\n",
    "    def vecchia_local_extra_base(self, params: torch.Tensor, covariance_function) -> torch.Tensor:\n",
    "        self.cov_map = defaultdict(list)\n",
    "        neg_log_lik = 0.0\n",
    "        \n",
    "        for time_idx in range(len(self.input_map)):\n",
    "            current_np = self.input_map[self.key_list[time_idx]]\n",
    "\n",
    "            # Use below when working on local computer to avoid singular matrix\n",
    "            # cur_heads = current_np[:21, :]\n",
    "            # neg_log_lik += self.full_likelihood(params, cur_heads, cur_heads[:, 2], covariance_function)\n",
    "\n",
    "            for index in range(0, self.size_per_hour):\n",
    "                current_row = current_np[index].reshape(1, -1)\n",
    "                current_y = current_row[0, 2]\n",
    "\n",
    "                # Construct conditioning set\n",
    "                mm_neighbors = self.nns_map[index]\n",
    "                past = list(mm_neighbors) + base_list\n",
    "                data_list = []\n",
    "\n",
    "                if past:\n",
    "                    data_list.append(current_np[past])\n",
    "\n",
    "                if time_idx > 1:\n",
    "                    cov_matrix = self.cov_map[index]['cov_matrix']\n",
    "                    tmp_for_beta = self.cov_map[index]['tmp_for_beta']\n",
    "                    cov_xx_inv = self.cov_map[index]['cov_xx_inv']\n",
    "            \n",
    "                    cov_ygivenx = self.cov_map[index]['cov_ygivenx']\n",
    "                    cond_mean_tmp = self.cov_map[index]['cond_mean_tmp']\n",
    "                    log_det = self.cov_map[index]['log_det']\n",
    "                    locs = self.cov_map[index]['locs']\n",
    "                    \n",
    "                    last_hour_np = self.input_map[self.key_list[time_idx - 1]]\n",
    "                    past_conditioning_data = last_hour_np[past + [index] + base_list, :]\n",
    "                    data_list.append(past_conditioning_data)\n",
    "\n",
    "                    if data_list:\n",
    "                        conditioning_data = torch.vstack(data_list)\n",
    "                    else:\n",
    "                        conditioning_data = torch.empty((0, current_row.shape[1]), dtype=torch.float32)\n",
    "\n",
    "                    np_arr = torch.vstack((current_row, conditioning_data))\n",
    "                    y_and_neighbors = np_arr[:, 2]\n",
    "\n",
    "                    cov_yx = cov_matrix[0, 1:]\n",
    "\n",
    "                    y_arr = y_and_neighbors\n",
    "                    tmp1 = tmp_for_beta\n",
    "                    tmp2 = torch.matmul(locs.T, torch.linalg.solve(cov_matrix, y_arr))\n",
    "                    beta = torch.linalg.solve(tmp1, tmp2)\n",
    "\n",
    "                    mu = torch.matmul(locs, beta)\n",
    "                    mu_current = mu[0]\n",
    "                    mu_neighbors = mu[1:]\n",
    "                    \n",
    "                    # Mean and variance of y|x\n",
    "                    cond_mean = mu_current + torch.matmul(cond_mean_tmp, (y_and_neighbors[1:] - mu_neighbors))\n",
    "                    alpha = current_y - cond_mean\n",
    "                    quad_form = alpha**2 * (1 / cov_ygivenx)\n",
    "                    neg_log_lik += 0.5 * (log_det + quad_form)\n",
    "\n",
    "                    continue\n",
    "\n",
    "                if time_idx > 0:\n",
    "                    last_hour_np = self.input_map[self.key_list[time_idx - 1]]\n",
    "                    past_conditioning_data = last_hour_np[past + [index]+ base_list, :]\n",
    "                    data_list.append(past_conditioning_data)\n",
    "\n",
    "                if data_list:\n",
    "                    conditioning_data = torch.vstack(data_list)\n",
    "                else:\n",
    "                    conditioning_data = torch.empty((0, current_row.shape[1]), dtype=torch.float32)\n",
    "\n",
    "                np_arr = torch.vstack((current_row, conditioning_data))\n",
    "                y_and_neighbors = np_arr[:, 2]\n",
    "                locs = np_arr[:, :2]\n",
    "\n",
    "                cov_matrix = covariance_function(params=params, y= np_arr, x= np_arr)\n",
    "                # print(f'Condition number: {torch.linalg.cond(cov_matrix)}')\n",
    "                cov_yx = cov_matrix[0, 1:]\n",
    "                        # Compute the log determinant of the covariance matrix\n",
    "                sign, log_det = torch.slogdet(cov_matrix)\n",
    "                # if sign <= 0:\n",
    "                #     raise ValueError(\"Covariance matrix is not positive definite\")\n",
    "            \n",
    "                y_arr = y_and_neighbors\n",
    "                # Compute beta\n",
    "                tmp1 = torch.matmul(locs.T, torch.linalg.solve(cov_matrix, locs))\n",
    "                tmp2 = torch.matmul(locs.T, torch.linalg.solve(cov_matrix, y_arr))\n",
    "                beta = torch.linalg.solve(tmp1, tmp2)\n",
    "\n",
    "                mu = torch.matmul(locs, beta)\n",
    "                mu_current = mu[0]\n",
    "                mu_neighbors = mu[1:]\n",
    "\n",
    "                # Mean and variance of y|x\n",
    "                sigma = cov_matrix[0, 0]\n",
    "                cov_xx = cov_matrix[1:, 1:]\n",
    "                cov_xx_inv = torch.linalg.inv(cov_xx)\n",
    "\n",
    "                cov_ygivenx = sigma - torch.matmul(cov_yx, torch.matmul(cov_xx_inv, cov_yx))\n",
    "                cond_mean_tmp = torch.matmul(cov_yx, cov_xx_inv)\n",
    "                cond_mean = mu_current + torch.matmul(cond_mean_tmp, (y_and_neighbors[1:] - mu_neighbors))\n",
    "                \n",
    "                alpha = current_y - cond_mean\n",
    "                quad_form = alpha**2 * (1 / cov_ygivenx)\n",
    "                log_det = torch.log(cov_ygivenx)\n",
    "                neg_log_lik += 0.5 * (log_det + quad_form)\n",
    " \n",
    "                if time_idx == 1:\n",
    "                    self.cov_map[index] = {\n",
    "                        'tmp_for_beta': tmp1,\n",
    "                        'cov_xx_inv': cov_xx_inv,\n",
    "                        'cov_matrix': cov_matrix,\n",
    "               \n",
    "                        'cov_ygivenx': cov_ygivenx,\n",
    "                        'cond_mean_tmp': cond_mean_tmp,\n",
    "                        'log_det': log_det,\n",
    "                        'locs': locs\n",
    "                    }\n",
    "        return neg_log_lik\n",
    "    \n",
    "\n",
    "    def vecchia_interpolation_1to6(self, params: torch.Tensor, covariance_function, cut_line=200) -> torch.Tensor:\n",
    "        self.cov_map = defaultdict(list)\n",
    "        neg_log_lik = 0.0\n",
    "        key_list = sorted(analysis_data_map)\n",
    "        cut_line = cut_line\n",
    "        heads = analysis_data_map[key_list[0]][:cut_line,:]\n",
    "        for time_idx in range(1, len(analysis_data_map)):\n",
    "            tmp = analysis_data_map[key_list[time_idx]][:cut_line,:]\n",
    "            heads = torch.cat( (heads,tmp), dim=0)\n",
    "\n",
    "        neg_log_lik += self.full_likelihood(params, heads, heads[:, 2], covariance_function)          \n",
    "        \n",
    "        for time_idx in range(0,len(self.input_map)):\n",
    "            current_np = self.input_map[self.key_list[time_idx]]\n",
    "\n",
    "            # Use below when working on local computer to avoid singular matrix\n",
    "            for index in range(cut_line, self.size_per_hour):\n",
    "                current_row = current_np[index].reshape(1, -1)\n",
    "                current_y = current_row[0, 2]\n",
    "\n",
    "                # Construct conditioning set\n",
    "                mm_neighbors = self.nns_map[index]\n",
    "                past = list(mm_neighbors) \n",
    "                data_list = []\n",
    "\n",
    "                if past:\n",
    "                    data_list.append(current_np[past])\n",
    "\n",
    "                if time_idx > 0 and time_idx<7:\n",
    "                    last_hour_np = self.input_map[self.key_list[time_idx - 1]]\n",
    "                    past_conditioning_data = last_hour_np[past + [index], :]\n",
    "                    data_list.append(past_conditioning_data)\n",
    "\n",
    "                    last_hour_np = self.input_map[self.key_list[time_idx +1]]\n",
    "                    # if index==200:\n",
    "                    #     print(self.input_map[self.key_list[time_idx-6]])\n",
    "                    past_conditioning_data = last_hour_np[past + [index], :]\n",
    "                    data_list.append(past_conditioning_data)\n",
    "                \n",
    "                if data_list:\n",
    "                    conditioning_data = torch.vstack(data_list)\n",
    "                else:\n",
    "                    conditioning_data = torch.empty((0, current_row.shape[1]), dtype=torch.float32)\n",
    "\n",
    "                np_arr = torch.vstack((current_row, conditioning_data))\n",
    "                y_and_neighbors = np_arr[:, 2]\n",
    "                locs = np_arr[:, :2]\n",
    "\n",
    "                cov_matrix = covariance_function(params=params, y= np_arr, x= np_arr)\n",
    "                # print(f'Condition number: {torch.linalg.cond(cov_matrix)}')\n",
    "                cov_yx = cov_matrix[0, 1:]\n",
    "                        # Compute the log determinant of the covariance matrix\n",
    "                sign, log_det = torch.slogdet(cov_matrix)\n",
    "                # if sign <= 0:\n",
    "                #     raise ValueError(\"Covariance matrix is not positive definite\")\n",
    "            \n",
    "                y_arr = y_and_neighbors\n",
    "                # Compute beta\n",
    "                tmp1 = torch.matmul(locs.T, torch.linalg.solve(cov_matrix, locs))\n",
    "                tmp2 = torch.matmul(locs.T, torch.linalg.solve(cov_matrix, y_arr))\n",
    "                beta = torch.linalg.solve(tmp1, tmp2)\n",
    "\n",
    "                mu = torch.matmul(locs, beta)\n",
    "                mu_current = mu[0]\n",
    "                mu_neighbors = mu[1:]\n",
    "\n",
    "                # Mean and variance of y|x\n",
    "                sigma = cov_matrix[0, 0]\n",
    "                cov_xx = cov_matrix[1:, 1:]\n",
    "                cov_xx_inv = torch.linalg.inv(cov_xx)\n",
    "\n",
    "                cov_ygivenx = sigma - torch.matmul(cov_yx, torch.matmul(cov_xx_inv, cov_yx))\n",
    "                cond_mean_tmp = torch.matmul(cov_yx, cov_xx_inv)\n",
    "                cond_mean = mu_current + torch.matmul(cond_mean_tmp, (y_and_neighbors[1:] - mu_neighbors))\n",
    "                \n",
    "                alpha = current_y - cond_mean\n",
    "                quad_form = alpha**2 * (1 / cov_ygivenx)\n",
    "                log_det = torch.log(cov_ygivenx)\n",
    "                neg_log_lik += 0.5 * (log_det + quad_form)\n",
    " \n",
    "        return neg_log_lik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class torch_vecchia_exp(matern_advec_beta_torch_vecchia):\n",
    "    def __init__(self, analaysis_data_map: torch.Tensor, params: torch.Tensor, nns_map=nns_map, mm_cond_number=mm_cond_number):\n",
    "        super().__init__(analaysis_data_map, params, nns_map, mm_cond_number)\n",
    "        # Any additional initialization for dignosis class can go here\n",
    "\n",
    "\n",
    "    def vecchia_interpolation_1to6(self, params: torch.Tensor, covariance_function, cut_line) -> torch.Tensor:\n",
    "        self.cov_map = defaultdict(list)\n",
    "        neg_log_lik = 0.0\n",
    "        key_list = sorted(analysis_data_map)\n",
    "        cut_line = cut_line\n",
    "        heads = analysis_data_map[key_list[0]][:cut_line,:]\n",
    "        for time_idx in range(1, len(analysis_data_map)):\n",
    "            tmp = analysis_data_map[key_list[time_idx]][:cut_line,:]\n",
    "            heads = torch.cat( (heads,tmp), dim=0)\n",
    "\n",
    "        neg_log_lik += self.full_likelihood(params, heads, heads[:, 2], covariance_function)          \n",
    "        \n",
    "        for time_idx in range(0,len(self.input_map)):\n",
    "            current_np = self.input_map[self.key_list[time_idx]]\n",
    "\n",
    "            # Use below when working on local computer to avoid singular matrix\n",
    "            for index in range(cut_line, self.size_per_hour):\n",
    "                current_row = current_np[index].reshape(1, -1)\n",
    "                current_y = current_row[0, 2]\n",
    "\n",
    "                # Construct conditioning set\n",
    "                mm_neighbors = self.nns_map[index]\n",
    "                past = list(mm_neighbors) \n",
    "                data_list = []\n",
    "\n",
    "                if past:\n",
    "                    data_list.append(current_np[past])\n",
    "\n",
    "                if time_idx > 0 and time_idx<7:\n",
    "                    last_hour_np = self.input_map[self.key_list[time_idx - 1]]\n",
    "                    past_conditioning_data = last_hour_np[past + [index], :]\n",
    "                    data_list.append(past_conditioning_data)\n",
    "\n",
    "                    last_hour_np = self.input_map[self.key_list[time_idx +1]]\n",
    "                    # if index==200:\n",
    "                    #     print(self.input_map[self.key_list[time_idx-6]])\n",
    "                    past_conditioning_data = last_hour_np[past + [index], :]\n",
    "                    data_list.append(past_conditioning_data)\n",
    "                \n",
    "                if data_list:\n",
    "                    conditioning_data = torch.vstack(data_list)\n",
    "                else:\n",
    "                    conditioning_data = torch.empty((0, current_row.shape[1]), dtype=torch.float32)\n",
    "\n",
    "                np_arr = torch.vstack((current_row, conditioning_data))\n",
    "                y_and_neighbors = np_arr[:, 2]\n",
    "                locs = np_arr[:, :2]\n",
    "\n",
    "                cov_matrix = covariance_function(params=params, y= np_arr, x= np_arr)\n",
    "                # print(f'Condition number: {torch.linalg.cond(cov_matrix)}')\n",
    "                cov_yx = cov_matrix[0, 1:]\n",
    "                        # Compute the log determinant of the covariance matrix\n",
    "                sign, log_det = torch.slogdet(cov_matrix)\n",
    "                # if sign <= 0:\n",
    "                #     raise ValueError(\"Covariance matrix is not positive definite\")\n",
    "            \n",
    "                y_arr = y_and_neighbors\n",
    "                # Compute beta\n",
    "                tmp1 = torch.matmul(locs.T, torch.linalg.solve(cov_matrix, locs))\n",
    "                tmp2 = torch.matmul(locs.T, torch.linalg.solve(cov_matrix, y_arr))\n",
    "                beta = torch.linalg.solve(tmp1, tmp2)\n",
    "\n",
    "                mu = torch.matmul(locs, beta)\n",
    "                mu_current = mu[0]\n",
    "                mu_neighbors = mu[1:]\n",
    "\n",
    "                # Mean and variance of y|x\n",
    "                sigma = cov_matrix[0, 0]\n",
    "                cov_xx = cov_matrix[1:, 1:]\n",
    "                cov_xx_inv = torch.linalg.inv(cov_xx)\n",
    "\n",
    "                cov_ygivenx = sigma - torch.matmul(cov_yx, torch.matmul(cov_xx_inv, cov_yx))\n",
    "                cond_mean_tmp = torch.matmul(cov_yx, cov_xx_inv)\n",
    "                cond_mean = mu_current + torch.matmul(cond_mean_tmp, (y_and_neighbors[1:] - mu_neighbors))\n",
    "                \n",
    "                alpha = current_y - cond_mean\n",
    "                quad_form = alpha**2 * (1 / cov_ygivenx)\n",
    "                log_det = torch.log(cov_ygivenx)\n",
    "                neg_log_lik += 0.5 * (log_det + quad_form)\n",
    " \n",
    "        return neg_log_lik\n",
    "\n",
    "    def vecchia_b1(self, params: torch.Tensor, covariance_function, cut_line) -> torch.Tensor:\n",
    "        self.cov_map = defaultdict(list)\n",
    "        neg_log_lik = 0.0\n",
    "        key_list = sorted(analysis_data_map)\n",
    "        cut_line = cut_line\n",
    "        heads = analysis_data_map[key_list[0]][:cut_line,:]\n",
    "        for time_idx in range(1, len(analysis_data_map)):\n",
    "            tmp = analysis_data_map[key_list[time_idx]][:cut_line,:]\n",
    "            heads = torch.cat( (heads,tmp), dim=0)\n",
    "\n",
    "        neg_log_lik += self.full_likelihood(params, heads, heads[:, 2], covariance_function)          \n",
    "        \n",
    "        for time_idx in range(0,len(self.input_map)):\n",
    "            current_np = self.input_map[self.key_list[time_idx]]\n",
    "\n",
    "            # Use below when working on local computer to avoid singular matrix\n",
    "            for index in range(cut_line, self.size_per_hour):\n",
    "                current_row = current_np[index].reshape(1, -1)\n",
    "                current_y = current_row[0, 2]\n",
    "\n",
    "                # Construct conditioning set\n",
    "                mm_neighbors = self.nns_map[index]\n",
    "                past = list(mm_neighbors) \n",
    "                data_list = []\n",
    "\n",
    "                if past:\n",
    "                    data_list.append(current_np[past])\n",
    "\n",
    "                if time_idx > 0:\n",
    "                    last_hour_np = self.input_map[self.key_list[time_idx - 1]]\n",
    "                    past_conditioning_data = last_hour_np[past + [index], :]\n",
    "                    data_list.append(past_conditioning_data)\n",
    "\n",
    "                if data_list:\n",
    "                    conditioning_data = torch.vstack(data_list)\n",
    "                else:\n",
    "                    conditioning_data = torch.empty((0, current_row.shape[1]), dtype=torch.float32)\n",
    "\n",
    "                np_arr = torch.vstack((current_row, conditioning_data))\n",
    "                y_and_neighbors = np_arr[:, 2]\n",
    "                locs = np_arr[:, :2]\n",
    "\n",
    "                cov_matrix = covariance_function(params=params, y= np_arr, x= np_arr)\n",
    "                # print(f'Condition number: {torch.linalg.cond(cov_matrix)}')\n",
    "                cov_yx = cov_matrix[0, 1:]\n",
    "                        # Compute the log determinant of the covariance matrix\n",
    "                sign, log_det = torch.slogdet(cov_matrix)\n",
    "                # if sign <= 0:\n",
    "                #     raise ValueError(\"Covariance matrix is not positive definite\")\n",
    "            \n",
    "                y_arr = y_and_neighbors\n",
    "                # Compute beta\n",
    "                tmp1 = torch.matmul(locs.T, torch.linalg.solve(cov_matrix, locs))\n",
    "                tmp2 = torch.matmul(locs.T, torch.linalg.solve(cov_matrix, y_arr))\n",
    "                beta = torch.linalg.solve(tmp1, tmp2)\n",
    "\n",
    "                mu = torch.matmul(locs, beta)\n",
    "                mu_current = mu[0]\n",
    "                mu_neighbors = mu[1:]\n",
    "\n",
    "                # Mean and variance of y|x\n",
    "                sigma = cov_matrix[0, 0]\n",
    "                cov_xx = cov_matrix[1:, 1:]\n",
    "                cov_xx_inv = torch.linalg.inv(cov_xx)\n",
    "\n",
    "                cov_ygivenx = sigma - torch.matmul(cov_yx, torch.matmul(cov_xx_inv, cov_yx))\n",
    "                cond_mean_tmp = torch.matmul(cov_yx, cov_xx_inv)\n",
    "                cond_mean = mu_current + torch.matmul(cond_mean_tmp, (y_and_neighbors[1:] - mu_neighbors))\n",
    "                \n",
    "                alpha = current_y - cond_mean\n",
    "                quad_form = alpha**2 * (1 / cov_ygivenx)\n",
    "                log_det = torch.log(cov_ygivenx)\n",
    "                neg_log_lik += 0.5 * (log_det + quad_form)\n",
    " \n",
    "        return neg_log_lik\n",
    "\n",
    "\n",
    "    def vecchia_b2(self, params: torch.Tensor, covariance_function, cut_line) -> torch.Tensor:\n",
    "        self.cov_map = defaultdict(list)\n",
    "        neg_log_lik = 0.0\n",
    "        key_list = sorted(analysis_data_map)\n",
    "        cut_line = cut_line\n",
    "        heads = analysis_data_map[key_list[0]][:cut_line,:]\n",
    "        for time_idx in range(1, len(analysis_data_map)):\n",
    "            tmp = analysis_data_map[key_list[time_idx]][:cut_line,:]\n",
    "            heads = torch.cat( (heads,tmp), dim=0)\n",
    "\n",
    "        neg_log_lik += self.full_likelihood(params, heads, heads[:, 2], covariance_function)          \n",
    "        \n",
    "        for time_idx in range(0,len(self.input_map)):\n",
    "            current_np = self.input_map[self.key_list[time_idx]]\n",
    "\n",
    "            # Use below when working on local computer to avoid singular matrix\n",
    "            for index in range(cut_line, self.size_per_hour):\n",
    "                current_row = current_np[index].reshape(1, -1)\n",
    "                current_y = current_row[0, 2]\n",
    "\n",
    "                # Construct conditioning set\n",
    "                mm_neighbors = self.nns_map[index]\n",
    "                past = list(mm_neighbors) \n",
    "                data_list = []\n",
    "\n",
    "                if past:\n",
    "                    data_list.append(current_np[past])\n",
    "\n",
    "                if time_idx > 0:\n",
    "                    last_hour_np = self.input_map[self.key_list[time_idx - 1]]\n",
    "                    past_conditioning_data = last_hour_np[past + [index], :]\n",
    "                    data_list.append(past_conditioning_data)\n",
    "\n",
    "                if time_idx > 1:\n",
    "                    last_hour_np = self.input_map[self.key_list[time_idx -2]]\n",
    "                    # if index==200:\n",
    "                    #     print(self.input_map[self.key_list[time_idx-6]])\n",
    "                    past_conditioning_data = last_hour_np[past + [index], :]\n",
    "                    data_list.append(past_conditioning_data)\n",
    "                \n",
    "                if data_list:\n",
    "                    conditioning_data = torch.vstack(data_list)\n",
    "                else:\n",
    "                    conditioning_data = torch.empty((0, current_row.shape[1]), dtype=torch.float32)\n",
    "\n",
    "                np_arr = torch.vstack((current_row, conditioning_data))\n",
    "                y_and_neighbors = np_arr[:, 2]\n",
    "                locs = np_arr[:, :2]\n",
    "\n",
    "                cov_matrix = covariance_function(params=params, y= np_arr, x= np_arr)\n",
    "                # print(f'Condition number: {torch.linalg.cond(cov_matrix)}')\n",
    "                cov_yx = cov_matrix[0, 1:]\n",
    "                        # Compute the log determinant of the covariance matrix\n",
    "                sign, log_det = torch.slogdet(cov_matrix)\n",
    "                # if sign <= 0:\n",
    "                #     raise ValueError(\"Covariance matrix is not positive definite\")\n",
    "            \n",
    "                y_arr = y_and_neighbors\n",
    "                # Compute beta\n",
    "                tmp1 = torch.matmul(locs.T, torch.linalg.solve(cov_matrix, locs))\n",
    "                tmp2 = torch.matmul(locs.T, torch.linalg.solve(cov_matrix, y_arr))\n",
    "                beta = torch.linalg.solve(tmp1, tmp2)\n",
    "\n",
    "                mu = torch.matmul(locs, beta)\n",
    "                mu_current = mu[0]\n",
    "                mu_neighbors = mu[1:]\n",
    "\n",
    "                # Mean and variance of y|x\n",
    "                sigma = cov_matrix[0, 0]\n",
    "                cov_xx = cov_matrix[1:, 1:]\n",
    "                cov_xx_inv = torch.linalg.inv(cov_xx)\n",
    "\n",
    "                cov_ygivenx = sigma - torch.matmul(cov_yx, torch.matmul(cov_xx_inv, cov_yx))\n",
    "                cond_mean_tmp = torch.matmul(cov_yx, cov_xx_inv)\n",
    "                cond_mean = mu_current + torch.matmul(cond_mean_tmp, (y_and_neighbors[1:] - mu_neighbors))\n",
    "                \n",
    "                alpha = current_y - cond_mean\n",
    "                quad_form = alpha**2 * (1 / cov_ygivenx)\n",
    "                log_det = torch.log(cov_ygivenx)\n",
    "                neg_log_lik += 0.5 * (log_det + quad_form)\n",
    " \n",
    "        return neg_log_lik\n",
    "\n",
    "\n",
    "    def vecchia_b3(self, params: torch.Tensor, covariance_function, cut_line) -> torch.Tensor:\n",
    "        self.cov_map = defaultdict(list)\n",
    "        neg_log_lik = 0.0\n",
    "        key_list = sorted(analysis_data_map)\n",
    "        cut_line = cut_line\n",
    "        heads = analysis_data_map[key_list[0]][:cut_line,:]\n",
    "        for time_idx in range(1, len(analysis_data_map)):\n",
    "            tmp = analysis_data_map[key_list[time_idx]][:cut_line,:]\n",
    "            heads = torch.cat( (heads,tmp), dim=0)\n",
    "\n",
    "        neg_log_lik += self.full_likelihood(params, heads, heads[:, 2], covariance_function)          \n",
    "        \n",
    "        for time_idx in range(0,len(self.input_map)):\n",
    "            current_np = self.input_map[self.key_list[time_idx]]\n",
    "\n",
    "            # Use below when working on local computer to avoid singular matrix\n",
    "            for index in range(cut_line, self.size_per_hour):\n",
    "                current_row = current_np[index].reshape(1, -1)\n",
    "                current_y = current_row[0, 2]\n",
    "\n",
    "                # Construct conditioning set\n",
    "                mm_neighbors = self.nns_map[index]\n",
    "                past = list(mm_neighbors) \n",
    "                data_list = []\n",
    "\n",
    "                if past:\n",
    "                    data_list.append(current_np[past])\n",
    "\n",
    "                if time_idx > 0:\n",
    "                    last_hour_np = self.input_map[self.key_list[time_idx - 1]]\n",
    "                    past_conditioning_data = last_hour_np[past + [index], :]\n",
    "                    data_list.append(past_conditioning_data)\n",
    "\n",
    "                if time_idx > 1:\n",
    "                    last_hour_np = self.input_map[self.key_list[time_idx -2]]\n",
    "                    # if index==200:\n",
    "                    #     print(self.input_map[self.key_list[time_idx-6]])\n",
    "                    past_conditioning_data = last_hour_np[past + [index], :]\n",
    "                    data_list.append(past_conditioning_data)\n",
    "\n",
    "                if time_idx > 2:\n",
    "                    last_hour_np = self.input_map[self.key_list[time_idx -3]]\n",
    "                    # if index==200:\n",
    "                    #     print(self.input_map[self.key_list[time_idx-6]])\n",
    "                    past_conditioning_data = last_hour_np[past + [index], :]\n",
    "                    data_list.append(past_conditioning_data)\n",
    "                \n",
    "                if data_list:\n",
    "                    conditioning_data = torch.vstack(data_list)\n",
    "                else:\n",
    "                    conditioning_data = torch.empty((0, current_row.shape[1]), dtype=torch.float32)\n",
    "\n",
    "                np_arr = torch.vstack((current_row, conditioning_data))\n",
    "                y_and_neighbors = np_arr[:, 2]\n",
    "                locs = np_arr[:, :2]\n",
    "\n",
    "                cov_matrix = covariance_function(params=params, y= np_arr, x= np_arr)\n",
    "                # print(f'Condition number: {torch.linalg.cond(cov_matrix)}')\n",
    "                cov_yx = cov_matrix[0, 1:]\n",
    "                        # Compute the log determinant of the covariance matrix\n",
    "                sign, log_det = torch.slogdet(cov_matrix)\n",
    "                # if sign <= 0:\n",
    "                #     raise ValueError(\"Covariance matrix is not positive definite\")\n",
    "            \n",
    "                y_arr = y_and_neighbors\n",
    "                # Compute beta\n",
    "                tmp1 = torch.matmul(locs.T, torch.linalg.solve(cov_matrix, locs))\n",
    "                tmp2 = torch.matmul(locs.T, torch.linalg.solve(cov_matrix, y_arr))\n",
    "                beta = torch.linalg.solve(tmp1, tmp2)\n",
    "\n",
    "                mu = torch.matmul(locs, beta)\n",
    "                mu_current = mu[0]\n",
    "                mu_neighbors = mu[1:]\n",
    "\n",
    "                # Mean and variance of y|x\n",
    "                sigma = cov_matrix[0, 0]\n",
    "                cov_xx = cov_matrix[1:, 1:]\n",
    "                cov_xx_inv = torch.linalg.inv(cov_xx)\n",
    "\n",
    "                cov_ygivenx = sigma - torch.matmul(cov_yx, torch.matmul(cov_xx_inv, cov_yx))\n",
    "                cond_mean_tmp = torch.matmul(cov_yx, cov_xx_inv)\n",
    "                cond_mean = mu_current + torch.matmul(cond_mean_tmp, (y_and_neighbors[1:] - mu_neighbors))\n",
    "                \n",
    "                alpha = current_y - cond_mean\n",
    "                quad_form = alpha**2 * (1 / cov_ygivenx)\n",
    "                log_det = torch.log(cov_ygivenx)\n",
    "                neg_log_lik += 0.5 * (log_det + quad_form)\n",
    " \n",
    "        return neg_log_lik\n",
    "    \n",
    "\n",
    "    def vecchia_b4(self, params: torch.Tensor, covariance_function, cut_line) -> torch.Tensor:\n",
    "        self.cov_map = defaultdict(list)\n",
    "        neg_log_lik = 0.0\n",
    "        key_list = sorted(analysis_data_map)\n",
    "        cut_line = cut_line\n",
    "        heads = analysis_data_map[key_list[0]][:cut_line,:]\n",
    "        for time_idx in range(1, len(analysis_data_map)):\n",
    "            tmp = analysis_data_map[key_list[time_idx]][:cut_line,:]\n",
    "            heads = torch.cat( (heads,tmp), dim=0)\n",
    "\n",
    "        neg_log_lik += self.full_likelihood(params, heads, heads[:, 2], covariance_function)          \n",
    "        \n",
    "        for time_idx in range(0,len(self.input_map)):\n",
    "            current_np = self.input_map[self.key_list[time_idx]]\n",
    "\n",
    "            # Use below when working on local computer to avoid singular matrix\n",
    "            for index in range(cut_line, self.size_per_hour):\n",
    "                current_row = current_np[index].reshape(1, -1)\n",
    "                current_y = current_row[0, 2]\n",
    "\n",
    "                # Construct conditioning set\n",
    "                mm_neighbors = self.nns_map[index]\n",
    "                past = list(mm_neighbors) \n",
    "                data_list = []\n",
    "\n",
    "                if past:\n",
    "                    data_list.append(current_np[past])\n",
    "\n",
    "                if time_idx > 0:\n",
    "                    last_hour_np = self.input_map[self.key_list[time_idx - 1]]\n",
    "                    past_conditioning_data = last_hour_np[past + [index], :]\n",
    "                    data_list.append(past_conditioning_data)\n",
    "\n",
    "                if time_idx > 1:\n",
    "                    last_hour_np = self.input_map[self.key_list[time_idx -2]]\n",
    "                    # if index==200:\n",
    "                    #     print(self.input_map[self.key_list[time_idx-6]])\n",
    "                    past_conditioning_data = last_hour_np[past + [index], :]\n",
    "                    data_list.append(past_conditioning_data)\n",
    "\n",
    "                if time_idx > 2:\n",
    "                    last_hour_np = self.input_map[self.key_list[time_idx -3]]\n",
    "                    # if index==200:\n",
    "                    #     print(self.input_map[self.key_list[time_idx-6]])\n",
    "                    past_conditioning_data = last_hour_np[past + [index], :]\n",
    "                    data_list.append(past_conditioning_data)\n",
    "\n",
    "                if time_idx > 3:\n",
    "                    last_hour_np = self.input_map[self.key_list[time_idx -4]]\n",
    "                    # if index==200:\n",
    "                    #     print(self.input_map[self.key_list[time_idx-6]])\n",
    "                    past_conditioning_data = last_hour_np[past + [index], :]\n",
    "                    data_list.append(past_conditioning_data)\n",
    "\n",
    "                \n",
    "                if data_list:\n",
    "                    conditioning_data = torch.vstack(data_list)\n",
    "                else:\n",
    "                    conditioning_data = torch.empty((0, current_row.shape[1]), dtype=torch.float32)\n",
    "\n",
    "                np_arr = torch.vstack((current_row, conditioning_data))\n",
    "                y_and_neighbors = np_arr[:, 2]\n",
    "                locs = np_arr[:, :2]\n",
    "\n",
    "                cov_matrix = covariance_function(params=params, y= np_arr, x= np_arr)\n",
    "                # print(f'Condition number: {torch.linalg.cond(cov_matrix)}')\n",
    "                cov_yx = cov_matrix[0, 1:]\n",
    "                        # Compute the log determinant of the covariance matrix\n",
    "                sign, log_det = torch.slogdet(cov_matrix)\n",
    "                # if sign <= 0:\n",
    "                #     raise ValueError(\"Covariance matrix is not positive definite\")\n",
    "            \n",
    "                y_arr = y_and_neighbors\n",
    "                # Compute beta\n",
    "                tmp1 = torch.matmul(locs.T, torch.linalg.solve(cov_matrix, locs))\n",
    "                tmp2 = torch.matmul(locs.T, torch.linalg.solve(cov_matrix, y_arr))\n",
    "                beta = torch.linalg.solve(tmp1, tmp2)\n",
    "\n",
    "                mu = torch.matmul(locs, beta)\n",
    "                mu_current = mu[0]\n",
    "                mu_neighbors = mu[1:]\n",
    "\n",
    "                # Mean and variance of y|x\n",
    "                sigma = cov_matrix[0, 0]\n",
    "                cov_xx = cov_matrix[1:, 1:]\n",
    "                cov_xx_inv = torch.linalg.inv(cov_xx)\n",
    "\n",
    "                cov_ygivenx = sigma - torch.matmul(cov_yx, torch.matmul(cov_xx_inv, cov_yx))\n",
    "                cond_mean_tmp = torch.matmul(cov_yx, cov_xx_inv)\n",
    "                cond_mean = mu_current + torch.matmul(cond_mean_tmp, (y_and_neighbors[1:] - mu_neighbors))\n",
    "                \n",
    "                alpha = current_y - cond_mean\n",
    "                quad_form = alpha**2 * (1 / cov_ygivenx)\n",
    "                log_det = torch.log(cov_ygivenx)\n",
    "                neg_log_lik += 0.5 * (log_det + quad_form)\n",
    " \n",
    "        return neg_log_lik\n",
    "\n",
    "    def vecchia_b5(self, params: torch.Tensor, covariance_function, cut_line) -> torch.Tensor:\n",
    "        self.cov_map = defaultdict(list)\n",
    "        neg_log_lik = 0.0\n",
    "        key_list = sorted(analysis_data_map)\n",
    "        cut_line = cut_line\n",
    "        heads = analysis_data_map[key_list[0]][:cut_line,:]\n",
    "        for time_idx in range(1, len(analysis_data_map)):\n",
    "            tmp = analysis_data_map[key_list[time_idx]][:cut_line,:]\n",
    "            heads = torch.cat( (heads,tmp), dim=0)\n",
    "\n",
    "        neg_log_lik += self.full_likelihood(params, heads, heads[:, 2], covariance_function)          \n",
    "        \n",
    "        for time_idx in range(0,len(self.input_map)):\n",
    "            current_np = self.input_map[self.key_list[time_idx]]\n",
    "\n",
    "            # Use below when working on local computer to avoid singular matrix\n",
    "            for index in range(cut_line, self.size_per_hour):\n",
    "                current_row = current_np[index].reshape(1, -1)\n",
    "                current_y = current_row[0, 2]\n",
    "\n",
    "                # Construct conditioning set\n",
    "                mm_neighbors = self.nns_map[index]\n",
    "                past = list(mm_neighbors) \n",
    "                data_list = []\n",
    "\n",
    "                if past:\n",
    "                    data_list.append(current_np[past])\n",
    "\n",
    "                if time_idx > 0:\n",
    "                    last_hour_np = self.input_map[self.key_list[time_idx - 1]]\n",
    "                    past_conditioning_data = last_hour_np[past + [index], :]\n",
    "                    data_list.append(past_conditioning_data)\n",
    "\n",
    "                if time_idx > 1:\n",
    "                    last_hour_np = self.input_map[self.key_list[time_idx -2]]\n",
    "                    # if index==200:\n",
    "                    #     print(self.input_map[self.key_list[time_idx-6]])\n",
    "                    past_conditioning_data = last_hour_np[past + [index], :]\n",
    "                    data_list.append(past_conditioning_data)\n",
    "\n",
    "                if time_idx > 2:\n",
    "                    last_hour_np = self.input_map[self.key_list[time_idx -3]]\n",
    "                    # if index==200:\n",
    "                    #     print(self.input_map[self.key_list[time_idx-6]])\n",
    "                    past_conditioning_data = last_hour_np[past + [index], :]\n",
    "                    data_list.append(past_conditioning_data)\n",
    "\n",
    "                if time_idx > 3:\n",
    "                    last_hour_np = self.input_map[self.key_list[time_idx -4]]\n",
    "                    # if index==200:\n",
    "                    #     print(self.input_map[self.key_list[time_idx-6]])\n",
    "                    past_conditioning_data = last_hour_np[past + [index], :]\n",
    "                    data_list.append(past_conditioning_data)\n",
    "\n",
    "                if time_idx > 4:\n",
    "                    last_hour_np = self.input_map[self.key_list[time_idx -5]]\n",
    "                    # if index==200:\n",
    "                    #     print(self.input_map[self.key_list[time_idx-6]])\n",
    "                    past_conditioning_data = last_hour_np[past + [index], :]\n",
    "                    data_list.append(past_conditioning_data)\n",
    "\n",
    "                \n",
    "                if data_list:\n",
    "                    conditioning_data = torch.vstack(data_list)\n",
    "                else:\n",
    "                    conditioning_data = torch.empty((0, current_row.shape[1]), dtype=torch.float32)\n",
    "\n",
    "                np_arr = torch.vstack((current_row, conditioning_data))\n",
    "                y_and_neighbors = np_arr[:, 2]\n",
    "                locs = np_arr[:, :2]\n",
    "\n",
    "                cov_matrix = covariance_function(params=params, y= np_arr, x= np_arr)\n",
    "                # print(f'Condition number: {torch.linalg.cond(cov_matrix)}')\n",
    "                cov_yx = cov_matrix[0, 1:]\n",
    "                        # Compute the log determinant of the covariance matrix\n",
    "                sign, log_det = torch.slogdet(cov_matrix)\n",
    "                # if sign <= 0:\n",
    "                #     raise ValueError(\"Covariance matrix is not positive definite\")\n",
    "            \n",
    "                y_arr = y_and_neighbors\n",
    "                # Compute beta\n",
    "                tmp1 = torch.matmul(locs.T, torch.linalg.solve(cov_matrix, locs))\n",
    "                tmp2 = torch.matmul(locs.T, torch.linalg.solve(cov_matrix, y_arr))\n",
    "                beta = torch.linalg.solve(tmp1, tmp2)\n",
    "\n",
    "                mu = torch.matmul(locs, beta)\n",
    "                mu_current = mu[0]\n",
    "                mu_neighbors = mu[1:]\n",
    "\n",
    "                # Mean and variance of y|x\n",
    "                sigma = cov_matrix[0, 0]\n",
    "                cov_xx = cov_matrix[1:, 1:]\n",
    "                cov_xx_inv = torch.linalg.inv(cov_xx)\n",
    "\n",
    "                cov_ygivenx = sigma - torch.matmul(cov_yx, torch.matmul(cov_xx_inv, cov_yx))\n",
    "                cond_mean_tmp = torch.matmul(cov_yx, cov_xx_inv)\n",
    "                cond_mean = mu_current + torch.matmul(cond_mean_tmp, (y_and_neighbors[1:] - mu_neighbors))\n",
    "                \n",
    "                alpha = current_y - cond_mean\n",
    "                quad_form = alpha**2 * (1 / cov_ygivenx)\n",
    "                log_det = torch.log(cov_ygivenx)\n",
    "                neg_log_lik += 0.5 * (log_det + quad_form)\n",
    " \n",
    "        return neg_log_lik\n",
    "\n",
    "    def vecchia_b6(self, params: torch.Tensor, covariance_function, cut_line) -> torch.Tensor:\n",
    "        self.cov_map = defaultdict(list)\n",
    "        neg_log_lik = 0.0\n",
    "        key_list = sorted(analysis_data_map)\n",
    "        cut_line = cut_line\n",
    "        heads = analysis_data_map[key_list[0]][:cut_line,:]\n",
    "        for time_idx in range(1, len(analysis_data_map)):\n",
    "            tmp = analysis_data_map[key_list[time_idx]][:cut_line,:]\n",
    "            heads = torch.cat( (heads,tmp), dim=0)\n",
    "\n",
    "        neg_log_lik += self.full_likelihood(params, heads, heads[:, 2], covariance_function)          \n",
    "        \n",
    "        for time_idx in range(0,len(self.input_map)):\n",
    "            current_np = self.input_map[self.key_list[time_idx]]\n",
    "\n",
    "            # Use below when working on local computer to avoid singular matrix\n",
    "            for index in range(cut_line, self.size_per_hour):\n",
    "                current_row = current_np[index].reshape(1, -1)\n",
    "                current_y = current_row[0, 2]\n",
    "\n",
    "                # Construct conditioning set\n",
    "                mm_neighbors = self.nns_map[index]\n",
    "                past = list(mm_neighbors) \n",
    "                data_list = []\n",
    "\n",
    "                if past:\n",
    "                    data_list.append(current_np[past])\n",
    "\n",
    "                if time_idx > 0:\n",
    "                    last_hour_np = self.input_map[self.key_list[time_idx - 1]]\n",
    "                    past_conditioning_data = last_hour_np[past + [index], :]\n",
    "                    data_list.append(past_conditioning_data)\n",
    "\n",
    "                if time_idx > 1:\n",
    "                    last_hour_np = self.input_map[self.key_list[time_idx -2]]\n",
    "                    # if index==200:\n",
    "                    #     print(self.input_map[self.key_list[time_idx-6]])\n",
    "                    past_conditioning_data = last_hour_np[past + [index], :]\n",
    "                    data_list.append(past_conditioning_data)\n",
    "\n",
    "                if time_idx > 2:\n",
    "                    last_hour_np = self.input_map[self.key_list[time_idx -3]]\n",
    "                    # if index==200:\n",
    "                    #     print(self.input_map[self.key_list[time_idx-6]])\n",
    "                    past_conditioning_data = last_hour_np[past + [index], :]\n",
    "                    data_list.append(past_conditioning_data)\n",
    "\n",
    "                if time_idx > 3:\n",
    "                    last_hour_np = self.input_map[self.key_list[time_idx -4]]\n",
    "                    # if index==200:\n",
    "                    #     print(self.input_map[self.key_list[time_idx-6]])\n",
    "                    past_conditioning_data = last_hour_np[past + [index], :]\n",
    "                    data_list.append(past_conditioning_data)\n",
    "\n",
    "                if time_idx > 4:\n",
    "                    last_hour_np = self.input_map[self.key_list[time_idx -5]]\n",
    "                    # if index==200:\n",
    "                    #     print(self.input_map[self.key_list[time_idx-6]])\n",
    "                    past_conditioning_data = last_hour_np[past + [index], :]\n",
    "                    data_list.append(past_conditioning_data)\n",
    "\n",
    "                if time_idx > 5:\n",
    "                    last_hour_np = self.input_map[self.key_list[time_idx -6]]\n",
    "                    # if index==200:\n",
    "                    #     print(self.input_map[self.key_list[time_idx-6]])\n",
    "                    past_conditioning_data = last_hour_np[past + [index], :]\n",
    "                    data_list.append(past_conditioning_data)\n",
    "\n",
    "                \n",
    "                if data_list:\n",
    "                    conditioning_data = torch.vstack(data_list)\n",
    "                else:\n",
    "                    conditioning_data = torch.empty((0, current_row.shape[1]), dtype=torch.float32)\n",
    "\n",
    "                np_arr = torch.vstack((current_row, conditioning_data))\n",
    "                y_and_neighbors = np_arr[:, 2]\n",
    "                locs = np_arr[:, :2]\n",
    "\n",
    "                cov_matrix = covariance_function(params=params, y= np_arr, x= np_arr)\n",
    "                # print(f'Condition number: {torch.linalg.cond(cov_matrix)}')\n",
    "                cov_yx = cov_matrix[0, 1:]\n",
    "                        # Compute the log determinant of the covariance matrix\n",
    "                sign, log_det = torch.slogdet(cov_matrix)\n",
    "                # if sign <= 0:\n",
    "                #     raise ValueError(\"Covariance matrix is not positive definite\")\n",
    "            \n",
    "                y_arr = y_and_neighbors\n",
    "                # Compute beta\n",
    "                tmp1 = torch.matmul(locs.T, torch.linalg.solve(cov_matrix, locs))\n",
    "                tmp2 = torch.matmul(locs.T, torch.linalg.solve(cov_matrix, y_arr))\n",
    "                beta = torch.linalg.solve(tmp1, tmp2)\n",
    "\n",
    "                mu = torch.matmul(locs, beta)\n",
    "                mu_current = mu[0]\n",
    "                mu_neighbors = mu[1:]\n",
    "\n",
    "                # Mean and variance of y|x\n",
    "                sigma = cov_matrix[0, 0]\n",
    "                cov_xx = cov_matrix[1:, 1:]\n",
    "                cov_xx_inv = torch.linalg.inv(cov_xx)\n",
    "\n",
    "                cov_ygivenx = sigma - torch.matmul(cov_yx, torch.matmul(cov_xx_inv, cov_yx))\n",
    "                cond_mean_tmp = torch.matmul(cov_yx, cov_xx_inv)\n",
    "                cond_mean = mu_current + torch.matmul(cond_mean_tmp, (y_and_neighbors[1:] - mu_neighbors))\n",
    "                \n",
    "                alpha = current_y - cond_mean\n",
    "                quad_form = alpha**2 * (1 / cov_ygivenx)\n",
    "                log_det = torch.log(cov_ygivenx)\n",
    "                neg_log_lik += 0.5 * (log_det + quad_form)\n",
    " \n",
    "        return neg_log_lik\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " day 1 data size per day: 200.0 \n",
      "\n",
      "full: 2553.678925484088\n",
      "vecc t-1, t+1: 2507.1623213701373\n",
      "vecc one lag : 2576.920816718928\n",
      "vecc two lags: 2576.920816718928\n",
      "vecc three lags: 2573.5734278895256\n",
      "vecc four lags: 2576.13271979959\n",
      " day 2 full 2553.678925484088 best 2-19.894502405437834\n",
      "\n",
      " day 2 data size per day: 200.0 \n",
      "\n",
      "full: 2236.099535758033\n",
      "vecc t-1, t+1: 2195.7420243868255\n",
      "vecc one lag : 2247.0187365411102\n",
      "vecc two lags: 2247.0187365411102\n",
      "vecc three lags: 2243.6654954193264\n",
      "vecc four lags: 2243.630764717792\n",
      " day 3 full 2236.099535758033 best 4-7.162646744208814\n",
      "\n",
      " day 3 data size per day: 200.0 \n",
      "\n",
      "full: 2653.7427420660033\n",
      "vecc t-1, t+1: 2610.935083276704\n",
      "vecc one lag : 2688.2294087458536\n",
      "vecc two lags: 2688.2294087458536\n",
      "vecc three lags: 2687.393136085843\n",
      "vecc four lags: 2686.567852539275\n",
      " day 4 full 2653.7427420660033 best 4-32.45233422016963\n",
      "\n",
      " day 4 data size per day: 200.0 \n",
      "\n",
      "full: 2580.4248381590032\n",
      "vecc t-1, t+1: 2568.658463248756\n",
      "vecc one lag : 2623.085432863803\n",
      "vecc two lags: 2623.085432863803\n",
      "vecc three lags: 2611.661261640396\n",
      "vecc four lags: 2608.2775929251065\n",
      " day 5 full 2580.4248381590032 best 0-11.766374910247123\n",
      "\n",
      " day 5 data size per day: 200.0 \n",
      "\n",
      "full: 2165.5222661960047\n",
      "vecc t-1, t+1: 2134.158329828968\n",
      "vecc one lag : 2199.4067564527463\n",
      "vecc two lags: 2199.4067564527463\n",
      "vecc three lags: 2192.67426648255\n",
      "vecc four lags: 2192.031430642477\n",
      " day 6 full 2165.5222661960047 best 3-26.50916444647237\n",
      "\n",
      " day 6 data size per day: 200.0 \n",
      "\n",
      "full: 2569.4795113206137\n",
      "vecc t-1, t+1: 2518.228773246537\n",
      "vecc one lag : 2593.159728258142\n",
      "vecc two lags: 2593.159728258142\n",
      "vecc three lags: 2595.917041742643\n",
      "vecc four lags: 2597.06871320482\n",
      " day 7 full 2569.4795113206137 best 1-23.680216937528257\n",
      "\n",
      " day 7 data size per day: 200.0 \n",
      "\n",
      "full: 2668.8397160680224\n",
      "vecc t-1, t+1: 2657.219888283512\n",
      "vecc one lag : 2730.889684430839\n",
      "vecc two lags: 2730.889684430839\n",
      "vecc three lags: 2727.0586061324266\n",
      "vecc four lags: 2723.8837975646143\n",
      " day 8 full 2668.8397160680224 best 0-11.619827784510562\n",
      "\n",
      " day 8 data size per day: 200.0 \n",
      "\n",
      "full: 2649.8970381406953\n",
      "vecc t-1, t+1: 2659.81201832585\n",
      "vecc one lag : 2755.540586397968\n",
      "vecc two lags: 2755.540586397968\n",
      "vecc three lags: 2747.075341293754\n",
      "vecc four lags: 2745.21561610021\n",
      " day 9 full 2649.8970381406953 best 0-9.914980185154946\n",
      "\n",
      " day 9 data size per day: 200.0 \n",
      "\n",
      "full: 2379.085139096838\n",
      "vecc t-1, t+1: 2349.751203804738\n",
      "vecc one lag : 2444.7842423582365\n",
      "vecc two lags: 2444.7842423582365\n",
      "vecc three lags: 2443.409046580933\n",
      "vecc four lags: 2441.936121783107\n",
      " day 10 full 2379.085139096838 best 0-29.333935292099795\n",
      "\n",
      " day 10 data size per day: 200.0 \n",
      "\n",
      "full: 2596.615708745634\n",
      "vecc t-1, t+1: 2518.8752391962485\n",
      "vecc one lag : 2633.51614287934\n",
      "vecc two lags: 2633.51614287934\n",
      "vecc three lags: 2633.296259949058\n",
      "vecc four lags: 2632.727610879946\n",
      " day 11 full 2596.615708745634 best 4-35.76402912541789\n",
      "\n",
      " day 11 data size per day: 200.0 \n",
      "\n",
      "full: 2329.29366696095\n",
      "vecc t-1, t+1: 2285.768747181174\n",
      "vecc one lag : 2360.705616687599\n",
      "vecc two lags: 2360.705616687599\n",
      "vecc three lags: 2360.0331764027183\n",
      "vecc four lags: 2361.0841649792237\n",
      " day 12 full 2329.29366696095 best 2-30.739509441768405\n",
      "\n",
      " day 12 data size per day: 200.0 \n",
      "\n",
      "full: 2099.32241814758\n",
      "vecc t-1, t+1: 2078.910419670493\n",
      "vecc one lag : 2134.6353808277895\n",
      "vecc two lags: 2134.6353808277895\n",
      "vecc three lags: 2134.6805952034656\n",
      "vecc four lags: 2135.7769378355747\n",
      " day 13 full 2099.32241814758 best 0-20.411998477086854\n",
      "\n",
      " day 13 data size per day: 200.0 \n",
      "\n",
      "full: 2123.976104214975\n",
      "vecc t-1, t+1: 2105.782926951142\n",
      "vecc one lag : 2149.915126959798\n",
      "vecc two lags: 2149.915126959798\n",
      "vecc three lags: 2149.844877521256\n",
      "vecc four lags: 2150.6790152144426\n",
      " day 14 full 2123.976104214975 best 0-18.193177263832695\n",
      "\n",
      " day 14 data size per day: 200.0 \n",
      "\n",
      "full: 2390.045588207836\n",
      "vecc t-1, t+1: 2336.231172673803\n",
      "vecc one lag : 2405.1932149886547\n",
      "vecc two lags: 2405.1932149886547\n",
      "vecc three lags: 2402.7989347105463\n",
      "vecc four lags: 2401.8888974376814\n",
      " day 15 full 2390.045588207836 best 4-11.571486896274564\n",
      "\n",
      " day 15 data size per day: 200.0 \n",
      "\n",
      "full: 2065.0404212564567\n",
      "vecc t-1, t+1: 2037.760398348179\n",
      "vecc one lag : 2088.6016354510853\n",
      "vecc two lags: 2088.6016354510853\n",
      "vecc three lags: 2086.1213956438773\n",
      "vecc four lags: 2086.119012014646\n",
      " day 16 full 2065.0404212564567 best 3-21.07859075818942\n",
      "\n",
      " day 16 data size per day: 200.0 \n",
      "\n",
      "full: 2159.2230433795153\n",
      "vecc t-1, t+1: 2135.6990656426397\n",
      "vecc one lag : 2179.5654769132047\n",
      "vecc two lags: 2179.5654769132047\n",
      "vecc three lags: 2176.989067311791\n",
      "vecc four lags: 2179.617977505956\n",
      " day 17 full 2159.2230433795153 best 2-17.766023932275857\n",
      "\n",
      " day 17 data size per day: 200.0 \n",
      "\n",
      "full: 2601.5881630971935\n",
      "vecc t-1, t+1: 2548.069486123228\n",
      "vecc one lag : 2606.7387974393364\n",
      "vecc two lags: 2606.7387974393364\n",
      "vecc three lags: 2603.30995515515\n",
      "vecc four lags: 2605.66484820941\n",
      " day 18 full 2601.5881630971935 best 2-1.7217920579564634\n",
      "\n",
      " day 18 data size per day: 200.0 \n",
      "\n",
      "full: 2448.6888325927493\n",
      "vecc t-1, t+1: 2402.2759038652343\n",
      "vecc one lag : 2468.8580909226807\n",
      "vecc two lags: 2468.8580909226807\n",
      "vecc three lags: 2467.9213281710536\n",
      "vecc four lags: 2469.678880321856\n",
      " day 19 full 2448.6888325927493 best 2-19.232495578304224\n",
      "\n",
      " day 19 data size per day: 200.0 \n",
      "\n",
      "full: 2304.9721300142137\n",
      "vecc t-1, t+1: 2242.145384373631\n",
      "vecc one lag : 2339.8734823333934\n",
      "vecc two lags: 2339.8734823333934\n",
      "vecc three lags: 2339.6548923937244\n",
      "vecc four lags: 2341.0426509464637\n",
      " day 20 full 2304.9721300142137 best 2-34.68276237951068\n",
      "\n",
      " day 20 data size per day: 200.0 \n",
      "\n",
      "full: 2332.4791486328168\n",
      "vecc t-1, t+1: 2304.34426522697\n",
      "vecc one lag : 2357.529583697717\n",
      "vecc two lags: 2357.529583697717\n",
      "vecc three lags: 2355.028735203141\n",
      "vecc four lags: 2356.287634858894\n",
      " day 21 full 2332.4791486328168 best 2-22.54958657032421\n",
      "\n",
      " day 21 data size per day: 200.0 \n",
      "\n",
      "full: 2345.8873999223597\n",
      "vecc t-1, t+1: 2319.7429749280586\n",
      "vecc one lag : 2356.578904684273\n",
      "vecc two lags: 2356.578904684273\n",
      "vecc three lags: 2347.3008506857427\n",
      "vecc four lags: 2346.6895762927315\n",
      " day 22 full 2345.8873999223597 best 3-0.8021763703718534\n",
      "\n",
      " day 22 data size per day: 200.0 \n",
      "\n",
      "full: 2330.5640652038496\n",
      "vecc t-1, t+1: 2349.387162000116\n",
      "vecc one lag : 2364.840708839527\n",
      "vecc two lags: 2364.840708839527\n",
      "vecc three lags: 2363.5675431349164\n",
      "vecc four lags: 2363.3668762692155\n",
      " day 23 full 2330.5640652038496 best 0-18.823096796266327\n",
      "\n",
      " day 23 data size per day: 200.0 \n",
      "\n",
      "full: 2025.4645162583156\n",
      "vecc t-1, t+1: 2000.7006283552519\n",
      "vecc one lag : 2046.197326486701\n",
      "vecc two lags: 2046.197326486701\n",
      "vecc three lags: 2045.3977041116448\n",
      "vecc four lags: 2044.4223534459918\n",
      " day 24 full 2025.4645162583156 best 3-18.957837187676205\n",
      "\n",
      " day 24 data size per day: 200.0 \n",
      "\n",
      "full: 2088.9312526568597\n",
      "vecc t-1, t+1: 2071.4182113441966\n",
      "vecc one lag : 2116.6307826340926\n",
      "vecc two lags: 2116.6307826340926\n",
      "vecc three lags: 2114.588662186965\n",
      "vecc four lags: 2114.2566826152843\n",
      " day 25 full 2088.9312526568597 best 0-17.513041312663063\n",
      "\n",
      " day 25 data size per day: 200.0 \n",
      "\n",
      "full: 1570.5908446396452\n",
      "vecc t-1, t+1: 1513.7885143095325\n",
      "vecc one lag : 1596.8462492018557\n",
      "vecc two lags: 1596.8462492018557\n",
      "vecc three lags: 1584.468227127601\n",
      "vecc four lags: 1586.0558327543142\n",
      " day 26 full 1570.5908446396452 best 2-13.877382487955856\n",
      "\n",
      " day 26 data size per day: 200.0 \n",
      "\n",
      "full: 1837.292810608712\n",
      "vecc t-1, t+1: 1822.2113561029964\n",
      "vecc one lag : 1856.7143986824403\n",
      "vecc two lags: 1856.7143986824403\n",
      "vecc three lags: 1849.6890370217313\n",
      "vecc four lags: 1847.653970778117\n",
      " day 27 full 1837.292810608712 best 3-10.361160169404911\n",
      "\n",
      " day 27 data size per day: 200.0 \n",
      "\n",
      "full: 1926.7565449166057\n",
      "vecc t-1, t+1: 1882.3517652531875\n",
      "vecc one lag : 1968.8582705406561\n",
      "vecc two lags: 1968.8582705406561\n",
      "vecc three lags: 1964.549565195396\n",
      "vecc four lags: 1963.7836006786656\n",
      " day 28 full 1926.7565449166057 best 4-36.8293432063972\n",
      "\n",
      " day 28 data size per day: 200.0 \n",
      "\n",
      "full: 2247.1905502853724\n",
      "vecc t-1, t+1: 2205.2971827771876\n",
      "vecc one lag : 2272.1417864500154\n",
      "vecc two lags: 2272.1417864500154\n",
      "vecc three lags: 2265.772745797057\n",
      "vecc four lags: 2267.0761838271487\n",
      " day 29 full 2247.1905502853724 best 2-18.582195511684404\n",
      "\n",
      " day 29 data size per day: 200.0 \n",
      "\n",
      "full: 2129.915724387622\n",
      "vecc t-1, t+1: 2090.2963773723764\n",
      "vecc one lag : 2154.771244592155\n",
      "vecc two lags: 2154.771244592155\n",
      "vecc three lags: 2148.9814180361786\n",
      "vecc four lags: 2148.0526788691823\n",
      " day 30 full 2129.915724387622 best 3-18.136954481560224\n",
      "\n",
      " day 30 data size per day: 200.0 \n",
      "\n",
      "full: 2346.168178698737\n",
      "vecc t-1, t+1: 2320.595704934063\n",
      "vecc one lag : 2361.3006926080816\n",
      "vecc two lags: 2361.3006926080816\n",
      "vecc three lags: 2359.0309896232948\n",
      "vecc four lags: 2358.948705311743\n",
      " day 31 full 2346.168178698737 best 4-12.37721563783407\n"
     ]
    }
   ],
   "source": [
    "lat_lon_resolution = [10,10]\n",
    "years = ['2024']\n",
    "month_range =[7,8]\n",
    "\n",
    "\n",
    "result = [0]*5\n",
    "for day in range(1,31):\n",
    "    print(f'\\n day {day} data size per day: { (200/lat_lon_resolution[0])*(100/lat_lon_resolution[0])  } \\n')\n",
    "\n",
    "    mm_cond_number = 10+day\n",
    "\n",
    "    idx_for_datamap= [ 8*(day-1),8*day]\n",
    "\n",
    "    instance = load_data_local_computer()\n",
    "    map, ord_mm, nns_map= instance.load_mm20k_data_bymonthyear( lat_lon_resolution= lat_lon_resolution, mm_cond_number=mm_cond_number,years_=years, months_=month_range)\n",
    "    analysis_data_map, aggregated_data = instance.load_working_data_byday( map, ord_mm, nns_map, idx_for_datamap= idx_for_datamap)\n",
    "\n",
    "    params = [ 27.25, 2.18, 2.294, 4.099e-4, -0.07915, 0.0999, 3.65]   #200\n",
    "    params = list(df.iloc[day-1][:-1])\n",
    "    params = torch.tensor(params, dtype=torch.float64, requires_grad=True)\n",
    "    instance = torch_vecchia_exp(analysis_data_map, params, nns_map, mm_cond_number)\n",
    "\n",
    "    out = instance.full_likelihood(params, aggregated_data[:,:4],aggregated_data[:,2], instance.matern_cov_ani)\n",
    "    print(f'full: {out}')  # 15105\n",
    "\n",
    "    out1 = instance.vecchia_interpolation_1to6(params,  instance.matern_cov_ani,10)\n",
    "    print(f'vecc t-1, t+1: {out1}')  # 15105\n",
    "\n",
    "    out2 = instance.vecchia_b1(params,  instance.matern_cov_ani,10)\n",
    "    print(f'vecc one lag : {out2}')  # 15105\n",
    "\n",
    "    out3 = instance.vecchia_b2(params,  instance.matern_cov_ani,10)\n",
    "    print(f'vecc two lags: {out2}')  # 15105\n",
    "\n",
    "    out4 = instance.vecchia_b3(params,  instance.matern_cov_ani,10)\n",
    "    print(f'vecc three lags: {out3}')  # 15105\n",
    "\n",
    "    out5 = instance.vecchia_b4(params,  instance.matern_cov_ani,10)\n",
    "    print(f'vecc four lags: {out4}')  # 15105\n",
    "\n",
    "\n",
    "    tmp_result = [ torch.abs(out-out1), torch.abs(out-out2),torch.abs(out-out3),torch.abs(out-out4),torch.abs(out-out5) ]\n",
    "    for i in range(5):\n",
    "        if tmp_result[i] == min(tmp_result):\n",
    "            result[i] +=1   #  mm_cond 10 , head10 then 3 2 11 4 1 4 0 \n",
    "\n",
    "            print(f' day {day+1} full {out} best {i}-{min(tmp_result)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 1, 9, 6, 6]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2 = result.copy()\n",
    "result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " day 1 data size per day: 1250.0 \n",
      "\n",
      "full: 14068.486752749093\n",
      "vecc t-1, t+1: 13982.689208138287\n",
      "vecc one lag : 14201.998055004173\n",
      "vecc two lags: 14201.998055004173\n",
      "vecc three lags: 14205.603450360539\n",
      "vecc four lags: 14201.395993475311\n",
      " day 2 full 14068.486752749093 best 0-85.79754461080665\n",
      "\n",
      " day 2 data size per day: 1250.0 \n",
      "\n",
      "full: 12357.708795058907\n",
      "vecc t-1, t+1: 12279.933181631382\n",
      "vecc one lag : 12472.641109561619\n",
      "vecc two lags: 12472.641109561619\n",
      "vecc three lags: 12465.056416225934\n",
      "vecc four lags: 12468.953487415489\n",
      " day 3 full 12357.708795058907 best 0-77.77561342752415\n",
      "\n",
      " day 3 data size per day: 1250.0 \n",
      "\n",
      "full: 14948.131212192107\n",
      "vecc t-1, t+1: 14931.098753063909\n",
      "vecc one lag : 15109.033805340665\n",
      "vecc two lags: 15109.033805340665\n",
      "vecc three lags: 15101.08932108893\n",
      "vecc four lags: 15101.5065164862\n",
      " day 4 full 14948.131212192107 best 0-17.032459128198752\n",
      "\n",
      " day 4 data size per day: 1250.0 \n",
      "\n",
      "full: 14785.598049194457\n",
      "vecc t-1, t+1: 14798.53219257884\n",
      "vecc one lag : 15001.062994432981\n",
      "vecc two lags: 15001.062994432981\n",
      "vecc three lags: 14993.671567147545\n",
      "vecc four lags: 14989.883860001546\n",
      " day 5 full 14785.598049194457 best 0-12.934143384381969\n",
      "\n",
      " day 5 data size per day: 1250.0 \n",
      "\n",
      "full: 12096.251148713112\n",
      "vecc t-1, t+1: 12030.333470361122\n",
      "vecc one lag : 12213.243697183321\n",
      "vecc two lags: 12213.243697183321\n",
      "vecc three lags: 12208.512957744002\n",
      "vecc four lags: 12212.741475464858\n",
      " day 6 full 12096.251148713112 best 0-65.91767835199062\n",
      "\n",
      " day 6 data size per day: 1250.0 \n",
      "\n",
      "full: 14690.24066140593\n",
      "vecc t-1, t+1: 14609.993327941687\n",
      "vecc one lag : 14855.960526272993\n",
      "vecc two lags: 14855.960526272993\n",
      "vecc three lags: 14849.942737126952\n",
      "vecc four lags: 14848.373610379589\n",
      " day 7 full 14690.24066140593 best 0-80.24733346424182\n",
      "\n",
      " day 7 data size per day: 1250.0 \n",
      "\n",
      "full: 15342.455709089625\n",
      "vecc t-1, t+1: 15399.58834262416\n",
      "vecc one lag : 15559.157883605558\n",
      "vecc two lags: 15559.157883605558\n",
      "vecc three lags: 15554.045561545947\n",
      "vecc four lags: 15548.79982563646\n",
      " day 8 full 15342.455709089625 best 0-57.13263353453476\n",
      "\n",
      " day 8 data size per day: 1250.0 \n",
      "\n",
      "full: 14857.187945276979\n",
      "vecc t-1, t+1: 14928.887558436852\n",
      "vecc one lag : 15236.535505660238\n",
      "vecc two lags: 15236.535505660238\n",
      "vecc three lags: 15205.612294121162\n",
      "vecc four lags: 15200.226339414385\n",
      " day 9 full 14857.187945276979 best 0-71.69961315987348\n",
      "\n",
      " day 9 data size per day: 1250.0 \n",
      "\n",
      "full: 12666.991036904043\n",
      "vecc t-1, t+1: 12645.178753959337\n",
      "vecc one lag : 12868.332369636228\n",
      "vecc two lags: 12868.332369636228\n",
      "vecc three lags: 12858.365090833742\n",
      "vecc four lags: 12862.090698545187\n",
      " day 10 full 12666.991036904043 best 0-21.812282944705657\n",
      "\n",
      " day 10 data size per day: 1250.0 \n",
      "\n",
      "full: 14987.7629397366\n",
      "vecc t-1, t+1: 14913.02421660553\n",
      "vecc one lag : 15124.357611232199\n",
      "vecc two lags: 15124.357611232199\n",
      "vecc three lags: 15114.721477318682\n",
      "vecc four lags: 15115.309368028558\n",
      " day 11 full 14987.7629397366 best 0-74.73872313106949\n",
      "\n",
      " day 11 data size per day: 1250.0 \n",
      "\n",
      "full: 13000.418436884574\n",
      "vecc t-1, t+1: 12885.210516887473\n",
      "vecc one lag : 13107.635898416169\n",
      "vecc two lags: 13107.635898416169\n",
      "vecc three lags: 13100.545927005287\n",
      "vecc four lags: 13103.082978802715\n",
      " day 12 full 13000.418436884574 best 2-100.12749012071254\n",
      "\n",
      " day 12 data size per day: 1250.0 \n",
      "\n",
      "full: 11485.487155867559\n",
      "vecc t-1, t+1: 11441.078191828172\n",
      "vecc one lag : 11586.663704217299\n",
      "vecc two lags: 11586.663704217299\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "lat_lon_resolution = [4,4]\n",
    "years = ['2024']\n",
    "month_range =[7,8]\n",
    "\n",
    "\n",
    "result = [0]* 5 \n",
    "for day in range(1,31):\n",
    "    print(f'\\n day {day} data size per day: { (200/lat_lon_resolution[0])*(100/lat_lon_resolution[0])  } \\n')\n",
    "\n",
    "    mm_cond_number = 10+day\n",
    "\n",
    "    idx_for_datamap= [ 8*(day-1),8*day]\n",
    "\n",
    "    instance = load_data_local_computer()\n",
    "    map, ord_mm, nns_map= instance.load_mm20k_data_bymonthyear( lat_lon_resolution= lat_lon_resolution, mm_cond_number=mm_cond_number,years_=years, months_=month_range)\n",
    "    analysis_data_map, aggregated_data = instance.load_working_data_byday( map, ord_mm, nns_map, idx_for_datamap= idx_for_datamap)\n",
    "\n",
    "    params = [ 27.25, 2.18, 2.294, 4.099e-4, -0.07915, 0.0999, 3.65]   #200\n",
    "    params = list(df.iloc[day-1][:-1])\n",
    "    params = torch.tensor(params, dtype=torch.float64, requires_grad=True)\n",
    "    instance = torch_vecchia_exp(analysis_data_map, params, nns_map, mm_cond_number)\n",
    "\n",
    "    out = instance.full_likelihood(params, aggregated_data[:,:4],aggregated_data[:,2], instance.matern_cov_ani)\n",
    "    print(f'full: {out}')  # 15105\n",
    "\n",
    "    out1 = instance.vecchia_interpolation_1to6(params,  instance.matern_cov_ani,10)\n",
    "    print(f'vecc t-1, t+1: {out1}')  # 15105\n",
    "\n",
    "    out2 = instance.vecchia_b1(params,  instance.matern_cov_ani,10)\n",
    "    print(f'vecc one lag : {out2}')  # 15105\n",
    "\n",
    "    out3 = instance.vecchia_b2(params,  instance.matern_cov_ani,10)\n",
    "    print(f'vecc two lags: {out2}')  # 15105\n",
    "\n",
    "    out4 = instance.vecchia_b3(params,  instance.matern_cov_ani,10)\n",
    "    print(f'vecc three lags: {out3}')  # 15105\n",
    "\n",
    "    out5 = instance.vecchia_b4(params,  instance.matern_cov_ani,10)\n",
    "    print(f'vecc four lags: {out4}')  # 15105\n",
    "\n",
    "\n",
    "    tmp_result = [ torch.abs(out-out1), torch.abs(out-out2),torch.abs(out-out3),torch.abs(out-out4),torch.abs(out-out5) ]\n",
    "    for i in range(5):\n",
    "        if tmp_result[i] == min(tmp_result):\n",
    "            result[i] +=1   #  mm_cond 10 , head10 then 3 2 11 4 1 4 0 \n",
    "\n",
    "            print(f' day {day+1} full {out} best {i}-{min(tmp_result)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " day 1 \n",
      "\n",
      "tensor(1385.7854, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(1385.0739, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1413.0866, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1338.3399, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1360.4388, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "\n",
      " day 2 \n",
      "\n",
      "tensor(1178.2726, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(1177.9323, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1184.0392, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1157.8186, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1147.4878, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "\n",
      " day 3 \n",
      "\n",
      "tensor(1359.9156, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(1359.5285, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1373.3153, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1335.5067, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1340.1894, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "\n",
      " day 4 \n",
      "\n",
      "tensor(1302.8228, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(1302.4777, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1315.7073, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1280.9686, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1274.3852, dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "lat_lon_resolution = [15,15]\n",
    "years = ['2024']\n",
    "month_range =[7,8]\n",
    "\n",
    "\n",
    "b = [0]*7\n",
    "\n",
    "b1=b2=b3=b4=b5=b6=0\n",
    "for day in range(1,5):\n",
    "    print(f'\\n day {day} \\n')\n",
    "\n",
    "    mm_cond_number = 10+day\n",
    "\n",
    "    idx_for_datamap= [ 8*(day-1),8*day]\n",
    "\n",
    "    instance = load_data_local_computer()\n",
    "    map, ord_mm, nns_map= instance.load_mm20k_data_bymonthyear( lat_lon_resolution= lat_lon_resolution, mm_cond_number=mm_cond_number,years_=years, months_=month_range)\n",
    "    analysis_data_map, aggregated_data = instance.load_working_data_byday( map, ord_mm, nns_map, idx_for_datamap= idx_for_datamap)\n",
    "\n",
    "    params = [ 27.25, 2.18, 2.294, 4.099e-4, -0.07915, 0.0999, 3.65]   #200\n",
    "    params = torch.tensor(params, dtype=torch.float64, requires_grad=True)\n",
    "    instance = torch_vecchia_exp(analysis_data_map, params, nns_map, mm_cond_number)\n",
    "\n",
    "    out = instance.full_likelihood(params, aggregated_data[:,:4],aggregated_data[:,2], instance.matern_cov_ani)\n",
    "    print(out)  # 15105\n",
    "\n",
    "\n",
    "    out = instance.vecchia_local_full_cond(params,  instance.matern_cov_ani)\n",
    "    print(out)  # 15105\n",
    "\n",
    "    out = instance.vecchia_b2(params,  instance.matern_cov_ani,10)\n",
    "    print(out)  # 15105\n",
    "\n",
    "    out = instance.vecchia_interpolation_1to6(params,  instance.matern_cov_ani,10)\n",
    "    print(out)  # 15105\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2588.8355, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(2539.4274, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2538.5730, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2538.1789, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2539.9501, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2542.8933, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2543.5865, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2544.8655, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "day 1 finished\n"
     ]
    }
   ],
   "source": [
    "lat_lon_resolution = [10,10]\n",
    "\n",
    "head100map = defaultdict(list)\n",
    "\n",
    "headn = 10\n",
    "b = [0]*7\n",
    "b1=b2=b3=b4=b5=b6=0\n",
    "for day in range(1,2):\n",
    "    mm_cond_number = 10\n",
    "\n",
    "    years = ['2024']\n",
    "    month_range =[7,8]\n",
    "    idx_for_datamap= [ 8*(day-1),8*day]\n",
    "\n",
    "    instance = load_data_local_computer()\n",
    "    map, ord_mm, nns_map= instance.load_mm20k_data_bymonthyear( lat_lon_resolution= lat_lon_resolution, mm_cond_number=mm_cond_number,years_=years, months_=month_range)\n",
    "    analysis_data_map, aggregated_data = instance.load_working_data_byday( map, ord_mm, nns_map, idx_for_datamap= idx_for_datamap)\n",
    "\n",
    "    params = [24.42, 1.92, 1.92, 0.001, -0.045, 0.237, 3.34]\n",
    "    params = torch.tensor(params, requires_grad=True)\n",
    "    instance = torch_vecchia_exp(analysis_data_map, params, nns_map, mm_cond_number)\n",
    "    out = instance.full_likelihood(params, aggregated_data[:,:4],aggregated_data[:,2], instance.matern_cov_ani)\n",
    "    print(out)  # 15105\n",
    "\n",
    "    out1 = instance.vecchia_interpolation_1to6(params, instance.matern_cov_ani, 5)\n",
    "    print(out1)   # 15181.4775  15183 0,1 lage 15185 0,2\n",
    "\n",
    "    out1 = instance.vecchia_interpolation_1to6(params, instance.matern_cov_ani, headn)\n",
    "    print(out1)   # 15181.4775  15183 0,1 lage 15185 0,2\n",
    "\n",
    "    out1 = instance.vecchia_interpolation_1to6(params, instance.matern_cov_ani, 15)\n",
    "    print(out1)   # 15181.4775  15183 0,1 lage 15185 0,2\n",
    "\n",
    "    out1 = instance.vecchia_interpolation_1to6(params, instance.matern_cov_ani, 20)\n",
    "    print(out1)   # 15181.4775  15183 0,1 lage 15185 0,2\n",
    "\n",
    "    out1 = instance.vecchia_interpolation_1to6(params, instance.matern_cov_ani, 25)\n",
    "    print(out1)   # 15181.4775  15183 0,1 lage 15185 0,2\n",
    "\n",
    "    out1 = instance.vecchia_interpolation_1to6(params, instance.matern_cov_ani, 30)\n",
    "    print(out1)   # 15181.4775  15183 0,1 lage 15185 0,2\n",
    "\n",
    "    out1 = instance.vecchia_interpolation_1to6(params, instance.matern_cov_ani, 35)\n",
    "    print(out1)   # 15181.4775  15183 0,1 lage 15185 0,2\n",
    "    print(f'day {day} finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sigmasq         25.822897\n",
       "range_lat        1.023014\n",
       "range_lon        1.131423\n",
       "advec_lat        0.073286\n",
       "advec_lon       -0.095810\n",
       "beta             0.177670\n",
       "nugget           1.569700\n",
       "loss         50396.417969\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2588.8355, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(2598.6200, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2596.4554, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2597.2973, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2597.4288, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2597.6245, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2597.7251, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      " day 2 full 2588.835494538167 best 2-7.619876935808406\n",
      "tensor(2325.3057, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(2338.3503, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2337.2224, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2337.3480, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2337.8504, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2337.7865, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2337.9979, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      " day 3 full 2325.3057231697794 best 2-11.916687282841394\n",
      "tensor(2677.8738, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(2711.6530, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2710.8470, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2710.0946, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2710.2561, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2710.2624, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2710.2837, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      " day 4 full 2677.873782988168 best 3-32.22080760327162\n",
      "tensor(2607.6200, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(2626.1323, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2628.0403, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2626.3039, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2626.3261, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2626.0761, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2626.3292, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      " day 5 full 2607.620008884488 best 5-18.456108220521855\n",
      "tensor(2297.7041, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(2317.1327, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2316.2551, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2315.8326, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2315.7545, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2315.6651, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2315.6782, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      " day 6 full 2297.704062279004 best 5-17.961066431277686\n",
      "tensor(2595.6083, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(2607.5411, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2607.3641, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2607.4065, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2607.4271, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2607.3450, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2607.2667, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2720.2230, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(2726.0195, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2726.2736, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2727.3466, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2727.6813, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2727.5627, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2727.4288, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      " day 8 full 2720.2230003749 best 1-5.79651889233719\n",
      "tensor(2716.2423, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(2746.4358, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2743.5788, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2743.5225, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2743.4989, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2743.2579, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2743.1530, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2439.7181, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(2465.3531, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2465.7143, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2465.1803, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2465.1571, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2465.1256, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2465.2253, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      " day 10 full 2439.718051492361 best 5-25.407566057368513\n",
      "tensor(2632.4615, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(2656.7989, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2654.6133, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2654.1847, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2654.0023, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2654.1116, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2654.0519, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      " day 11 full 2632.461532144173 best 4-21.540797109914365\n",
      "tensor(2397.5475, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(2415.1000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2414.8049, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2414.2531, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2414.1802, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2414.0144, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2413.9669, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2254.0872, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(2277.3050, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2278.2964, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2277.9706, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2277.8628, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2277.8632, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2277.9051, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      " day 13 full 2254.0872290437924 best 1-23.21780800665192\n",
      "tensor(2273.8395, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(2291.7017, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2290.6677, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2291.7426, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2291.7406, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2291.8359, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2291.7217, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      " day 14 full 2273.839546753164 best 2-16.828122013940174\n",
      "tensor(2444.7211, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(2457.8423, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2455.5376, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2455.2565, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2454.9719, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2454.8507, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2454.6879, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2239.4959, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(2256.8316, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2255.6135, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2255.5940, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2255.7225, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2255.7953, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2255.7773, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      " day 16 full 2239.495854029915 best 3-16.098146601861572\n",
      "tensor(2289.3533, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(2306.6114, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2305.5030, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2305.7232, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2305.8898, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2305.8676, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2305.8515, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      " day 17 full 2289.353331686605 best 2-16.14970080096009\n",
      "tensor(2604.6595, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(2609.6826, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2608.5096, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2608.2245, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2608.4528, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2608.3938, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2608.3466, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      " day 18 full 2604.6594993738818 best 3-3.5649968806819743\n",
      "tensor(2501.7653, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(2519.3117, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2519.5096, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2520.4348, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2520.3124, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2520.7086, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2520.4703, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      " day 19 full 2501.7653357445975 best 1-17.546328131036717\n",
      "tensor(2383.8398, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(2410.2557, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2409.4686, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2409.6487, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2409.6723, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2409.7001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2409.6403, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      " day 20 full 2383.8398046939737 best 2-25.628830834950804\n",
      "tensor(2397.9914, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(2416.0251, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2416.7615, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2416.9200, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2416.9514, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2416.9429, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2416.9958, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      " day 21 full 2397.9913503612715 best 1-18.033776973373733\n",
      "tensor(2415.2363, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(2426.0299, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2424.4697, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2423.9458, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2423.7174, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2423.8332, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2423.9201, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      " day 22 full 2415.2362851612124 best 4-8.481101648688764\n",
      "tensor(2395.3138, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(2416.4154, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2416.9620, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2417.0255, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2416.9522, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2417.0855, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2417.1347, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      " day 23 full 2395.313819575629 best 1-21.101553463564414\n",
      "tensor(2221.0660, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(2240.2560, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2239.4026, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2239.2811, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2239.3526, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2239.2509, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2239.2417, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2259.2643, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(2281.0549, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2278.8848, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2278.8007, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2278.7219, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2278.6225, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2278.6297, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      " day 25 full 2259.264339937321 best 5-19.358143734249097\n",
      "tensor(2036.1660, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(2057.3812, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2055.4435, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2055.2120, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2055.2183, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2055.2493, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2055.2752, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      " day 26 full 2036.16602521864 best 3-19.045997493149343\n",
      "tensor(2146.0333, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(2160.5631, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2160.0290, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2159.6130, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2159.6851, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2159.7519, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2159.7405, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      " day 27 full 2146.0333096528807 best 3-13.57972815117455\n",
      "tensor(2164.2665, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(2189.2787, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2187.8623, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2187.6484, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2187.7190, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2187.6251, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2187.5509, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2349.6745, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(2368.7387, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2367.5945, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2367.8489, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2368.1959, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2367.9423, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2368.1533, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      " day 29 full 2349.674522763318 best 2-17.919993674066063\n",
      "tensor(2261.4948, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(2280.9012, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2278.3062, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2278.1144, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2277.9829, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2277.7629, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2277.9217, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      " day 30 full 2261.494816838197 best 5-16.268066494493723\n",
      "tensor(2391.0470, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(2397.9122, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2396.5535, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2395.9974, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2396.0717, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2396.3047, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2396.4791, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      " day 31 full 2391.047020052954 best 3-4.95039353568427\n",
      "tensor(3038.9627, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(3002.6027, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(3008.2816, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(3008.1634, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(3008.1979, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(3008.2025, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(3008.1352, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      " day 32 full 3038.9627261779337 best 2-30.68107633844238\n"
     ]
    }
   ],
   "source": [
    "lat_lon_resolution = [10,10]\n",
    "\n",
    "head100map = defaultdict(list)\n",
    "headn = 50\n",
    "\n",
    "b = [0]*7\n",
    "b1=b2=b3=b4=b5=b6=0\n",
    "for day in range(1,32):\n",
    "    mm_cond_number = 10\n",
    "\n",
    "    years = ['2024']\n",
    "    month_range =[7,8]\n",
    "    idx_for_datamap= [ 8*(day-1),8*day]\n",
    "\n",
    "    instance = load_data_local_computer()\n",
    "    map, ord_mm, nns_map= instance.load_mm20k_data_bymonthyear( lat_lon_resolution= lat_lon_resolution, mm_cond_number=mm_cond_number,years_=years, months_=month_range)\n",
    "    analysis_data_map, aggregated_data = instance.load_working_data_byday( map, ord_mm, nns_map, idx_for_datamap= idx_for_datamap)\n",
    "\n",
    "    params = [24.42, 1.92, 1.92, 0.001, -0.045, 0.237, 3.34]\n",
    "    params = torch.tensor(params, requires_grad=True)\n",
    "    instance = torch_vecchia_exp(analysis_data_map, params, nns_map, mm_cond_number)\n",
    "    out = instance.full_likelihood(params, aggregated_data[:,:4],aggregated_data[:,2], instance.matern_cov_ani)\n",
    "    print(out)  # 15105\n",
    "\n",
    "\n",
    "    # out1 = instance.vecchia_interpolation_1to6(params, instance.matern_cov_ani, headn)\n",
    "    # print(out1)   # 15181.4775  15183 0,1 lage 15185 0,2\n",
    "    out1 = float('inf')\n",
    "\n",
    "    out2 = instance.vecchia_b1(params, instance.matern_cov_ani, headn)\n",
    "    print(out2) \n",
    "\n",
    "    out3 = instance.vecchia_b2(params, instance.matern_cov_ani, headn)\n",
    "    print(out3) \n",
    "\n",
    "    out4 = instance.vecchia_b3(params, instance.matern_cov_ani, headn)\n",
    "    print(out4) \n",
    "\n",
    "    out5 = instance.vecchia_b4(params, instance.matern_cov_ani, headn)\n",
    "    print(out5) \n",
    "\n",
    "    out6 = instance.vecchia_b5(params, instance.matern_cov_ani, headn)\n",
    "    print(out6) \n",
    "\n",
    "    out7 = instance.vecchia_b6(params, instance.matern_cov_ani, headn)\n",
    "    print(out7) \n",
    "\n",
    "\n",
    "    tmp_result = [ torch.abs(out-out1), torch.abs(out-out2),torch.abs(out-out3),torch.abs(out-out4),torch.abs(out-out5),torch.abs(out-out6) ,torch.abs(out-out7) ]\n",
    "    for i in range(6):\n",
    "        if tmp_result[i] == min(tmp_result):\n",
    "            b[i] +=1   #  mm_cond 10 , head10 then 3 2 11 4 1 4 0 \n",
    "\n",
    "            print(f' day {day+1} full {out} best {i}-{min(tmp_result)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 5, 7, 6, 2, 5, 0]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(10, 10): [3, 2, 11, 4, 1, 4, 0],\n",
       " (10, 20): [9, 4, 8, 3, 1, 2, 0],\n",
       " (10, 30): [10, 3, 4, 5, 1, 3, 0]}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bmap = {}  #( cond number)\n",
    "bmap[(10,10)] = [3,2,11,4,1,4,0]\n",
    "bmap[(10,20)] = [9,4,8,3,1,2,0]\n",
    "bmap[(10,30)] = [10,3,4,5,1,3,0]\n",
    "bmap[(10,40)] = [12,4,4,4,2,3,0]\n",
    "bmap[(10,50)] = [13,3,4,4,2,2,0]  # [0, 5, 7, 6, 2, 5, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare full likleihood vs vecchia interpolation vs vecchia extrapolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14257.319\n",
      "14233.447\n",
      "14332.837\n",
      "day1 finish\n",
      "12877.236\n",
      "12867.427\n",
      "12949.4\n",
      "day2 finish\n",
      "15105.671\n",
      "15112.495\n",
      "15198.854\n",
      "day3 finish\n",
      "15057.407\n",
      "15024.938\n",
      "15142.105\n",
      "day4 finish\n",
      "12729.295\n",
      "12719.305\n",
      "12799.255\n",
      "day5 finish\n",
      "14974.811\n",
      "14911.461\n",
      "15026.632\n",
      "day6 finish\n",
      "15914.439\n",
      "15905.117\n",
      "15964.356\n",
      "day7 finish\n",
      "15345.43\n",
      "15299.767\n",
      "15427.701\n",
      "day8 finish\n",
      "13209.886\n",
      "13204.401\n",
      "13292.492\n",
      "day9 finish\n",
      "15197.731\n",
      "15179.452\n",
      "15288.105\n",
      "day10 finish\n",
      "13394.018\n",
      "13358.698\n",
      "13453.695\n",
      "day11 finish\n",
      "12367.97\n",
      "12354.931\n",
      "12420.804\n",
      "day12 finish\n",
      "12334.455\n",
      "12334.198\n",
      "12398.205\n",
      "day13 finish\n",
      "13388.797\n",
      "13357.456\n",
      "13426.342\n",
      "day14 finish\n",
      "11979.054\n",
      "11971.41\n",
      "12037.568\n",
      "day15 finish\n",
      "12619.898\n",
      "12600.382\n",
      "12677.345\n",
      "day16 finish\n",
      "14524.198\n",
      "14494.066\n",
      "14582.043\n",
      "day17 finish\n",
      "13897.533\n",
      "13883.741\n",
      "13965.368\n",
      "day18 finish\n",
      "13206.887\n",
      "13188.489\n",
      "13267.975\n",
      "day19 finish\n",
      "13289.11\n",
      "13276.595\n",
      "13340.859\n",
      "day20 finish\n",
      "13417.07\n",
      "13425.823\n",
      "13504.782\n",
      "day21 finish\n",
      "13321.848\n",
      "13321.367\n",
      "13379.887\n",
      "day22 finish\n",
      "11662.559\n",
      "11667.87\n",
      "11710.672\n",
      "day23 finish\n",
      "12236.074\n",
      "12234.279\n",
      "12310.165\n",
      "day24 finish\n",
      "11077.486\n",
      "11078.632\n",
      "11148.504\n",
      "day25 finish\n",
      "11703.971\n",
      "11689.076\n",
      "11763.364\n",
      "day26 finish\n",
      "12463.498\n",
      "12437.096\n",
      "12517.367\n",
      "day27 finish\n",
      "12985.387\n",
      "12959.564\n",
      "13042.633\n",
      "day28 finish\n",
      "13388.154\n",
      "13363.384\n",
      "13439.973\n",
      "day29 finish\n",
      "13491.634\n",
      "13471.905\n",
      "13552.401\n",
      "day30 finish\n",
      "15753.032\n",
      "15699.134\n",
      "15787.982\n",
      "day31 finish\n"
     ]
    }
   ],
   "source": [
    "lat_lon_resolution = [4,4]\n",
    "\n",
    "# Create an empty DataFrame\n",
    "head200df = pd.DataFrame(columns=['full', 'vecc_inter', 'vecc_extra', 'full-vecc_inter','full-vecc_extra'])\n",
    "\n",
    "for day in range(1,32):\n",
    "    mm_cond_number = 10\n",
    "\n",
    "    years = ['2024']\n",
    "    month_range =[7,8]\n",
    "    idx_for_datamap= [ 8*(day-1),8*day]\n",
    "\n",
    "    instance = load_data_local_computer()\n",
    "    map, ord_mm, nns_map= instance.load_mm20k_data_bymonthyear( lat_lon_resolution= lat_lon_resolution, mm_cond_number=mm_cond_number,years_=years, months_=month_range)\n",
    "    analysis_data_map, aggregated_data = instance.load_working_data_byday( map, ord_mm, nns_map, idx_for_datamap= idx_for_datamap)\n",
    "\n",
    "\n",
    "    params = [24.42, 1.92, 1.92, 0.001, -0.045, 0.237, 3.34]\n",
    "    params = torch.tensor(params, requires_grad=True)\n",
    "    instance = torch_vecchia_exp(analysis_data_map, params, nns_map, mm_cond_number)\n",
    "    out0 = instance.full_likelihood(params, aggregated_data[:,:4],aggregated_data[:,2], instance.matern_cov_ani).detach().numpy() \n",
    "    print(out0)  # 15105\n",
    "    # out0 = instance.vecchia_local2(params, instance.matern_cov_ani)\n",
    "    # print(out0)   # 15181.4775  15183 0,1 lage 15185 0,2\n",
    "\n",
    "    out1 = instance.vecchia_interpolation_1to6(params, instance.matern_cov_ani, 200).detach().numpy() \n",
    "    print(out1)   # 15181.4775  15183 0,1 lage 15185 0,2\n",
    "  \n",
    "    out2 = instance.vecchia_like_local_computer(params, instance.matern_cov_ani).detach().numpy() \n",
    "    print(out2)\n",
    "    head200df.loc[day-1] = [out0, out1, out2, out0-out1, out0-out2]\n",
    "    print(f'day{day} finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"/Users/joonwonlee/Documents/GEMS_TCO-1/Exercises/st_model/estimates\"\n",
    "\n",
    "# Generate date range\n",
    "date_range = pd.date_range(start='07-01-24', end='07-31-24')\n",
    "\n",
    "# Ensure the number of dates matches the number of rows in df_1250\n",
    "if len(date_range) == len(head200df):\n",
    "    head200df.index = date_range\n",
    "\n",
    "# Save DataFrame to CSV\n",
    "output_filename = 'head200_full_vs_vecc_1250_july24.csv'\n",
    "output_csv_path = os.path.join(input_path, output_filename)\n",
    "head200df.to_csv(output_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Gradients: [  -9.955391  207.88681    -2.595461 -169.72203   273.39944   771.1119\n",
      "  -79.33867 ]\n",
      " Loss: 15135.7587890625, Parameters: [ 2.442e+01  1.920e+00  1.920e+00  1.000e-03 -4.500e-02  2.370e-01\n",
      "  3.340e+00]\n",
      "Epoch 101, Gradients: [ -1.4867018    0.10161591   1.1231489    3.3106918  -11.375813\n",
      "  -7.5312614    7.9387875 ]\n",
      " Loss: 15014.2587890625, Parameters: [ 2.5338207e+01  1.3597493e+00  1.7280715e+00  1.9441580e-02\n",
      " -1.6756412e-01  1.8955134e-01  3.3110123e+00]\n",
      "Converged at epoch 189\n",
      "Epoch 190, Gradients: [-1.2997863  -0.27633095 -0.09813547  0.49712753 -0.5989456  -1.545433\n",
      " -0.09783697]\n",
      " Loss: 15012.7626953125, Parameters: [ 2.5795250e+01  1.3089702e+00  1.6588148e+00  1.8806925e-02\n",
      " -1.6661680e-01  1.9616681e-01  3.1115689e+00]\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "params = [24.42, 1.92, 1.92, 0.001, -0.045, 0.237, 3.34]\n",
    "params = torch.tensor(params, requires_grad=True)\n",
    "\n",
    "instance = torch_vecchia_exp(analysis_data_map, params, nns_map, mm_cond_number)\n",
    "\n",
    "# optimizer = optim.Adam([params], lr=0.01)  # For Adam\n",
    "optimizer = optim.Adam([params],lr=0.01, betas=(0.9, 0.8), eps=1e-8)\n",
    "scheduler = StepLR(optimizer, step_size=20, gamma=0.9)\n",
    "\n",
    "# Example function to compute out1\n",
    "def compute_out1(params):\n",
    "    # Compute the output using your function\n",
    "    # nll = instance.full_likelihood(params, instance.matern_advec_beta_cov )\n",
    "    nll = instance.vecchia_local4(params, instance.matern_cov_ani, 200 )\n",
    "    return nll\n",
    "\n",
    "# Training loop\n",
    "prev_loss = float('inf')\n",
    "tol = 1e-4  # Convergence tolerance\n",
    "for epoch in range(600):  # Number of epochs\n",
    "    optimizer.zero_grad()  # Zero the gradients \n",
    "    \n",
    "    loss = compute_out1(params)\n",
    "    loss.backward()  # Backpropagate the loss\n",
    "    \n",
    "    # Print gradients and parameters every 10th epoch\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch {epoch+1}, Gradients: {params.grad.numpy()}\\n Loss: {loss.item()}, Parameters: {params.detach().numpy()}')\n",
    "    \n",
    "    # print(f'Epoch {epoch+1}, Gradients: {params.grad.numpy()}\\n Loss: {loss.item()}, Parameters: {params.detach().numpy()}')\n",
    "    \n",
    "    optimizer.step()  # Update the parameters\n",
    "    scheduler.step()\n",
    "    # Check for convergence\n",
    "    if abs(prev_loss - loss.item()) < tol:\n",
    "        print(f\"Converged at epoch {epoch}\")\n",
    "        print(f'Epoch {epoch+1}, Gradients: {params.grad.numpy()}\\n Loss: {loss.item()}, Parameters: {params.detach().numpy()}')\n",
    "    \n",
    "        break\n",
    "    \n",
    "    prev_loss = loss.item()\n",
    "\n",
    "print('Training complete.') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Gradients: [-10.6224985 200.28781    -6.4957714 -78.33738   149.36243   605.0917\n",
      " -81.693665 ]\n",
      " Loss: 15183.4765625, Parameters: [ 2.442e+01  1.920e+00  1.920e+00  1.000e-03 -4.500e-02  2.370e-01\n",
      "  3.340e+00]\n",
      "Epoch 101, Gradients: [-1.9947629  4.9151707  6.4719105 -1.286026  -2.0892706  2.9007835\n",
      "  1.0226293]\n",
      " Loss: 15077.75, Parameters: [25.32368     1.3661038   1.7502507   0.04647188 -0.12653434  0.17788467\n",
      "  3.327231  ]\n",
      "Converged at epoch 135\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "params = [24.42, 1.92, 1.92, 0.001, -0.045, 0.237, 3.34]\n",
    "params = torch.tensor(params, requires_grad=True)\n",
    "\n",
    "instance = torch_vecchia_exp(analysis_data_map, params, nns_map, mm_cond_number)\n",
    "\n",
    "# optimizer = optim.Adam([params], lr=0.01)  # For Adam\n",
    "optimizer = optim.Adam([params],lr=0.01, betas=(0.9, 0.8), eps=1e-8)\n",
    "scheduler = StepLR(optimizer, step_size=20, gamma=0.9)\n",
    "\n",
    "# Example function to compute out1\n",
    "def compute_out1(params):\n",
    "    # Compute the output using your function\n",
    "    # nll = instance.full_likelihood(params, instance.matern_advec_beta_cov )\n",
    "    nll = instance.vecchia_local3(params, instance.matern_cov_ani )\n",
    "    return nll\n",
    "\n",
    "# Training loop\n",
    "prev_loss = float('inf')\n",
    "tol = 1e-4  # Convergence tolerance\n",
    "for epoch in range(500):  # Number of epochs\n",
    "    optimizer.zero_grad()  # Zero the gradients \n",
    "    \n",
    "    loss = compute_out1(params)\n",
    "    loss.backward()  # Backpropagate the loss\n",
    "    \n",
    "    # Print gradients and parameters every 10th epoch\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch {epoch+1}, Gradients: {params.grad.numpy()}\\n Loss: {loss.item()}, Parameters: {params.detach().numpy()}')\n",
    "    \n",
    "    # print(f'Epoch {epoch+1}, Gradients: {params.grad.numpy()}\\n Loss: {loss.item()}, Parameters: {params.detach().numpy()}')\n",
    "    \n",
    "    optimizer.step()  # Update the parameters\n",
    "    scheduler.step()\n",
    "    # Check for convergence\n",
    "    if abs(prev_loss - loss.item()) < tol:\n",
    "        print(f\"Converged at epoch {epoch}\")\n",
    "        print(f'Epoch {epoch+1}, Gradients: {params.grad.numpy()}\\n Loss: {loss.item()}, Parameters: {params.detach().numpy()}')\n",
    "        break\n",
    "    \n",
    "    prev_loss = loss.item()\n",
    "\n",
    "print('Training complete.') \n",
    "\n",
    " \n",
    "# vecchia local 2  332   epo 33.4s   25.55 2.61 2.68 0.16 0.03 2.7\n",
    "#    24.89 2.06 2.24 1.36e-2 -5.63 e-2 0.10113 3.75\n",
    "# vecchia cholesky local 380 epo 43.2  25 2.61 2.68 0.16 0.03 2.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 200 x 8\n",
    "\n",
    "lr 0.001 without scheduler  same as lr, step_size, gamma  0.01 40 0.5  (9.8s)\n",
    "\n",
    " Loss: 2549.066650390625, full Parameters: [ 2.48777485e+01  2.05998826e+00  2.16013098e+00  2.20775465e-03\n",
    " -7.89414570e-02  1.05411254e-01  3.75236106e+00]\n",
    "\n",
    " lr 0.01  step size 40  betas 0.9 , 0.8 gamma 0.9  30 s\n",
    "\n",
    "  Loss: 2547.1728515625, full Parameters: [ 2.7377291e+01  2.2077193e+00  2.3204505e+00  1.0307773e-03\n",
    " -8.0311157e-02  9.8579854e-02  3.6677265e+00]\n",
    "\n",
    " lr 0.01  step size 10 betas 0.9 , 0.8 gamma 0.9  30 s\n",
    "  Loss: 2548.87841796875, full Parameters: [ 2.5092268e+01  2.0689390e+00  2.1694989e+00  2.0285936e-03\n",
    " -7.9028614e-02  1.0501490e-01  3.7373385e+00]\n",
    "Training full likelihood complete.   11.8 sc\n",
    "\n",
    " lr 0.01  step size 20 betas 0.9 , 0.8 gamma 0.9  30 s\n",
    " Loss: 2548.15283203125, full Parameters: [ 2.59814014e+01  2.12175608e+00  2.22699022e+00  1.73025124e-03\n",
    " -7.93599486e-02  1.02427535e-01  3.70715070e+00]\n",
    "\n",
    "\n",
    "\n",
    "lr 0.01  step size 20 beta 0.9 0.99 gamma 0.9\n",
    " Loss: 2548.18603515625, full Parameters: [ 2.5938652e+01  2.1110108e+00  2.2155209e+00  1.5893303e-03\n",
    " -7.9482891e-02  1.0297947e-01  3.6958976e+00]\n",
    " 21.6\n",
    "\n",
    "lr 0.01  step size 20 beta 0.9 0.8 gamma 0.9\n",
    " Loss: 2548.15283203125, full Parameters: [ 2.59814014e+01  2.12175608e+00  2.22699022e+00  1.73025124e-03\n",
    " -7.93599486e-02  1.02427535e-01  3.70715070e+00]\n",
    " 22.9 s\n",
    "\n",
    "lr 0.01  step size 10 beta 0.9 0.99 gamma 0.9\n",
    "Loss: 2548.95361328125, full Parameters: [ 2.5118145e+01  1.9827319e+00  2.0768294e+00  1.0898338e-03\n",
    " -8.0070712e-02  1.1034889e-01  3.5647078e+00]\n",
    "\n",
    "\n",
    "## 1250 x 8\n",
    "\n",
    "1250* 8 55m using constant learning rate 0.0001 \n",
    "Loss: 14068.798828125, full Parameters: [ 2.46198387e+01  1.61719894e+00  1.76454413e+00  8.55297223e-03\n",
    " -1.08275235e-01  1.28809512e-01  2.80795789e+00]\n",
    "\n",
    "1250* 8 10m 32s\n",
    "lr 0.01  step size 40 beta 0.9 0.8 gamma 0.9\n",
    "  Loss: 14068.1953125, full Parameters: [ 2.5030930e+01  1.6107724e+00  1.7573007e+00  8.8407323e-03\n",
    " -1.0820019e-01  1.2936097e-01  2.7430327e+00]\n",
    "Training full likelihood complete.\n",
    "\n",
    "9m 33s\n",
    "lr 0.01  step size 20 beta 0.9 0.8 gamma 0.9\n",
    " Loss: 14068.29296875, full Parameters: \n",
    " [ 2.4933689e+01  1.6009743e+00  1.7502663e+00  9.2404895e-03 -1.0737537e-01  1.2953614e-01 \n",
    "  2.7420275e+00]\n",
    "Training full likelihood complete.\n",
    "\n",
    "#### high resolution data might benefits from larger step size high resolution data often provides \n",
    "#### more stable gradients, so larger step size less likely to cause significant fluctuations\n",
    "14n 41.8s\n",
    "lr 0.01  step size 10 beta 0.9 0.99 gamma 0.9\n",
    "\n",
    "FINAL STATE: Epoch 199, \n",
    " Loss: 14068.8828125, full Parameters: \n",
    " [ 2.4707581e+01  1.6489888e+00  1.7993137e+00  8.4043797e-03 -1.0836436e-01  1.2655504e-01  \n",
    " 2.8416286e+00]\n",
    "\n",
    "#### beta 0.9 0.99 might be too conservative for high resolution data\n",
    "13m 44.8s\n",
    "lr 0.01  step size 20 beta 0.9 0.99 gamma 0.9\n",
    "\n",
    " Loss: 14068.318359375, full Parameters: [ 2.4938175e+01  1.6203119e+00  1.7678342e+00  8.6686825e-03\n",
    " -1.0813228e-01  1.2845081e-01  2.7731323e+00]\n",
    "\n",
    "\n",
    "18m\n",
    "lr 0.01  step size 40 beta 0.9 0.99 gamma 0.9\n",
    "\n",
    " Loss: 14067.970703125, full Parameters: [ 2.5205673e+01  1.6159834e+00  1.7630767e+00  8.7957922e-03\n",
    " -1.0802399e-01  1.2862283e-01  2.7390635e+00]\n",
    "\n",
    "9m 52s\n",
    "lr 0.01  step size 20 beta 0.9 0.8 gamma 0.9\n",
    "\n",
    "Loss: 14068.29296875, full Parameters: [ 2.4933689e+01  1.6009743e+00  1.7502663e+00  9.2404895e-03\n",
    " -1.0737537e-01  1.2953614e-01  2.7420275e+00]\n",
    "Training full likelihood complete."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "faiss_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
