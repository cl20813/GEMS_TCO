{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "gems_tco_path = \"/Users/joonwonlee/Documents/GEMS_TCO-1/src\"\n",
    "sys.path.append(gems_tco_path)\n",
    "\n",
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle \n",
    "\n",
    "import GEMS_TCO\n",
    "from GEMS_TCO import kernels \n",
    "from GEMS_TCO import orderings as _orderings\n",
    "from GEMS_TCO import load_data\n",
    "from GEMS_TCO import configuration as config\n",
    "\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import copy                    # clone tensor\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "from json import JSONEncoder\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare vecchia estimates on full likleihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     691.186064\n",
      "1    1255.413615\n",
      "2    6902.720330\n",
      "3     372.894852\n",
      "4     476.700776\n",
      "Name: time, dtype: float64\n",
      "0      590.373994\n",
      "1      566.339952\n",
      "2    11145.832204\n",
      "3      514.743971\n",
      "4     2649.230663\n",
      "Name: time, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "vecc_est1 = pd.read_csv( \"/Users/joonwonlee/Documents/GEMS_TCO-1/Exercises/st_model/estimates/vecchia_v05_reord_1250.0.csv\"  )\n",
    "vecc_est2 = pd.read_csv( \"/Users/joonwonlee/Documents/GEMS_TCO-1/Exercises/st_model/estimates/vecchia_v05_ori_ord_1250.0.csv\" )\n",
    "print(vecc_est1['time'].head(5) )\n",
    "\n",
    "\n",
    "vecc_est1 = pd.read_csv( \"/Users/joonwonlee/Documents/GEMS_TCO-1/Exercises/st_model/estimates/vecchia_v05_reord_5000.0.csv\"  )\n",
    "vecc_est2 = pd.read_csv( \"/Users/joonwonlee/Documents/GEMS_TCO-1/Exercises/st_model/estimates/vecchia_v05_ori_ord5000.0.csv\" )\n",
    "print(vecc_est1['time'].head(5) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Day 13 data size per day: 88.8888888888889 \n",
      "\n",
      "full: 1176.2858798410507 using reorder took 0.02\n",
      "full using ori order: 1176.2858798410425 took 0.02\n"
     ]
    }
   ],
   "source": [
    "lat_lon_resolution = [4,4]\n",
    "years = ['2024']\n",
    "month_range =[7,8]\n",
    "nheads = 2\n",
    "mm_cond_number = 10 \n",
    "\n",
    "data_load_instance = load_data(config.mac_data_load_path)\n",
    "df = data_load_instance.read_pickle(config.mac_estimates_day_path,config.mac_full_day_v05_pickle)\n",
    "map, ord_mm, nns_map= data_load_instance.load_mm20k_data_bymonthyear( lat_lon_resolution= lat_lon_resolution, mm_cond_number=mm_cond_number,years_=years, months_=month_range)\n",
    "\n",
    "result_2 = [0]*31\n",
    "result_1 = [0]*31\n",
    "result_3 = [0]*31\n",
    "for day in range(13,14):\n",
    "    print(f'\\n Day {day} data size per day: { (200/lat_lon_resolution[0])*(100/lat_lon_resolution[0])  } \\n')\n",
    "\n",
    "    idx_for_datamap= [ 8*(day-1),8*day]\n",
    "    # params = [ 27.25, 2.18, 2.294, 4.099e-4, -0.07915, 0.0999, 3.65]   #200\n",
    "    params1 = list(vecc_est1.iloc[0, 5:12])\n",
    "    params1 = torch.tensor(params1, dtype=torch.float64, requires_grad=True)\n",
    "\n",
    "    params2 = list(vecc_est2.iloc[0, 5:12])\n",
    "    params2 = torch.tensor(params2, dtype=torch.float64, requires_grad=True)\n",
    "\n",
    "    # data\n",
    "    analysis_data_map, aggregated_data = data_load_instance.load_working_data_byday( map, ord_mm, nns_map, idx_for_datamap= idx_for_datamap)\n",
    "\n",
    "\n",
    "    start_time = time.time()\n",
    "    instance = kernels.vecchia_experiment(0.5, analysis_data_map, aggregated_data,nns_map,mm_cond_number, nheads)\n",
    "    out1 = instance.full_likelihood(params1, aggregated_data[:,:4],aggregated_data[:,2], instance.matern_cov_anisotropy_v05)\n",
    "    end_time = time.time()\n",
    "    epoch_time = end_time - start_time\n",
    "    print(f'full: {out1} using reorder took {epoch_time:.2f}')  \n",
    "\n",
    "    start_time = time.time()\n",
    "    instance = kernels.vecchia_experiment(0.5, analysis_data_map, aggregated_data,nns_map,mm_cond_number, nheads)\n",
    "    out2 = instance.full_likelihood(params2, aggregated_data[:,:4],aggregated_data[:,2], instance.matern_cov_anisotropy_v05)\n",
    "    end_time = time.time()\n",
    "    epoch_time = end_time - start_time\n",
    "    print(f'full using ori order: {out2} took {epoch_time:.2f}')  \n",
    "    if out1 < out2:\n",
    "        result_1[day-1] = 1\n",
    "    elif out1 > out2:\n",
    "        result_2[day-1] = 1\n",
    "    \n",
    "    result_3[day-1] = out1 - out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  7.5250, 115.0250, 278.6868, 309.0000],\n",
       "        [  5.0250, 110.0250, 270.9129, 309.0000],\n",
       "        [  5.0250, 119.9750, 270.4871, 309.0000],\n",
       "        [  9.9750, 110.6750, 280.0706, 309.0000],\n",
       "        [  9.9750, 119.3750, 277.4235, 309.0000],\n",
       "        [  5.0250, 113.1750, 265.9426, 309.0000],\n",
       "        [  5.0250, 116.8750, 271.7598, 309.0000],\n",
       "        [  9.9750, 116.5250, 273.8728, 309.0000],\n",
       "        [  9.9750, 113.5250, 276.9880, 309.0000],\n",
       "        [  7.3750, 118.3750, 274.1869, 309.0000],\n",
       "        [  7.3750, 111.6750, 277.4110, 309.0000],\n",
       "        [  5.5750, 115.0250, 273.2255, 309.0000],\n",
       "        [  8.2250, 110.0250, 279.6494, 309.0000],\n",
       "        [  8.2250, 119.9750, 270.5052, 309.0000],\n",
       "        [  8.1750, 116.7250, 275.9615, 309.0000],\n",
       "        [  8.1750, 113.3250, 279.1612, 309.0000],\n",
       "        [  5.6750, 118.4250, 270.6163, 309.0000],\n",
       "        [  5.6750, 111.6250, 269.4268, 309.0000],\n",
       "        [  9.2250, 115.0250, 276.7859, 309.0000],\n",
       "        [  6.5750, 116.3750, 277.7238, 309.0000],\n",
       "        [  6.5750, 113.6750, 270.9863, 309.0000],\n",
       "        [  6.6250, 110.2250, 272.6259, 309.0000],\n",
       "        [  6.6250, 119.8250, 278.1770, 309.0000],\n",
       "        [  8.9750, 118.1250, 275.9126, 309.0000],\n",
       "        [  8.9750, 111.9250, 277.3821, 309.0000],\n",
       "        [  6.5250, 117.5750, 275.8299, 309.0000],\n",
       "        [  6.5250, 112.4750, 272.1614, 309.0000],\n",
       "        [  9.9750, 117.6250, 277.7013, 309.0000],\n",
       "        [  9.9750, 112.4250, 277.3933, 309.0000],\n",
       "        [  8.3750, 115.6750, 277.1316, 309.0000],\n",
       "        [  8.3750, 114.3750, 277.2260, 309.0000],\n",
       "        [  8.9250, 110.8250, 276.9015, 309.0000],\n",
       "        [  8.2750, 118.9250, 268.2468, 309.0000],\n",
       "        [  9.1250, 117.0750, 276.5293, 309.0000],\n",
       "        [  9.1250, 112.9750, 278.8114, 309.0000],\n",
       "        [  6.5250, 114.6750, 271.9416, 309.0000],\n",
       "        [  5.6250, 116.0250, 272.8536, 309.0000],\n",
       "        [  5.6250, 114.0250, 270.7848, 309.0000],\n",
       "        [  7.4750, 114.0250, 275.1398, 309.0000],\n",
       "        [  7.4750, 116.0250, 273.5402, 309.0000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_data_map['2024_07_y24m07day13_hm01:00'][0:40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "empirical variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimization vecchia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Gradients: [   1.604289    -3.3953786   13.173016   -16.285385    23.079647\n",
      " -266.99118      8.324189 ]\n",
      " Loss: 638.6804942628457, Parameters: [ 2.442e+01  1.920e+00  1.920e+00  1.000e-03 -4.500e-02  2.370e-01\n",
      "  3.340e+00]\n",
      "Epoch 11, Gradients: [   1.7063622   -6.3740706   15.490283   -26.686237    25.25128\n",
      " -170.4671       7.6667776]\n",
      " Loss: 657.3515694001899, Parameters: [24.31977     2.0212595   1.8195608   0.10210952 -0.1454065   0.33540848\n",
      "  3.2402055 ]\n",
      "Early stopping at epoch 10\n",
      "FINAL STATE: Epoch 11, Loss: 657.3515694001899, \n",
      " vecc Parameters: [24.310724    2.0305831   1.8104354   0.11135044 -0.15445194  0.3439487\n",
      "  3.23128   ]\n"
     ]
    }
   ],
   "source": [
    "params = [24.42, 1.92, 1.92, 0.001, -0.045, 0.237, 3.34]\n",
    "params = torch.tensor(params, requires_grad=True)\n",
    "nheads= 200\n",
    "instance = kernels.model_fitting(\n",
    "    smooth=0.5,\n",
    "    input_map=analysis_data_map,\n",
    "    aggregated_data=aggregated_data,\n",
    "    nns_map=nns_map,\n",
    "    mm_cond_number=mm_cond_number,\n",
    "    nheads= nheads\n",
    ")\n",
    "\n",
    "early_stopping = kernels.EarlyStopping(patience= 10, delta=0.001)\n",
    "instance_map = kernels.vecchia_experiment(0.5, analysis_data_map, aggregated_data, nns_map,mm_cond_number, nheads)\n",
    "# optimizer = optim.Adam([params], lr=0.01)  # For Adam\n",
    "optimizer, scheduler = instance.optimizer_fun( params, lr=0.01, betas=(0.9, 0.99), eps=1e-8, step_size=10, gamma=0.9) \n",
    "\n",
    "cov_map =  instance_map.cov_structure_saver(params, instance_map.matern_cov_anisotropy_spline)\n",
    "out, epoch = instance.run_vecc_ori_order_grad_tracker(params, optimizer,scheduler, instance.matern_cov_anisotropy_kv, cov_map, 400, early_stopping)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Day 12 data size per day: 50.0 \n",
      "\n",
      "full: 604.0888756252047 took 0.01\n"
     ]
    }
   ],
   "source": [
    "lat_lon_resolution = [20,20]\n",
    "years = ['2024']\n",
    "month_range =[7,8]\n",
    "nheads = 200\n",
    "mm_cond_number = 10 \n",
    "\n",
    "data_load_instance = load_data(config.mac_data_load_path)\n",
    "df = data_load_instance.read_pickle(config.mac_estimates_day_path,config.mac_full_day_v05_pickle)\n",
    "map, ord_mm, nns_map= data_load_instance.load_mm20k_data_bymonthyear( lat_lon_resolution= lat_lon_resolution, mm_cond_number=mm_cond_number,years_=years, months_=month_range)\n",
    "\n",
    "df.head()\n",
    "\n",
    "for day in range(12,13):\n",
    "    print(f'\\n Day {day} data size per day: { (200/lat_lon_resolution[0])*(100/lat_lon_resolution[0])  } \\n')\n",
    "\n",
    "    idx_for_datamap= [ 8*(day),8*(day+1)]\n",
    "\n",
    "    params = list(df.iloc[day-1][:-1])\n",
    "    params = torch.tensor(params, dtype=torch.float64, requires_grad=True)\n",
    "\n",
    "    input_path = Path(config.mac_data_load_path)\n",
    "   \n",
    "    \n",
    "    analysis_data_map, aggregated_data = data_load_instance.load_working_data_byday( map, ord_mm, nns_map, idx_for_datamap= idx_for_datamap)\n",
    "\n",
    "    start_time = time.time()\n",
    "    instance_ori = kernels.vecchia_experiment(0.5, analysis_data_map, aggregated_data,nns_map,mm_cond_number, nheads)\n",
    "    out = instance_ori.full_likelihood(params, aggregated_data[:,:4],aggregated_data[:,2], instance_ori.matern_cov_anisotropy_v05)\n",
    "    end_time = time.time()\n",
    "    epoch_time = end_time - start_time\n",
    "    print(f'full: {out} took {epoch_time:.2f}')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Day 12 data size per day: 50.0 \n",
      "\n",
      "full: 604.0888756252047 took 0.00\n",
      "vecc kv: 1116.830937070988 took 0.03\n",
      "vecc two lags: 1116.830937070988 took 0.03\n",
      "\n",
      "\n",
      " Day 12 full likelihood: 604.0888756252047\n",
      " parameters: [23.036033630371094, 2.299997568130493, 3.3469552993774414, -0.054280802607536316, 0.11497637629508972, 0.11015477031469345, 1.6048980951309204] \n",
      "\n",
      "Best approximation: two lag with abs_diff: 512.7420614457834\n",
      "Second best approximation: vecc t-1, t+1 with abs_diff: 572.197004215846\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "result_2 = [0]*3\n",
    "result_1 = [0]*3\n",
    "\n",
    "lat_lon_resolution = [20,20]\n",
    "years = ['2024']\n",
    "month_range =[7,8]\n",
    "nheads = 10\n",
    "mm_cond_number = 10 \n",
    "\n",
    "data_load_instance = load_data(config.mac_data_load_path)\n",
    "df = data_load_instance.read_pickle(config.mac_estimates_day_path,config.mac_full_day_v05_pickle)\n",
    "map, ord_mm, nns_map= data_load_instance.load_mm20k_data_bymonthyear( lat_lon_resolution= lat_lon_resolution, mm_cond_number=mm_cond_number,years_=years, months_=month_range)\n",
    "\n",
    "df.head()\n",
    "\n",
    "for day in range(12,13):\n",
    "    print(f'\\n Day {day} data size per day: { (200/lat_lon_resolution[0])*(100/lat_lon_resolution[0])  } \\n')\n",
    "\n",
    "    idx_for_datamap= [ 8*(day),8*(day+1)]\n",
    "\n",
    "    params = list(df.iloc[day-1][:-1])\n",
    "    params = torch.tensor(params, dtype=torch.float64, requires_grad=True)\n",
    "\n",
    "    input_path = Path(config.mac_data_load_path)\n",
    "   \n",
    "    \n",
    "    analysis_data_map, aggregated_data = data_load_instance.load_working_data_byday( map, ord_mm, nns_map, idx_for_datamap= idx_for_datamap)\n",
    "\n",
    "    # different approximations\n",
    "    key_order = [0,1,2,4,3,5,7,6]\n",
    "    keys = list(analysis_data_map.keys())\n",
    "    reordered_dict = {keys[key]: analysis_data_map[keys[key]] for key in key_order}\n",
    "\n",
    "\n",
    "    start_time = time.time()\n",
    "    instance_ori = kernels.vecchia_experiment(0.5, analysis_data_map, aggregated_data,nns_map,mm_cond_number, nheads)\n",
    "    out = instance_ori.full_likelihood(params, aggregated_data[:,:4],aggregated_data[:,2], instance_ori.matern_cov_anisotropy_v05)\n",
    "    end_time = time.time()\n",
    "    epoch_time = end_time - start_time\n",
    "    print(f'full: {out} took {epoch_time:.2f}')  \n",
    "\n",
    "    cov_map_ori = instance.cov_structure_saver(params, instance_ori.matern_cov_anisotropy_v05)\n",
    "    cov_map = instance.cov_structure_saver(params, instance.matern_cov_anisotropy_v05)\n",
    "\n",
    "    start_time = time.time()\n",
    "    out2 = instance.vecchia_ori_order(params,  instance.matern_cov_anisotropy_v05, cov_map)\n",
    "    end_time = time.time()\n",
    "    epoch_time2 = end_time - start_time\n",
    "    print(f'vecc kv: {out2} took {epoch_time2:.2f}') \n",
    "  \n",
    "    #out22 = instance_ori.vecchia_b2(params,  instance_ori.matern_cov_anisotropy_v05)\n",
    "    #print(f'vecc two lags: {out22}')  \n",
    "\n",
    "    instance = kernels.vecchia_experiment(0.5, reordered_dict, aggregated_data,nns_map,mm_cond_number, nheads)\n",
    "\n",
    "\n",
    "    cov_map_ori = instance.cov_structure_saver(params, instance_ori.matern_cov_anisotropy_v05)\n",
    "    cov_map_new = instance.cov_structure_saver(params, instance.matern_cov_anisotropy_v05)\n",
    "\n",
    "    start_time = time.time()\n",
    "    out3 = instance.vecchia_ori_order(params,  instance.matern_cov_anisotropy_v05, cov_map)\n",
    "    end_time = time.time()\n",
    "    epoch_time2 = end_time - start_time\n",
    "    print(f'vecc two lags: {out3} took {epoch_time2:.2f}') \n",
    "  \n",
    "\n",
    "\n",
    "    approx_map = {0: 'vecc t-1, t+1', 1: 'two lag', 2:'competitor'}\n",
    "\n",
    "    tmp_result = [ torch.abs(out-out1), torch.abs(out-out2) , torch.abs(out)]\n",
    "    stacked_tensor = torch.stack(tmp_result)\n",
    "    top2_indices = torch.topk(stacked_tensor, 2, largest=False).indices\n",
    "\n",
    "    best_index = top2_indices[0].item()\n",
    "    second_best_index = top2_indices[1].item()\n",
    "\n",
    "    # Update the result for the best approximation\n",
    "    result_1[best_index] += 1\n",
    "    result_2[second_best_index] +=1\n",
    "    # Print the results\n",
    "    print(f'\\n\\n Day {day} full likelihood: {out}\\n parameters: {params.tolist()} \\n')\n",
    "    print(f'Best approximation: {approx_map[best_index]} with abs_diff: {stacked_tensor[best_index]}')\n",
    "    print(f'Second best approximation: {approx_map[second_best_index]} with abs_diff: {stacked_tensor[second_best_index]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 200 x 8\n",
    "\n",
    "lr 0.001 without scheduler  same as lr, step_size, gamma  0.01 40 0.5  (9.8s)\n",
    "\n",
    " Loss: 2549.066650390625, full Parameters: [ 2.48777485e+01  2.05998826e+00  2.16013098e+00  2.20775465e-03\n",
    " -7.89414570e-02  1.05411254e-01  3.75236106e+00]\n",
    "\n",
    " lr 0.01  step size 40  betas 0.9 , 0.8 gamma 0.9  30 s\n",
    "\n",
    "  Loss: 2547.1728515625, full Parameters: [ 2.7377291e+01  2.2077193e+00  2.3204505e+00  1.0307773e-03\n",
    " -8.0311157e-02  9.8579854e-02  3.6677265e+00]\n",
    "\n",
    " lr 0.01  step size 10 betas 0.9 , 0.8 gamma 0.9  30 s\n",
    "  Loss: 2548.87841796875, full Parameters: [ 2.5092268e+01  2.0689390e+00  2.1694989e+00  2.0285936e-03\n",
    " -7.9028614e-02  1.0501490e-01  3.7373385e+00]\n",
    "Training full likelihood complete.   11.8 sc\n",
    "\n",
    " lr 0.01  step size 20 betas 0.9 , 0.8 gamma 0.9  30 s\n",
    " Loss: 2548.15283203125, full Parameters: [ 2.59814014e+01  2.12175608e+00  2.22699022e+00  1.73025124e-03\n",
    " -7.93599486e-02  1.02427535e-01  3.70715070e+00]\n",
    "\n",
    "\n",
    "\n",
    "lr 0.01  step size 20 beta 0.9 0.99 gamma 0.9\n",
    " Loss: 2548.18603515625, full Parameters: [ 2.5938652e+01  2.1110108e+00  2.2155209e+00  1.5893303e-03\n",
    " -7.9482891e-02  1.0297947e-01  3.6958976e+00]\n",
    " 21.6\n",
    "\n",
    "lr 0.01  step size 20 beta 0.9 0.8 gamma 0.9\n",
    " Loss: 2548.15283203125, full Parameters: [ 2.59814014e+01  2.12175608e+00  2.22699022e+00  1.73025124e-03\n",
    " -7.93599486e-02  1.02427535e-01  3.70715070e+00]\n",
    " 22.9 s\n",
    "\n",
    "lr 0.01  step size 10 beta 0.9 0.99 gamma 0.9\n",
    "Loss: 2548.95361328125, full Parameters: [ 2.5118145e+01  1.9827319e+00  2.0768294e+00  1.0898338e-03\n",
    " -8.0070712e-02  1.1034889e-01  3.5647078e+00]\n",
    "\n",
    "\n",
    "## 1250 x 8\n",
    "\n",
    "1250* 8 55m using constant learning rate 0.0001 \n",
    "Loss: 14068.798828125, full Parameters: [ 2.46198387e+01  1.61719894e+00  1.76454413e+00  8.55297223e-03\n",
    " -1.08275235e-01  1.28809512e-01  2.80795789e+00]\n",
    "\n",
    "1250* 8 10m 32s\n",
    "lr 0.01  step size 40 beta 0.9 0.8 gamma 0.9\n",
    "  Loss: 14068.1953125, full Parameters: [ 2.5030930e+01  1.6107724e+00  1.7573007e+00  8.8407323e-03\n",
    " -1.0820019e-01  1.2936097e-01  2.7430327e+00]\n",
    "Training full likelihood complete.\n",
    "\n",
    "9m 33s\n",
    "lr 0.01  step size 20 beta 0.9 0.8 gamma 0.9\n",
    " Loss: 14068.29296875, full Parameters: \n",
    " [ 2.4933689e+01  1.6009743e+00  1.7502663e+00  9.2404895e-03 -1.0737537e-01  1.2953614e-01 \n",
    "  2.7420275e+00]\n",
    "Training full likelihood complete.\n",
    "\n",
    "#### high resolution data might benefits from larger step size high resolution data often provides \n",
    "#### more stable gradients, so larger step size less likely to cause significant fluctuations\n",
    "14n 41.8s\n",
    "lr 0.01  step size 10 beta 0.9 0.99 gamma 0.9\n",
    "\n",
    "FINAL STATE: Epoch 199, \n",
    " Loss: 14068.8828125, full Parameters: \n",
    " [ 2.4707581e+01  1.6489888e+00  1.7993137e+00  8.4043797e-03 -1.0836436e-01  1.2655504e-01  \n",
    " 2.8416286e+00]\n",
    "\n",
    "#### beta 0.9 0.99 might be too conservative for high resolution data\n",
    "13m 44.8s\n",
    "lr 0.01  step size 20 beta 0.9 0.99 gamma 0.9\n",
    "\n",
    " Loss: 14068.318359375, full Parameters: [ 2.4938175e+01  1.6203119e+00  1.7678342e+00  8.6686825e-03\n",
    " -1.0813228e-01  1.2845081e-01  2.7731323e+00]\n",
    "\n",
    "\n",
    "18m\n",
    "lr 0.01  step size 40 beta 0.9 0.99 gamma 0.9\n",
    "\n",
    " Loss: 14067.970703125, full Parameters: [ 2.5205673e+01  1.6159834e+00  1.7630767e+00  8.7957922e-03\n",
    " -1.0802399e-01  1.2862283e-01  2.7390635e+00]\n",
    "\n",
    "9m 52s\n",
    "lr 0.01  step size 20 beta 0.9 0.8 gamma 0.9\n",
    "\n",
    "Loss: 14068.29296875, full Parameters: [ 2.4933689e+01  1.6009743e+00  1.7502663e+00  9.2404895e-03\n",
    " -1.0737537e-01  1.2953614e-01  2.7420275e+00]\n",
    "Training full likelihood complete."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "faiss_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
