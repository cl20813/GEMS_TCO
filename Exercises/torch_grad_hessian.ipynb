{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "# gems_tco_path = \"/Users/joonwonlee/Documents/GEMS_TCO-1/src\"\n",
    "# sys.path.append(gems_tco_path)\n",
    "\n",
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle \n",
    "\n",
    "import GEMS_TCO\n",
    "from GEMS_TCO import kernels \n",
    "from GEMS_TCO import orderings as _orderings\n",
    "from GEMS_TCO import load_data_local_computer\n",
    "\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "from torch.func import grad, hessian, jacfwd, jacrev\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import copy                    # clone tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "Two options: 1. torch.autograd 2. torch.func (recommended for both gradients and hessians)\n",
    "\n",
    "Observations:\n",
    "- In order to track gradients, ```sqrt()``` in distance function has to be removed and put ```sqrt(distance function output)``` in covariance function.   \n",
    "\n",
    "- If dtypes don't match, both autograd and torch.func cannot track hessians, so consider ```.to(torch.float64)``` so ``` aggregated_data[:,:4].torch.float64()```   \n",
    "for the consistency.\n",
    "Actually, it turns out that if I use ```float32```, then autograd derivative can be different from analytical derivative by ```0.001 ~ 0.004```. \n",
    "\n",
    "the difference is on the order of one-thousandth \n",
    "\n",
    "- For hessians, torch.func is recommended. ``` torch.autograd.functional.hessian(compute_loss, params)``` this doesn't work.   \n",
    "\n",
    "- It seems there is nontrivial difference between float32 and float64 settings. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD estimates for July 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sigmasq</th>\n",
       "      <th>range_lat</th>\n",
       "      <th>range_lon</th>\n",
       "      <th>advec_lat</th>\n",
       "      <th>advec_lon</th>\n",
       "      <th>beta</th>\n",
       "      <th>nugget</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.793444</td>\n",
       "      <td>1.584529</td>\n",
       "      <td>1.718248</td>\n",
       "      <td>0.009089</td>\n",
       "      <td>-0.107299</td>\n",
       "      <td>0.131038</td>\n",
       "      <td>2.717239</td>\n",
       "      <td>14068.529297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.424301</td>\n",
       "      <td>1.997055</td>\n",
       "      <td>1.942683</td>\n",
       "      <td>0.043588</td>\n",
       "      <td>-0.072679</td>\n",
       "      <td>0.137124</td>\n",
       "      <td>1.513148</td>\n",
       "      <td>12357.715820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.009497</td>\n",
       "      <td>1.215236</td>\n",
       "      <td>1.558868</td>\n",
       "      <td>0.023392</td>\n",
       "      <td>-0.150548</td>\n",
       "      <td>0.199850</td>\n",
       "      <td>2.890678</td>\n",
       "      <td>14948.140625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24.701347</td>\n",
       "      <td>1.612308</td>\n",
       "      <td>1.822960</td>\n",
       "      <td>-0.164069</td>\n",
       "      <td>-0.237443</td>\n",
       "      <td>0.131595</td>\n",
       "      <td>3.636499</td>\n",
       "      <td>14786.204102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22.598671</td>\n",
       "      <td>2.901185</td>\n",
       "      <td>3.722327</td>\n",
       "      <td>-0.011729</td>\n",
       "      <td>-0.152072</td>\n",
       "      <td>0.072866</td>\n",
       "      <td>2.397249</td>\n",
       "      <td>12096.261719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25.594908</td>\n",
       "      <td>1.702692</td>\n",
       "      <td>2.255174</td>\n",
       "      <td>0.017462</td>\n",
       "      <td>-0.158125</td>\n",
       "      <td>0.098684</td>\n",
       "      <td>3.850205</td>\n",
       "      <td>14690.248047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>26.030510</td>\n",
       "      <td>1.261084</td>\n",
       "      <td>2.831952</td>\n",
       "      <td>0.054831</td>\n",
       "      <td>-0.343255</td>\n",
       "      <td>0.103045</td>\n",
       "      <td>4.596346</td>\n",
       "      <td>15342.459961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>26.043682</td>\n",
       "      <td>0.995279</td>\n",
       "      <td>1.629503</td>\n",
       "      <td>-0.019824</td>\n",
       "      <td>-0.411626</td>\n",
       "      <td>0.164296</td>\n",
       "      <td>2.751402</td>\n",
       "      <td>14857.195312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>24.052070</td>\n",
       "      <td>1.377774</td>\n",
       "      <td>2.357721</td>\n",
       "      <td>0.021439</td>\n",
       "      <td>-0.220316</td>\n",
       "      <td>0.142847</td>\n",
       "      <td>1.675457</td>\n",
       "      <td>12666.991211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>25.766110</td>\n",
       "      <td>1.392051</td>\n",
       "      <td>2.358172</td>\n",
       "      <td>0.026684</td>\n",
       "      <td>-0.077366</td>\n",
       "      <td>0.150648</td>\n",
       "      <td>3.821219</td>\n",
       "      <td>14987.769531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>23.945438</td>\n",
       "      <td>1.490333</td>\n",
       "      <td>2.470762</td>\n",
       "      <td>-0.009915</td>\n",
       "      <td>0.027429</td>\n",
       "      <td>0.137959</td>\n",
       "      <td>2.066264</td>\n",
       "      <td>13000.419922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>23.036034</td>\n",
       "      <td>2.299998</td>\n",
       "      <td>3.346955</td>\n",
       "      <td>-0.054281</td>\n",
       "      <td>0.114976</td>\n",
       "      <td>0.110155</td>\n",
       "      <td>1.604898</td>\n",
       "      <td>11485.496094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>22.790960</td>\n",
       "      <td>2.072518</td>\n",
       "      <td>3.616723</td>\n",
       "      <td>-0.130206</td>\n",
       "      <td>0.076944</td>\n",
       "      <td>0.135628</td>\n",
       "      <td>1.441895</td>\n",
       "      <td>11315.873047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>24.079025</td>\n",
       "      <td>2.077914</td>\n",
       "      <td>2.578654</td>\n",
       "      <td>-0.035028</td>\n",
       "      <td>0.072091</td>\n",
       "      <td>0.144720</td>\n",
       "      <td>2.405799</td>\n",
       "      <td>13138.958984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>22.556171</td>\n",
       "      <td>3.047949</td>\n",
       "      <td>3.821722</td>\n",
       "      <td>-0.051073</td>\n",
       "      <td>0.067158</td>\n",
       "      <td>0.109084</td>\n",
       "      <td>1.462631</td>\n",
       "      <td>10808.830078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>23.403471</td>\n",
       "      <td>2.888016</td>\n",
       "      <td>3.056899</td>\n",
       "      <td>-0.004253</td>\n",
       "      <td>0.005845</td>\n",
       "      <td>0.104761</td>\n",
       "      <td>2.019670</td>\n",
       "      <td>12012.943359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>24.978308</td>\n",
       "      <td>1.371159</td>\n",
       "      <td>2.236580</td>\n",
       "      <td>-0.068871</td>\n",
       "      <td>-0.126589</td>\n",
       "      <td>0.137412</td>\n",
       "      <td>3.044259</td>\n",
       "      <td>14286.230469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>23.328363</td>\n",
       "      <td>1.295417</td>\n",
       "      <td>3.319158</td>\n",
       "      <td>-0.079007</td>\n",
       "      <td>-0.109866</td>\n",
       "      <td>0.131408</td>\n",
       "      <td>2.737964</td>\n",
       "      <td>13417.033203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>23.913704</td>\n",
       "      <td>1.824143</td>\n",
       "      <td>2.503119</td>\n",
       "      <td>0.020213</td>\n",
       "      <td>0.016007</td>\n",
       "      <td>0.142548</td>\n",
       "      <td>2.095682</td>\n",
       "      <td>12876.714844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>23.171667</td>\n",
       "      <td>2.521096</td>\n",
       "      <td>3.594732</td>\n",
       "      <td>0.032805</td>\n",
       "      <td>-0.026624</td>\n",
       "      <td>0.092923</td>\n",
       "      <td>2.846266</td>\n",
       "      <td>12944.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>23.972263</td>\n",
       "      <td>2.328973</td>\n",
       "      <td>3.350626</td>\n",
       "      <td>-0.002169</td>\n",
       "      <td>-0.070489</td>\n",
       "      <td>0.109454</td>\n",
       "      <td>2.806951</td>\n",
       "      <td>13142.653320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>23.484762</td>\n",
       "      <td>1.773483</td>\n",
       "      <td>3.144358</td>\n",
       "      <td>0.106800</td>\n",
       "      <td>-0.146150</td>\n",
       "      <td>0.170165</td>\n",
       "      <td>2.292179</td>\n",
       "      <td>12951.943359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22.399940</td>\n",
       "      <td>2.525346</td>\n",
       "      <td>3.945889</td>\n",
       "      <td>-0.004455</td>\n",
       "      <td>0.073785</td>\n",
       "      <td>0.144858</td>\n",
       "      <td>1.340997</td>\n",
       "      <td>10006.291016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>22.485428</td>\n",
       "      <td>1.960177</td>\n",
       "      <td>3.856450</td>\n",
       "      <td>0.042581</td>\n",
       "      <td>-0.149502</td>\n",
       "      <td>0.134382</td>\n",
       "      <td>1.423066</td>\n",
       "      <td>11153.117188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>22.398106</td>\n",
       "      <td>3.968451</td>\n",
       "      <td>3.945308</td>\n",
       "      <td>0.006230</td>\n",
       "      <td>-0.013954</td>\n",
       "      <td>0.047208</td>\n",
       "      <td>1.345503</td>\n",
       "      <td>8595.869141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>22.393942</td>\n",
       "      <td>2.544035</td>\n",
       "      <td>3.943803</td>\n",
       "      <td>-0.004113</td>\n",
       "      <td>0.031536</td>\n",
       "      <td>0.084661</td>\n",
       "      <td>1.334278</td>\n",
       "      <td>10097.978516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>22.484076</td>\n",
       "      <td>2.263680</td>\n",
       "      <td>3.848698</td>\n",
       "      <td>-0.026536</td>\n",
       "      <td>-0.070513</td>\n",
       "      <td>0.085162</td>\n",
       "      <td>1.953647</td>\n",
       "      <td>11613.490234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>22.687857</td>\n",
       "      <td>1.915375</td>\n",
       "      <td>3.615972</td>\n",
       "      <td>-0.024074</td>\n",
       "      <td>-0.078118</td>\n",
       "      <td>0.091293</td>\n",
       "      <td>2.331802</td>\n",
       "      <td>12408.534180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>22.405510</td>\n",
       "      <td>2.753298</td>\n",
       "      <td>3.919266</td>\n",
       "      <td>0.003522</td>\n",
       "      <td>-0.051619</td>\n",
       "      <td>0.069307</td>\n",
       "      <td>3.181403</td>\n",
       "      <td>12968.927734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>23.821210</td>\n",
       "      <td>2.505870</td>\n",
       "      <td>3.378460</td>\n",
       "      <td>-0.030410</td>\n",
       "      <td>-0.199047</td>\n",
       "      <td>0.127340</td>\n",
       "      <td>2.945880</td>\n",
       "      <td>13282.449219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>24.262573</td>\n",
       "      <td>3.082172</td>\n",
       "      <td>2.880464</td>\n",
       "      <td>0.059405</td>\n",
       "      <td>-0.190543</td>\n",
       "      <td>0.197513</td>\n",
       "      <td>5.303008</td>\n",
       "      <td>15539.535156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sigmasq  range_lat  range_lon  advec_lat  advec_lon      beta    nugget  \\\n",
       "0   24.793444   1.584529   1.718248   0.009089  -0.107299  0.131038  2.717239   \n",
       "1   24.424301   1.997055   1.942683   0.043588  -0.072679  0.137124  1.513148   \n",
       "2   26.009497   1.215236   1.558868   0.023392  -0.150548  0.199850  2.890678   \n",
       "3   24.701347   1.612308   1.822960  -0.164069  -0.237443  0.131595  3.636499   \n",
       "4   22.598671   2.901185   3.722327  -0.011729  -0.152072  0.072866  2.397249   \n",
       "5   25.594908   1.702692   2.255174   0.017462  -0.158125  0.098684  3.850205   \n",
       "6   26.030510   1.261084   2.831952   0.054831  -0.343255  0.103045  4.596346   \n",
       "7   26.043682   0.995279   1.629503  -0.019824  -0.411626  0.164296  2.751402   \n",
       "8   24.052070   1.377774   2.357721   0.021439  -0.220316  0.142847  1.675457   \n",
       "9   25.766110   1.392051   2.358172   0.026684  -0.077366  0.150648  3.821219   \n",
       "10  23.945438   1.490333   2.470762  -0.009915   0.027429  0.137959  2.066264   \n",
       "11  23.036034   2.299998   3.346955  -0.054281   0.114976  0.110155  1.604898   \n",
       "12  22.790960   2.072518   3.616723  -0.130206   0.076944  0.135628  1.441895   \n",
       "13  24.079025   2.077914   2.578654  -0.035028   0.072091  0.144720  2.405799   \n",
       "14  22.556171   3.047949   3.821722  -0.051073   0.067158  0.109084  1.462631   \n",
       "15  23.403471   2.888016   3.056899  -0.004253   0.005845  0.104761  2.019670   \n",
       "16  24.978308   1.371159   2.236580  -0.068871  -0.126589  0.137412  3.044259   \n",
       "17  23.328363   1.295417   3.319158  -0.079007  -0.109866  0.131408  2.737964   \n",
       "18  23.913704   1.824143   2.503119   0.020213   0.016007  0.142548  2.095682   \n",
       "19  23.171667   2.521096   3.594732   0.032805  -0.026624  0.092923  2.846266   \n",
       "20  23.972263   2.328973   3.350626  -0.002169  -0.070489  0.109454  2.806951   \n",
       "21  23.484762   1.773483   3.144358   0.106800  -0.146150  0.170165  2.292179   \n",
       "22  22.399940   2.525346   3.945889  -0.004455   0.073785  0.144858  1.340997   \n",
       "23  22.485428   1.960177   3.856450   0.042581  -0.149502  0.134382  1.423066   \n",
       "24  22.398106   3.968451   3.945308   0.006230  -0.013954  0.047208  1.345503   \n",
       "25  22.393942   2.544035   3.943803  -0.004113   0.031536  0.084661  1.334278   \n",
       "26  22.484076   2.263680   3.848698  -0.026536  -0.070513  0.085162  1.953647   \n",
       "27  22.687857   1.915375   3.615972  -0.024074  -0.078118  0.091293  2.331802   \n",
       "28  22.405510   2.753298   3.919266   0.003522  -0.051619  0.069307  3.181403   \n",
       "29  23.821210   2.505870   3.378460  -0.030410  -0.199047  0.127340  2.945880   \n",
       "30  24.262573   3.082172   2.880464   0.059405  -0.190543  0.197513  5.303008   \n",
       "\n",
       "            loss  \n",
       "0   14068.529297  \n",
       "1   12357.715820  \n",
       "2   14948.140625  \n",
       "3   14786.204102  \n",
       "4   12096.261719  \n",
       "5   14690.248047  \n",
       "6   15342.459961  \n",
       "7   14857.195312  \n",
       "8   12666.991211  \n",
       "9   14987.769531  \n",
       "10  13000.419922  \n",
       "11  11485.496094  \n",
       "12  11315.873047  \n",
       "13  13138.958984  \n",
       "14  10808.830078  \n",
       "15  12012.943359  \n",
       "16  14286.230469  \n",
       "17  13417.033203  \n",
       "18  12876.714844  \n",
       "19  12944.312500  \n",
       "20  13142.653320  \n",
       "21  12951.943359  \n",
       "22  10006.291016  \n",
       "23  11153.117188  \n",
       "24   8595.869141  \n",
       "25  10097.978516  \n",
       "26  11613.490234  \n",
       "27  12408.534180  \n",
       "28  12968.927734  \n",
       "29  13282.449219  \n",
       "30  15539.535156  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lat_lon_resolution = [4,4]\n",
    "day = 7\n",
    "mm_cond_number = 10\n",
    "\n",
    "years = ['2024']\n",
    "month_range =[7,8]\n",
    "idx_for_datamap= [ 8*(day-1),8*day]\n",
    "\n",
    "instance = load_data_local_computer()\n",
    "month_map, ord_mm, nns_map= instance.load_mm20k_data_bymonthyear( lat_lon_resolution= lat_lon_resolution, mm_cond_number=mm_cond_number,years_=years, months_=month_range)\n",
    "analysis_data_map, aggregated_data = instance.load_working_data_byday( month_map, ord_mm, nns_map, idx_for_datamap=idx_for_datamap)\n",
    "\n",
    "input_path = \"/Users/joonwonlee/Documents/GEMS_TCO-1/Exercises/st_model/estimates\"\n",
    "output_filename = 'vecchia_inter_estimates_1250_july24.csv'\n",
    "output_csv_path = os.path.join(input_path, output_filename)\n",
    "\n",
    "df = pd.read_csv(output_csv_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradients and hessians sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input parameters: tensor([ 2.4793e+01,  1.5845e+00,  1.7182e+00,  9.0885e-03, -1.0730e-01,\n",
      "         1.3104e-01,  2.7172e+00], dtype=torch.float64, requires_grad=True)\n",
      " the gradient: (tensor([  -3.5293,    3.5674,   -3.6402,   16.3591,   81.4576, -450.7034,\n",
      "         -23.6871], dtype=torch.float64),)\n",
      " the gradient: tensor([  -3.5293,    3.5674,   -3.6402,   16.3591,   81.4576, -450.7034,\n",
      "         -23.6871], dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "nheads =10\n",
    "instance = kernels.vecchia_experiment(0.5, analysis_data_map, aggregated_data,nns_map,mm_cond_number, nheads)\n",
    "\n",
    "# Convert parameters to a tensor with requires_grad=True\n",
    "params = torch.tensor(df.iloc[0, :-1].values, dtype=torch.float64, requires_grad=True)\n",
    "print(f'input parameters: {params}')\n",
    "\n",
    "# Define the function to compute the loss\n",
    "def compute_loss(params):\n",
    "    return instance.full_likelihood(params, aggregated_data[:, :4].to(torch.float64), aggregated_data[:, 2].to(torch.float64), instance.matern_cov_anisotropy_v05)\n",
    "    # return instance.vecchia_interpolation_1to6(params, instance.matern_cov_ani, 35)\n",
    "    \n",
    "# Compute the first derivative using torch.func.grad\n",
    "grad_f = torch.autograd.grad(compute_loss(params), params)\n",
    "print(f' the gradient: {grad_f}')\n",
    "\n",
    "grad_function = torch.func.grad(compute_loss)\n",
    "gradient = grad_function(params)\n",
    "print(f' the gradient: {gradient}')\n",
    "\n",
    "#[  0.9324, -43.9642, -35.9082,  59.9937, -17.1091, -76.0932,  -0.6668]\n",
    "torch.autograd.gradcheck(compute_loss, params, atol=1e-9, rtol=1e-6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gradient(vecc) * hessian (full) * gradient (vecc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(16.2136, dtype=torch.float64, grad_fn=<DotBackward0>)\n",
      "tensor(18.0869, dtype=torch.float64, grad_fn=<DotBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(19.9679, dtype=torch.float64, grad_fn=<DotBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# params = [24.42, 1.92, 1.92, 0.001, -0.045, 0.237, 3.34]\n",
    "\n",
    "# Convert parameters to a tensor with requires_grad=True\n",
    "params = torch.tensor(df.iloc[0, :-1].values, dtype=torch.float64, requires_grad=True)\n",
    "\n",
    "params = [ 27.25, 2.18, 2.294, 4.099e-4, -0.07915, 0.0999, 3.65]   #200\n",
    "params = torch.tensor(params, dtype=torch.float64, requires_grad=True)\n",
    "  \n",
    "\n",
    "nheads =10\n",
    "instance = kernels.vecchia_experiment(0.5, analysis_data_map, aggregated_data,nns_map,mm_cond_number, nheads)\n",
    "\n",
    "o1 = instance.vecc_ghg_statistic(params,instance.full_likelihood, instance.vecchia_b1,instance.matern_cov_anisotropy_v05, aggregated_data[:, :4],aggregated_data[:, 2])\n",
    "print(o1)\n",
    "o2 = instance.vecc_ghg_statistic(params,instance.full_likelihood, instance.vecchia_b2,instance.matern_cov_anisotropy_v05, aggregated_data[:, :4],aggregated_data[:, 2])\n",
    "print(o2)\n",
    "\n",
    "mm_cond_number = 10\n",
    "instance = kernels.vecchia_experiment(0.5, analysis_data_map, aggregated_data,nns_map,mm_cond_number, nheads)\n",
    "instance.vecc_ghg_statistic(params,instance.full_likelihood, instance.vecchia_b2,instance.matern_cov_anisotropy_v05, aggregated_data[:, :4],aggregated_data[:, 2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I prefer looking at likelihoods only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nheads = 200\n",
    "params = [ 27.25, 2.18, 2.294, 4.099e-4, -0.07915, 0.0999, 3.65]   #200\n",
    "params = torch.tensor(params, dtype=torch.float64, requires_grad=True)\n",
    "\n",
    "instance = kernels.vecchia_experiment(0.5, analysis_data_map, aggregated_data,nns_map,mm_cond_number, nheads)\n",
    "\n",
    "mm_cond_number=10\n",
    "fl= instance.full_likelihood(params, aggregated_data[:, :4],aggregated_data[:, 2], instance.matern_cov_anisotropy_v05)\n",
    "print(fl)\n",
    "\n",
    "ll = instance.vecchia_b2(params, instance.matern_cov_anisotropy_v05 )\n",
    "print(f'mm_cond_number: {mm_cond_number} likelihood: {ll}')\n",
    "\n",
    "ll2 = instance.vecchia_interpolation_1to6(params, instance.matern_cov_anisotropy_v05 )\n",
    "print(f'mm_cond_number: {mm_cond_number} likelihood: {ll2}')\n",
    "\n",
    "key_order = [0,1,2,4,3,5,7,6]\n",
    "keys = list(analysis_data_map.keys())\n",
    "reordered_dict = {keys[key]: analysis_data_map[keys[key]] for key in key_order}\n",
    "instance = kernels.vecchia_experiment(0.5, reordered_dict, aggregated_data,nns_map,mm_cond_number, nheads)\n",
    "\n",
    "\n",
    "ll = instance.vecchia_b2(params, instance.matern_cov_anisotropy_v05 )\n",
    "print(f'mm_cond_number: {mm_cond_number} likelihood: {ll}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now compare statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cond_number of hessian 2816516.366634098\n",
      "3940.2817598903225\n",
      "-59.56466834318\n"
     ]
    }
   ],
   "source": [
    "copy_analysis_map = copy.deepcopy(analysis_data_map)\n",
    "key_order = [0,1,2,4,3,5,7,6]\n",
    "keys = list(analysis_data_map.keys())\n",
    "reordered_dict = {keys[key]: copy_analysis_map[keys[key]] for key in key_order}\n",
    "\n",
    "\n",
    "params = [ 27.25, 2.18, 2.294, 4.099e-4, -0.07915, 0.0999, 3.65]   #200\n",
    "params = torch.tensor(params, dtype=torch.float64, requires_grad=True)\n",
    "nheads =200\n",
    "instance = kernels.vecchia_experiment(0.5, analysis_data_map, aggregated_data,nns_map,mm_cond_number, nheads)\n",
    "fl= instance.full_likelihood(params, aggregated_data[:, :4],aggregated_data[:, 2], instance.matern_cov_anisotropy_v05)\n",
    "fs = instance.full_ghg_statistic(params,instance.full_likelihood, instance.matern_cov_anisotropy_v05, aggregated_data[:, :4],aggregated_data[:, 2])\n",
    "\n",
    "print(fl.item())\n",
    "print(fs.item())\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cond_number of hessian 2816516.366634098\n",
      "3940.2817598903225\n",
      "-59.56466834318\n",
      "vecchia_b2 mm_cond_number: 20 likelihood: 3975.3121026623235, statistic:-43.993833612555065\n",
      "vecchia_interpolation mm_cond_number: 20 likelihood: 3898.6010621925916, statistic:-29.24946918728037\n",
      "vecchia_b2_reordered mm_cond_number: 20 likelihood: 3972.5613997053033, statistic:-33.000113088118\n",
      "day 1 above\n",
      "cond_number of hessian 212182.97911473023\n",
      "3663.07630645092\n",
      "299.06449546243493\n",
      "vecchia_b2 mm_cond_number: 20 likelihood: 3678.227239185976, statistic:306.403761341758\n",
      "vecchia_interpolation mm_cond_number: 20 likelihood: 3593.9613722562485, statistic:346.83343565608084\n",
      "vecchia_b2_reordered mm_cond_number: 20 likelihood: 3678.0105807485916, statistic:305.79937533188473\n",
      "day 2 above\n",
      "cond_number of hessian 183073.7950892095\n",
      "4343.463121533729\n",
      "83.91664846163812\n",
      "vecchia_b2 mm_cond_number: 20 likelihood: 4367.746971329721, statistic:56.015318528607715\n",
      "vecchia_interpolation mm_cond_number: 20 likelihood: 4295.084667816446, statistic:61.17919423440279\n",
      "vecchia_b2_reordered mm_cond_number: 20 likelihood: 4377.247113226095, statistic:56.55501444263892\n",
      "day 3 above\n",
      "cond_number of hessian 229398.97183150565\n",
      "4176.694521833107\n",
      "-17.229593179563764\n",
      "vecchia_b2 mm_cond_number: 20 likelihood: 4221.472119446713, statistic:27.277282871831062\n",
      "vecchia_interpolation mm_cond_number: 20 likelihood: 4137.018148790564, statistic:52.4305666824352\n",
      "vecchia_b2_reordered mm_cond_number: 20 likelihood: 4216.360455810484, statistic:0.403899777226286\n",
      "day 4 above\n",
      "cond_number of hessian 38115.8884741029\n",
      "3570.7439797369634\n",
      "488.4422245175275\n",
      "vecchia_b2 mm_cond_number: 20 likelihood: 3621.9635435647006, statistic:411.04432044126753\n",
      "vecchia_interpolation mm_cond_number: 20 likelihood: 3544.245733685256, statistic:438.72816416974905\n",
      "vecchia_b2_reordered mm_cond_number: 20 likelihood: 3612.3469147075, statistic:436.630985346751\n",
      "day 5 above\n",
      "cond_number of hessian 308841.07111646316\n",
      "4056.432055551953\n",
      "42.92307229639042\n",
      "vecchia_b2 mm_cond_number: 20 likelihood: 4101.680400760245, statistic:18.1684571597105\n",
      "vecchia_interpolation mm_cond_number: 20 likelihood: 4002.2192143242446, statistic:26.16992424301987\n",
      "vecchia_b2_reordered mm_cond_number: 20 likelihood: 4086.9964393958226, statistic:26.69525695681834\n",
      "day 6 above\n",
      "cond_number of hessian 205356.63358799714\n",
      "4425.151112241204\n",
      "128.11351231961606\n",
      "vecchia_b2 mm_cond_number: 20 likelihood: 4458.4826684540785, statistic:103.07556640152819\n",
      "vecchia_interpolation mm_cond_number: 20 likelihood: 4407.594661585072, statistic:153.97799488058476\n",
      "vecchia_b2_reordered mm_cond_number: 20 likelihood: 4448.4241291496555, statistic:101.6783887360184\n",
      "day 7 above\n",
      "cond_number of hessian 206771.24498913877\n",
      "4300.3574636734675\n",
      "16.31338391097391\n",
      "vecchia_b2 mm_cond_number: 20 likelihood: 4388.130833701285, statistic:68.50386261493549\n",
      "vecchia_interpolation mm_cond_number: 20 likelihood: 4316.969543472212, statistic:91.36553332798192\n",
      "vecchia_b2_reordered mm_cond_number: 20 likelihood: 4381.710530096565, statistic:64.93593084546438\n",
      "day 8 above\n",
      "cond_number of hessian 1550136.1257715044\n",
      "3778.682120807496\n",
      "202.0936203152329\n",
      "vecchia_b2 mm_cond_number: 20 likelihood: 3824.990322889017, statistic:128.7078097917488\n",
      "vecchia_interpolation mm_cond_number: 20 likelihood: 3723.132939053775, statistic:154.73228355133708\n",
      "vecchia_b2_reordered mm_cond_number: 20 likelihood: 3808.704593069864, statistic:151.52749489448556\n",
      "day 9 above\n",
      "cond_number of hessian 224061.12567819454\n",
      "4210.454494444216\n",
      "85.8065347886513\n",
      "vecchia_b2 mm_cond_number: 20 likelihood: 4249.196873589959, statistic:54.928390557257345\n",
      "vecchia_interpolation mm_cond_number: 20 likelihood: 4117.866337079586, statistic:31.911956856682426\n",
      "vecchia_b2_reordered mm_cond_number: 20 likelihood: 4247.193668546364, statistic:56.16707346342244\n",
      "day 10 above\n",
      "cond_number of hessian 1690718.4192618672\n",
      "3811.798100703498\n",
      "162.26057488419025\n",
      "vecchia_b2 mm_cond_number: 20 likelihood: 3837.083257173617, statistic:145.75863581254436\n",
      "vecchia_interpolation mm_cond_number: 20 likelihood: 3726.6890165802542, statistic:154.9325782126018\n",
      "vecchia_b2_reordered mm_cond_number: 20 likelihood: 3839.754460550377, statistic:131.8371650257125\n",
      "day 11 above\n",
      "cond_number of hessian 63537.94468948002\n",
      "3544.8111566058383\n",
      "986.4175750033716\n",
      "vecchia_b2 mm_cond_number: 20 likelihood: 3564.743293258005, statistic:968.1395221615202\n",
      "vecchia_interpolation mm_cond_number: 20 likelihood: 3495.080205676562, statistic:978.0882741678824\n",
      "vecchia_b2_reordered mm_cond_number: 20 likelihood: 3561.9905296898164, statistic:943.2188750640967\n",
      "day 12 above\n",
      "cond_number of hessian 292477.22700400156\n",
      "3578.6805701270364\n",
      "1042.052958415718\n",
      "vecchia_b2 mm_cond_number: 20 likelihood: 3605.6343855881537, statistic:963.6952830530785\n",
      "vecchia_interpolation mm_cond_number: 20 likelihood: 3543.3758346830787, statistic:747.7075068862723\n",
      "vecchia_b2_reordered mm_cond_number: 20 likelihood: 3601.2327019353597, statistic:945.6898414899069\n",
      "day 13 above\n",
      "cond_number of hessian 1199356.2961698393\n",
      "3737.2161536568747\n",
      "170.24490642202932\n",
      "vecchia_b2 mm_cond_number: 20 likelihood: 3764.524184527033, statistic:129.4526409253935\n",
      "vecchia_interpolation mm_cond_number: 20 likelihood: 3690.0534779112086, statistic:130.02625037101214\n",
      "vecchia_b2_reordered mm_cond_number: 20 likelihood: 3751.237367854742, statistic:117.12126666668559\n",
      "day 14 above\n"
     ]
    }
   ],
   "source": [
    "lat_lon_resolution = [8,8]\n",
    "params = [ 27.25, 2.18, 2.294, 4.099e-4, -0.07915, 0.0999, 3.65]   #200\n",
    "params = torch.tensor(params, dtype=torch.float64, requires_grad=True)\n",
    "\n",
    "\n",
    "for day in range(1,15):\n",
    "    # day = 7\n",
    "    mm_cond_number = 20\n",
    "\n",
    "    years = ['2024']\n",
    "    month_range =[7,8]\n",
    "    idx_for_datamap= [ 8*(day-1),8*day]\n",
    "\n",
    "    instance = load_data_local_computer()\n",
    "    month_map, ord_mm, nns_map= instance.load_mm20k_data_bymonthyear( lat_lon_resolution= lat_lon_resolution, mm_cond_number=mm_cond_number,years_=years, months_=month_range)\n",
    "    analysis_data_map, aggregated_data = instance.load_working_data_byday( month_map, ord_mm, nns_map, idx_for_datamap=idx_for_datamap)\n",
    "\n",
    "    nheads = 20\n",
    "    instance = kernels.vecchia_experiment(0.5, analysis_data_map, aggregated_data,nns_map,mm_cond_number, nheads)\n",
    "\n",
    "    fl= instance.full_likelihood(params, aggregated_data[:, :4],aggregated_data[:, 2], instance.matern_cov_anisotropy_v05)\n",
    "    \n",
    "    fs = instance.full_ghg_statistic(params,instance.full_likelihood, instance.matern_cov_anisotropy_v05, aggregated_data[:, :4],aggregated_data[:, 2])\n",
    "\n",
    "    print(fl.item())\n",
    "\n",
    "    print(fs.item())\n",
    "\n",
    "    o1= instance.vecc_ghg_statistic(params,instance.full_likelihood, instance.vecchia_b2,instance.matern_cov_anisotropy_v05, aggregated_data[:, :4],aggregated_data[:, 2])\n",
    "\n",
    "    ll = instance.vecchia_b2(params, instance.matern_cov_anisotropy_v05 )\n",
    "    print(f'vecchia_b2 mm_cond_number: {mm_cond_number} likelihood: {ll}, statistic:{o1}')\n",
    "\n",
    "    o1= instance.vecc_ghg_statistic(params,instance.full_likelihood, instance.vecchia_interpolation_1to6,instance.matern_cov_anisotropy_v05, aggregated_data[:, :4],aggregated_data[:, 2])\n",
    "\n",
    "    ll = instance.vecchia_interpolation_1to6(params, instance.matern_cov_anisotropy_v05 )\n",
    "    print(f'vecchia_interpolation mm_cond_number: {mm_cond_number} likelihood: {ll}, statistic:{o1}')\n",
    "\n",
    "\n",
    "    key_order = [0,1,2,4,3,5,7,6]\n",
    "    keys = list(analysis_data_map.keys())\n",
    "    reordered_dict = {keys[key]: analysis_data_map[keys[key]] for key in key_order}\n",
    "\n",
    "    instance = kernels.vecchia_experiment(0.5, reordered_dict, aggregated_data,nns_map,mm_cond_number, nheads)\n",
    "\n",
    "    o1= instance.vecc_ghg_statistic(params,instance.full_likelihood, instance.vecchia_b2, instance.matern_cov_anisotropy_v05, aggregated_data[:, :4],aggregated_data[:, 2])\n",
    "    ll = instance.vecchia_b2(params, instance.matern_cov_anisotropy_v05 )\n",
    "    print(f'vecchia_b2_reordered mm_cond_number: {mm_cond_number} likelihood: {ll}, statistic:{o1}')\n",
    "\n",
    "    print( f'day {day} above')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vary the size of conditioning set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cond_number of hessian 189194.83871267262\n",
      "full likelihood: 2547.258276245673, full statistic: 5.100717330882949\n",
      "cond_number of hessian 189194.83871267262\n",
      "mm_cond_number: 5 likelihood: 2571.7202011676554, statistic:4.810536260238044\n",
      "cond_number of hessian 189194.83871267262\n",
      "mm_cond_number: 6 likelihood: 2569.9784416212933, statistic:4.106628202046433\n",
      "cond_number of hessian 189194.83871267262\n",
      "mm_cond_number: 7 likelihood: 2567.640680723155, statistic:4.602141260135241\n",
      "cond_number of hessian 189194.83871267262\n",
      "mm_cond_number: 8 likelihood: 2567.6782831405317, statistic:5.079131623977824\n",
      "cond_number of hessian 189194.83871267262\n",
      "mm_cond_number: 9 likelihood: 2568.0001926920804, statistic:5.343090709089482\n",
      "cond_number of hessian 189194.83871267262\n",
      "mm_cond_number: 10 likelihood: 2566.523313914881, statistic:5.518904441534436\n",
      "cond_number of hessian 189194.83871267262\n",
      "mm_cond_number: 11 likelihood: 2566.7857736093847, statistic:5.4051722056787765\n",
      "cond_number of hessian 189194.83871267262\n",
      "mm_cond_number: 12 likelihood: 2568.124282603543, statistic:5.0296126600381275\n",
      "cond_number of hessian 189194.83871267262\n",
      "mm_cond_number: 13 likelihood: 2568.233047121573, statistic:5.250201889848884\n",
      "cond_number of hessian 189194.83871267262\n",
      "mm_cond_number: 14 likelihood: 2567.7039694302566, statistic:5.450737014135071\n",
      "cond_number of hessian 189194.83871267262\n",
      "mm_cond_number: 15 likelihood: 2568.0358535771416, statistic:5.417689812997492\n",
      "cond_number of hessian 189194.83871267262\n",
      "mm_cond_number: 16 likelihood: 2568.219484059257, statistic:5.164314269337584\n",
      "cond_number of hessian 189194.83871267262\n",
      "mm_cond_number: 17 likelihood: 2568.4759060207284, statistic:5.039571475176778\n",
      "cond_number of hessian 189194.83871267262\n",
      "mm_cond_number: 18 likelihood: 2568.5694376562374, statistic:4.8627871727010685\n",
      "cond_number of hessian 189194.83871267262\n",
      "mm_cond_number: 19 likelihood: 2568.953714275638, statistic:5.170509997209056\n",
      "cond_number of hessian 189194.83871267262\n",
      "mm_cond_number: 20 likelihood: 2569.1609961219333, statistic:5.325902938501164\n",
      "cond_number of hessian 189194.83871267262\n",
      "mm_cond_number: 21 likelihood: 2569.1609961219333, statistic:5.325902938501164\n",
      "cond_number of hessian 189194.83871267262\n",
      "mm_cond_number: 22 likelihood: 2569.1609961219333, statistic:5.325902938501164\n",
      "cond_number of hessian 189194.83871267262\n",
      "mm_cond_number: 23 likelihood: 2569.1609961219333, statistic:5.325902938501164\n",
      "cond_number of hessian 189194.83871267262\n",
      "mm_cond_number: 24 likelihood: 2569.1609961219333, statistic:5.325902938501164\n",
      "cond_number of hessian 189194.83871267262\n",
      "mm_cond_number: 25 likelihood: 2569.1609961219333, statistic:5.325902938501164\n",
      "cond_number of hessian 189194.83871267262\n",
      "mm_cond_number: 26 likelihood: 2569.1609961219333, statistic:5.325902938501164\n",
      "cond_number of hessian 189194.83871267262\n",
      "mm_cond_number: 27 likelihood: 2569.1609961219333, statistic:5.325902938501164\n",
      "cond_number of hessian 189194.83871267262\n",
      "mm_cond_number: 28 likelihood: 2569.1609961219333, statistic:5.325902938501164\n",
      "cond_number of hessian 189194.83871267262\n",
      "mm_cond_number: 29 likelihood: 2569.1609961219333, statistic:5.325902938501164\n"
     ]
    }
   ],
   "source": [
    "instance = kernels.vecchia_experiment(0.5, analysis_data_map, aggregated_data,nns_map,mm_cond_number, nheads)\n",
    "fl= instance.full_likelihood(params, aggregated_data[:, :4],aggregated_data[:, 2], instance.matern_cov_anisotropy_v05)\n",
    "fs = instance.full_ghg_statistic(params,instance.full_likelihood, instance.matern_cov_anisotropy_v05, aggregated_data[:, :4],aggregated_data[:, 2])\n",
    "\n",
    "print(f'full likelihood: {fl}, full statistic: {fs}')\n",
    "for i in range(5,30):\n",
    "    mm_cond_number = i\n",
    "    instance = kernels.vecchia_experiment(0.5, analysis_data_map, aggregated_data,nns_map,mm_cond_number, nheads)\n",
    "    \n",
    "    o1= instance.vecc_ghg_statistic(params,instance.full_likelihood, instance.vecchia_b2,instance.matern_cov_anisotropy_v05, aggregated_data[:, :4],aggregated_data[:, 2])\n",
    "    ll = instance.vecchia_b2(params, instance.matern_cov_anisotropy_v05 )\n",
    "    print(f'mm_cond_number: {i} likelihood: {ll}, statistic:{o1}')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "faiss_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
