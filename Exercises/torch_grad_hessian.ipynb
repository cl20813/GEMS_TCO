{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "# gems_tco_path = \"/Users/joonwonlee/Documents/GEMS_TCO-1/src\"\n",
    "# sys.path.append(gems_tco_path)\n",
    "\n",
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle \n",
    "\n",
    "import GEMS_TCO\n",
    "from GEMS_TCO import kernels \n",
    "from GEMS_TCO import orderings as _orderings\n",
    "from GEMS_TCO import load_data_local_computer\n",
    "\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "from torch.func import grad, hessian, jacfwd, jacrev\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import copy                    # clone tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "Two options: 1. torch.autograd 2. torch.func (recommended for both gradients and hessians)\n",
    "\n",
    "Observations:\n",
    "- In order to track gradients, ```sqrt()``` in distance function has to be removed and put ```sqrt(distance function output)``` in covariance function.   \n",
    "\n",
    "- If dtypes don't match, both autograd and torch.func cannot track hessians, so consider ```.to(torch.float64)``` so ``` aggregated_data[:,:4].torch.float64()```   \n",
    "for the consistency.\n",
    "Actually, it turns out that if I use ```float32```, then autograd derivative can be different from analytical derivative by ```0.001 ~ 0.004```. \n",
    "\n",
    "the difference is on the order of one-thousandth \n",
    "\n",
    "- For hessians, torch.func is recommended. ``` torch.autograd.functional.hessian(compute_loss, params)``` this doesn't work.   \n",
    "\n",
    "- It seems there is nontrivial difference between float32 and float64 settings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      4\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m instance.full_likelihood(params, aggregated_data[:, :\u001b[32m4\u001b[39m].to(torch.float64), aggregated_data[:, \u001b[32m2\u001b[39m].to(torch.float64), instance.matern_cov_ani)\n\u001b[32m      5\u001b[39m     \u001b[38;5;66;03m# return instance.vecchia_interpolation_1to6(params, instance.matern_cov_ani, 35)\u001b[39;00m\n\u001b[32m      6\u001b[39m \n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Convert parameters to a tensor with requires_grad=True\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m params = torch.tensor(\u001b[43mdf\u001b[49m.iloc[\u001b[32m0\u001b[39m, :-\u001b[32m1\u001b[39m].values, dtype=torch.float64, requires_grad=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(params)\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Compute the first derivative using torch.func.grad\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# CODE EXAMPLE\n",
    "# Define the function to compute the loss\n",
    "def compute_loss(params):\n",
    "    return instance.full_likelihood(params, aggregated_data[:, :4].to(torch.float64), aggregated_data[:, 2].to(torch.float64), instance.matern_cov_ani)\n",
    "    # return instance.vecchia_interpolation_1to6(params, instance.matern_cov_ani, 35)\n",
    "\n",
    "# Convert parameters to a tensor with requires_grad=True\n",
    "params = torch.tensor(df.iloc[0, :-1].values, dtype=torch.float64, requires_grad=True)\n",
    "print(params)\n",
    "\n",
    "# Compute the first derivative using torch.func.grad\n",
    "grad_f = grad(compute_loss)\n",
    "g1 = grad_f(params)\n",
    "print(f'Gradient: {g1}')\n",
    "\n",
    "# Compute the Hessian matrix using torch.func.hessian\n",
    "try:\n",
    "    hessian_matrix = hessian(compute_loss, params)      ## this is equivalent to jacfwd(jacrev(compute_loss))(params)\n",
    "    print(hessian_matrix)\n",
    "except Exception as e:\n",
    "    print(f'Error computing Hessian: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD DATA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sigmasq</th>\n",
       "      <th>range_lat</th>\n",
       "      <th>range_lon</th>\n",
       "      <th>advec_lat</th>\n",
       "      <th>advec_lon</th>\n",
       "      <th>beta</th>\n",
       "      <th>nugget</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.822897</td>\n",
       "      <td>1.023014</td>\n",
       "      <td>1.131423</td>\n",
       "      <td>0.073286</td>\n",
       "      <td>-0.095810</td>\n",
       "      <td>0.177670</td>\n",
       "      <td>1.569700</td>\n",
       "      <td>50396.417969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.242847</td>\n",
       "      <td>2.147953</td>\n",
       "      <td>1.945775</td>\n",
       "      <td>0.050045</td>\n",
       "      <td>-0.070032</td>\n",
       "      <td>0.140178</td>\n",
       "      <td>1.442902</td>\n",
       "      <td>43290.984375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.156120</td>\n",
       "      <td>0.818184</td>\n",
       "      <td>1.061921</td>\n",
       "      <td>0.081691</td>\n",
       "      <td>-0.119475</td>\n",
       "      <td>0.241490</td>\n",
       "      <td>2.123204</td>\n",
       "      <td>54808.964844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26.001230</td>\n",
       "      <td>1.194200</td>\n",
       "      <td>1.434477</td>\n",
       "      <td>-0.206528</td>\n",
       "      <td>-0.174575</td>\n",
       "      <td>0.041952</td>\n",
       "      <td>2.593778</td>\n",
       "      <td>52697.542969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.724660</td>\n",
       "      <td>1.819339</td>\n",
       "      <td>2.713623</td>\n",
       "      <td>-0.166419</td>\n",
       "      <td>-0.037361</td>\n",
       "      <td>-0.014584</td>\n",
       "      <td>1.945128</td>\n",
       "      <td>43821.054688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sigmasq  range_lat  range_lon  advec_lat  advec_lon      beta    nugget  \\\n",
       "0  25.822897   1.023014   1.131423   0.073286  -0.095810  0.177670  1.569700   \n",
       "1  24.242847   2.147953   1.945775   0.050045  -0.070032  0.140178  1.442902   \n",
       "2  26.156120   0.818184   1.061921   0.081691  -0.119475  0.241490  2.123204   \n",
       "3  26.001230   1.194200   1.434477  -0.206528  -0.174575  0.041952  2.593778   \n",
       "4  23.724660   1.819339   2.713623  -0.166419  -0.037361 -0.014584  1.945128   \n",
       "\n",
       "           loss  \n",
       "0  50396.417969  \n",
       "1  43290.984375  \n",
       "2  54808.964844  \n",
       "3  52697.542969  \n",
       "4  43821.054688  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lat_lon_resolution = [20,20]\n",
    "day = 1\n",
    "mm_cond_number = 20\n",
    "\n",
    "years = ['2024']\n",
    "month_range =[7,8]\n",
    "idx_for_datamap= [ 8*(day-1),8*day]\n",
    "\n",
    "instance = load_data_local_computer()\n",
    "map, ord_mm, nns_map= instance.load_mm20k_data_bymonthyear( lat_lon_resolution= lat_lon_resolution, mm_cond_number=mm_cond_number,years_=years, months_=month_range)\n",
    "analysis_data_map, aggregated_data = instance.load_working_data_byday( map, ord_mm, nns_map, idx_for_datamap=[0,8])\n",
    "\n",
    "input_path = \"/Users/joonwonlee/Documents/GEMS_TCO-1/Exercises/st_model/estimates\"\n",
    "output_filename = 'vecchia_inter_estimates_1250_july24.csv'\n",
    "output_csv_path = os.path.join(input_path, output_filename)\n",
    "\n",
    "df = pd.read_csv(output_csv_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class matern_advec_beta_torch_vecchia:\n",
    "    def __init__(self, analaysis_data_map: torch.Tensor, params: torch.Tensor, nns_map=nns_map, mm_cond_number=mm_cond_number):\n",
    "        \n",
    "        self.key_list = sorted(analysis_data_map)\n",
    "        self.input_map = analysis_data_map\n",
    "\n",
    "        self.mm_cond_number = mm_cond_number\n",
    "        self.nns_map = nns_map \n",
    "        self.input_map = analaysis_data_map\n",
    "        self.smooth = 0.5  \n",
    "        sample_df = analaysis_data_map[self.key_list[0]]\n",
    "\n",
    "        self.size_per_hour = len(sample_df)\n",
    "\n",
    "    def custom_distance_matrix(self, U, V):\n",
    "        # Efficient distance computation with broadcasting\n",
    "        spatial_diff = torch.norm(U[:, :2].unsqueeze(1) - V[:, :2].unsqueeze(0), dim=2)\n",
    "\n",
    "        temporal_diff = torch.abs(U[:, 2].unsqueeze(1) - V[:, 2].unsqueeze(0))\n",
    "        distance = (spatial_diff**2 + temporal_diff**2)  # move torch.sqrt to covariance function to track gradients of beta and avec\n",
    "        return distance\n",
    "    \n",
    "    def precompute_coords_ani(self, params, y: torch.Tensor, x: torch.Tensor)-> torch.Tensor:\n",
    "        sigmasq, range_lat, range_lon, advec_lat, advec_lon, beta, nugget = params\n",
    "\n",
    "        if y is None or x is None:\n",
    "            raise ValueError(\"Both y and x_df must be provided.\")\n",
    "\n",
    "        x1 = x[:, 0]\n",
    "        y1 = x[:, 1]\n",
    "        t1 = x[:, 3]\n",
    "\n",
    "        x2 = y[:, 0]\n",
    "        y2 = y[:, 1]\n",
    "        t2 = y[:, 3]\n",
    "\n",
    "        # spat_coord1 = torch.stack((self.x1 , self.y1 - advec * self.t1), dim=-1)\n",
    "        spat_coord1 = torch.stack(( (x1 - advec_lat * t1)/range_lat, (y1 - advec_lon * t1)/range_lon ), dim=-1)\n",
    "        spat_coord2 = torch.stack(( (x2 - advec_lat * t2)/range_lat, (y2 - advec_lon * t2)/range_lon ), dim=-1)\n",
    "\n",
    "        U = torch.cat((spat_coord1, (beta * t1).reshape(-1, 1)), dim=1)\n",
    "        V = torch.cat((spat_coord2, (beta * t2).reshape(-1, 1)), dim=1)\n",
    "\n",
    "        distance = self.custom_distance_matrix(U,V)\n",
    "        non_zero_indices = distance != 0\n",
    "        return distance, non_zero_indices\n",
    "    \n",
    "    # anisotropic in three \n",
    "    def matern_cov_ani(self,params: torch.Tensor, x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "        sigmasq, range_lat, range_lon, advec_lat, advec_lon, beta, nugget = params\n",
    "        \n",
    "\n",
    "        distance, non_zero_indices = self.precompute_coords_ani(params, x,y)\n",
    "        out = torch.zeros_like(distance)\n",
    "\n",
    "        non_zero_indices = distance != 0\n",
    "        if torch.any(non_zero_indices):\n",
    "            out[non_zero_indices] = sigmasq * torch.exp(- torch.sqrt(distance[non_zero_indices]))\n",
    "        out[~non_zero_indices] = sigmasq\n",
    "\n",
    "        # Add a small jitter term to the diagonal for numerical stability\n",
    "        out += torch.eye(out.shape[0], dtype=torch.float64) * nugget \n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def full_likelihood(self,params: torch.Tensor, input_np: torch.Tensor, y: torch.Tensor, covariance_function) -> torch.Tensor:\n",
    "        input_arr = input_np[:, :4]\n",
    "        y_arr = y\n",
    "\n",
    "        # Compute the covariance matrix\n",
    "        cov_matrix = covariance_function(params=params, y=input_arr, x=input_arr)\n",
    "        \n",
    "        # Compute the log determinant of the covariance matrix\n",
    "        sign, log_det = torch.slogdet(cov_matrix)\n",
    "        #log_det = torch.log(torch.linalg.det(cov_matrix))\n",
    "        #if sign <= 0:\n",
    "        #    raise ValueError(\"Covariance matrix is not positive definite\")\n",
    "        \n",
    "        # Extract locations\n",
    "        locs = input_arr[:, :2]\n",
    "\n",
    "        # Compute beta\n",
    "        tmp1 = torch.matmul(locs.T, torch.linalg.solve(cov_matrix, locs))\n",
    "        tmp2 = torch.matmul(locs.T, torch.linalg.solve(cov_matrix, y_arr))\n",
    "        beta = torch.linalg.solve(tmp1, tmp2)\n",
    "\n",
    "        # Compute the mean\n",
    "        mu = torch.matmul(locs, beta)\n",
    "        y_mu = y_arr - mu\n",
    "\n",
    "        # Compute the quadratic form\n",
    "        quad_form = torch.matmul(y_mu, torch.linalg.solve(cov_matrix, y_mu))\n",
    "\n",
    "        # Compute the negative log likelihood\n",
    "        neg_log_lik = 0.5 * (log_det + quad_form)\n",
    "        # neg_log_lik = 0.5 * ( log_det )\n",
    "        return  neg_log_lik \n",
    "\n",
    "    def vecchia_like_local_computer(self, params: torch.Tensor, covariance_function) -> torch.Tensor:\n",
    "        self.cov_map = defaultdict(list)\n",
    "        neg_log_lik = 0.0\n",
    "        \n",
    "        for time_idx in range(len(self.input_map)):\n",
    "            current_np = self.input_map[self.key_list[time_idx]]\n",
    "\n",
    "            # Use below when working on local computer to avoid singular matrix\n",
    "            #cur_heads = current_np[:21, :]\n",
    "            #neg_log_lik += self.full_likelihood(params, cur_heads, cur_heads[:, 2], covariance_function)\n",
    "\n",
    "            for index in range(0, self.size_per_hour):\n",
    "\n",
    "                \n",
    "                current_row = current_np[index].reshape(1, -1)\n",
    "                current_y = current_row[0, 2]\n",
    "\n",
    "                # Construct conditioning set\n",
    "                mm_neighbors = self.nns_map[index]\n",
    "                past = list(mm_neighbors)\n",
    "                data_list = []\n",
    "\n",
    "                if past:\n",
    "                    data_list.append(current_np[past])\n",
    "\n",
    "                if time_idx > 1:\n",
    "                    cov_matrix = self.cov_map[index]['cov_matrix']\n",
    "                    tmp_for_beta = self.cov_map[index]['tmp_for_beta']\n",
    "                    cov_xx_inv = self.cov_map[index]['cov_xx_inv']\n",
    "                    L_inv = self.cov_map[index]['L_inv']\n",
    "                    cov_ygivenx = self.cov_map[index]['cov_ygivenx']\n",
    "                    cond_mean_tmp = self.cov_map[index]['cond_mean_tmp']\n",
    "                    log_det = self.cov_map[index]['log_det']\n",
    "                    locs = self.cov_map[index]['locs']\n",
    "                    \n",
    "                    last_hour_np = self.input_map[self.key_list[time_idx - 1]]\n",
    "                    past_conditioning_data = last_hour_np[past + [index], :]\n",
    "                    data_list.append(past_conditioning_data)\n",
    "\n",
    "                    if data_list:\n",
    "                        conditioning_data = torch.vstack(data_list)\n",
    "                    else:\n",
    "                        conditioning_data = torch.empty((0, current_row.shape[1]), dtype=torch.float32)\n",
    "\n",
    "                    np_arr = torch.vstack((current_row, conditioning_data))\n",
    "                    y_and_neighbors = np_arr[:, 2]\n",
    "\n",
    "                    cov_yx = cov_matrix[0, 1:]\n",
    "\n",
    "                    tmp2 = torch.matmul(torch.matmul(L_inv, locs).T, torch.matmul(L_inv, y_and_neighbors))\n",
    "                    beta = torch.linalg.solve(tmp_for_beta, tmp2)\n",
    "\n",
    "                    mu = torch.matmul(locs, beta)\n",
    "                    mu_current = mu[0]\n",
    "                    mu_neighbors = mu[1:]\n",
    "                    \n",
    "                    # Mean and variance of y|x\n",
    "                    cond_mean = mu_current + torch.matmul(cond_mean_tmp, (y_and_neighbors[1:] - mu_neighbors))\n",
    "                    alpha = current_y - cond_mean\n",
    "                    quad_form = alpha**2 * (1 / cov_ygivenx)\n",
    "                    neg_log_lik += 0.5 * (log_det + quad_form)\n",
    "\n",
    "                    continue\n",
    "\n",
    "                if time_idx > 0:\n",
    "                    last_hour_np = self.input_map[self.key_list[time_idx - 1]]\n",
    "                    past_conditioning_data = last_hour_np[past + [index], :]\n",
    "                    data_list.append(past_conditioning_data)\n",
    "\n",
    "                if data_list:\n",
    "                    conditioning_data = torch.vstack(data_list)\n",
    "                else:\n",
    "                    conditioning_data = torch.empty((0, current_row.shape[1]), dtype=torch.float32)\n",
    "\n",
    "                np_arr = torch.vstack((current_row, conditioning_data))\n",
    "                y_and_neighbors = np_arr[:, 2]\n",
    "                locs = np_arr[:, :2]\n",
    "\n",
    "                cov_matrix = covariance_function(params=params, y= np_arr, x= np_arr)\n",
    "                # print(f'Condition number: {torch.linalg.cond(cov_matrix)}')\n",
    "                L = torch.linalg.cholesky(cov_matrix)\n",
    "                L11 = L[:1, :1]\n",
    "                L12 = torch.zeros(L[:1, 1:].shape)\n",
    "                L21 = L[1:, :1]\n",
    "                L22 = L[1:, 1:]\n",
    "                L11_inv = torch.linalg.inv(L11)\n",
    "                L22_inv = torch.linalg.inv(L22)\n",
    "\n",
    "                # First block: [L11_inv, L12]\n",
    "                upper_block = torch.cat((L11_inv, L12), dim=1)  # Concatenate along columns (dim=1)\n",
    "\n",
    "                # Second block: [-torch.matmul(torch.matmul(L22_inv, L21), L11_inv), L22_inv]\n",
    "                lower_left = -torch.matmul(torch.matmul(L22_inv, L21), L11_inv)\n",
    "                lower_block = torch.cat((lower_left, L22_inv), dim=1)  # Concatenate along columns (dim=1)\n",
    "\n",
    "                # Combine the upper and lower blocks\n",
    "                L_inv = torch.cat((upper_block, lower_block), dim=0)  # Concatenate along rows (dim=0)\n",
    "\n",
    "                cov_yx = cov_matrix[0, 1:]\n",
    "\n",
    "                tmp1 = torch.matmul(L_inv, locs)\n",
    "                tmp2 = torch.matmul(torch.matmul(L_inv, locs).T, torch.matmul(L_inv, y_and_neighbors))\n",
    "                tmp_for_beta = torch.matmul(tmp1.T, tmp1)\n",
    "                beta = torch.linalg.solve(tmp_for_beta, tmp2)\n",
    "\n",
    "                mu = torch.matmul(locs, beta)\n",
    "                mu_current = mu[0]\n",
    "                mu_neighbors = mu[1:]\n",
    "\n",
    "                # Mean and variance of y|x\n",
    "                sigma = cov_matrix[0, 0]\n",
    "                cov_xx = cov_matrix[1:, 1:]\n",
    "                cov_xx_inv = torch.linalg.inv(cov_xx)\n",
    "\n",
    "                cov_ygivenx = sigma - torch.matmul(cov_yx, torch.matmul(cov_xx_inv, cov_yx))\n",
    "                cond_mean_tmp = torch.matmul(cov_yx, cov_xx_inv)\n",
    "                cond_mean = mu_current + torch.matmul(cond_mean_tmp, (y_and_neighbors[1:] - mu_neighbors))\n",
    "                \n",
    "                alpha = current_y - cond_mean\n",
    "                quad_form = alpha**2 * (1 / cov_ygivenx)\n",
    "                log_det = torch.log(cov_ygivenx)\n",
    "                neg_log_lik += 0.5 * (log_det + quad_form)\n",
    "\n",
    "             \n",
    "                if time_idx == 1:\n",
    "                    self.cov_map[index] = {\n",
    "                        'tmp_for_beta': tmp_for_beta,\n",
    "                        'cov_xx_inv': cov_xx_inv,\n",
    "                        'cov_matrix': cov_matrix,\n",
    "                        'L_inv': L_inv,\n",
    "                        'cov_ygivenx': cov_ygivenx,\n",
    "                        'cond_mean_tmp': cond_mean_tmp,\n",
    "                        'log_det': log_det,\n",
    "                        'locs': locs\n",
    "                    }\n",
    "\n",
    "        return neg_log_lik  \n",
    "\n",
    "    def vecchia_local_extra_base(self, params: torch.Tensor, covariance_function) -> torch.Tensor:\n",
    "        self.cov_map = defaultdict(list)\n",
    "        neg_log_lik = 0.0\n",
    "        \n",
    "        for time_idx in range(len(self.input_map)):\n",
    "            current_np = self.input_map[self.key_list[time_idx]]\n",
    "\n",
    "            # Use below when working on local computer to avoid singular matrix\n",
    "            # cur_heads = current_np[:21, :]\n",
    "            # neg_log_lik += self.full_likelihood(params, cur_heads, cur_heads[:, 2], covariance_function)\n",
    "\n",
    "            for index in range(0, self.size_per_hour):\n",
    "                current_row = current_np[index].reshape(1, -1)\n",
    "                current_y = current_row[0, 2]\n",
    "\n",
    "                # Construct conditioning set\n",
    "                mm_neighbors = self.nns_map[index]\n",
    "                past = list(mm_neighbors) + base_list\n",
    "                data_list = []\n",
    "\n",
    "                if past:\n",
    "                    data_list.append(current_np[past])\n",
    "\n",
    "                if time_idx > 1:\n",
    "                    cov_matrix = self.cov_map[index]['cov_matrix']\n",
    "                    tmp_for_beta = self.cov_map[index]['tmp_for_beta']\n",
    "                    cov_xx_inv = self.cov_map[index]['cov_xx_inv']\n",
    "            \n",
    "                    cov_ygivenx = self.cov_map[index]['cov_ygivenx']\n",
    "                    cond_mean_tmp = self.cov_map[index]['cond_mean_tmp']\n",
    "                    log_det = self.cov_map[index]['log_det']\n",
    "                    locs = self.cov_map[index]['locs']\n",
    "                    \n",
    "                    last_hour_np = self.input_map[self.key_list[time_idx - 1]]\n",
    "                    past_conditioning_data = last_hour_np[past + [index] + base_list, :]\n",
    "                    data_list.append(past_conditioning_data)\n",
    "\n",
    "                    if data_list:\n",
    "                        conditioning_data = torch.vstack(data_list)\n",
    "                    else:\n",
    "                        conditioning_data = torch.empty((0, current_row.shape[1]), dtype=torch.float32)\n",
    "\n",
    "                    np_arr = torch.vstack((current_row, conditioning_data))\n",
    "                    y_and_neighbors = np_arr[:, 2]\n",
    "\n",
    "                    cov_yx = cov_matrix[0, 1:]\n",
    "\n",
    "                    y_arr = y_and_neighbors\n",
    "                    tmp1 = tmp_for_beta\n",
    "                    tmp2 = torch.matmul(locs.T, torch.linalg.solve(cov_matrix, y_arr))\n",
    "                    beta = torch.linalg.solve(tmp1, tmp2)\n",
    "\n",
    "                    mu = torch.matmul(locs, beta)\n",
    "                    mu_current = mu[0]\n",
    "                    mu_neighbors = mu[1:]\n",
    "                    \n",
    "                    # Mean and variance of y|x\n",
    "                    cond_mean = mu_current + torch.matmul(cond_mean_tmp, (y_and_neighbors[1:] - mu_neighbors))\n",
    "                    alpha = current_y - cond_mean\n",
    "                    quad_form = alpha**2 * (1 / cov_ygivenx)\n",
    "                    neg_log_lik += 0.5 * (log_det + quad_form)\n",
    "\n",
    "                    continue\n",
    "\n",
    "                if time_idx > 0:\n",
    "                    last_hour_np = self.input_map[self.key_list[time_idx - 1]]\n",
    "                    past_conditioning_data = last_hour_np[past + [index]+ base_list, :]\n",
    "                    data_list.append(past_conditioning_data)\n",
    "\n",
    "                if data_list:\n",
    "                    conditioning_data = torch.vstack(data_list)\n",
    "                else:\n",
    "                    conditioning_data = torch.empty((0, current_row.shape[1]), dtype=torch.float32)\n",
    "\n",
    "                np_arr = torch.vstack((current_row, conditioning_data))\n",
    "                y_and_neighbors = np_arr[:, 2]\n",
    "                locs = np_arr[:, :2]\n",
    "\n",
    "                cov_matrix = covariance_function(params=params, y= np_arr, x= np_arr)\n",
    "                # print(f'Condition number: {torch.linalg.cond(cov_matrix)}')\n",
    "                cov_yx = cov_matrix[0, 1:]\n",
    "                        # Compute the log determinant of the covariance matrix\n",
    "                sign, log_det = torch.slogdet(cov_matrix)\n",
    "                # if sign <= 0:\n",
    "                #     raise ValueError(\"Covariance matrix is not positive definite\")\n",
    "            \n",
    "                y_arr = y_and_neighbors\n",
    "                # Compute beta\n",
    "                tmp1 = torch.matmul(locs.T, torch.linalg.solve(cov_matrix, locs))\n",
    "                tmp2 = torch.matmul(locs.T, torch.linalg.solve(cov_matrix, y_arr))\n",
    "                beta = torch.linalg.solve(tmp1, tmp2)\n",
    "\n",
    "                mu = torch.matmul(locs, beta)\n",
    "                mu_current = mu[0]\n",
    "                mu_neighbors = mu[1:]\n",
    "\n",
    "                # Mean and variance of y|x\n",
    "                sigma = cov_matrix[0, 0]\n",
    "                cov_xx = cov_matrix[1:, 1:]\n",
    "                cov_xx_inv = torch.linalg.inv(cov_xx)\n",
    "\n",
    "                cov_ygivenx = sigma - torch.matmul(cov_yx, torch.matmul(cov_xx_inv, cov_yx))\n",
    "                cond_mean_tmp = torch.matmul(cov_yx, cov_xx_inv)\n",
    "                cond_mean = mu_current + torch.matmul(cond_mean_tmp, (y_and_neighbors[1:] - mu_neighbors))\n",
    "                \n",
    "                alpha = current_y - cond_mean\n",
    "                quad_form = alpha**2 * (1 / cov_ygivenx)\n",
    "                log_det = torch.log(cov_ygivenx)\n",
    "                neg_log_lik += 0.5 * (log_det + quad_form)\n",
    " \n",
    "                if time_idx == 1:\n",
    "                    self.cov_map[index] = {\n",
    "                        'tmp_for_beta': tmp1,\n",
    "                        'cov_xx_inv': cov_xx_inv,\n",
    "                        'cov_matrix': cov_matrix,\n",
    "               \n",
    "                        'cov_ygivenx': cov_ygivenx,\n",
    "                        'cond_mean_tmp': cond_mean_tmp,\n",
    "                        'log_det': log_det,\n",
    "                        'locs': locs\n",
    "                    }\n",
    "        return neg_log_lik\n",
    "    \n",
    "\n",
    "    def vecchia_b2(self, params: torch.Tensor, covariance_function, cut_line=35) -> torch.Tensor:\n",
    "        self.cov_map = defaultdict(list)\n",
    "        neg_log_lik = 0.0\n",
    "        key_list = sorted(analysis_data_map)\n",
    "        cut_line = cut_line\n",
    "        heads = analysis_data_map[key_list[0]][:cut_line,:]\n",
    "        for time_idx in range(1, len(analysis_data_map)):\n",
    "            tmp = analysis_data_map[key_list[time_idx]][:cut_line,:]\n",
    "            heads = torch.cat( (heads,tmp), dim=0)\n",
    "\n",
    "        neg_log_lik += self.full_likelihood(params, heads, heads[:, 2], covariance_function)          \n",
    "        \n",
    "        for time_idx in range(0,len(self.input_map)):\n",
    "            current_np = self.input_map[self.key_list[time_idx]]\n",
    "\n",
    "            # Use below when working on local computer to avoid singular matrix\n",
    "            for index in range(cut_line, self.size_per_hour):\n",
    "                current_row = current_np[index].reshape(1, -1)\n",
    "                current_y = current_row[0, 2]\n",
    "\n",
    "                # Construct conditioning set\n",
    "                mm_neighbors = self.nns_map[index]\n",
    "                past = list(mm_neighbors) \n",
    "                data_list = []\n",
    "\n",
    "                if past:\n",
    "                    data_list.append(current_np[past])\n",
    "\n",
    "                if time_idx > 0:\n",
    "                    last_hour_np = self.input_map[self.key_list[time_idx - 1]]\n",
    "                    past_conditioning_data = last_hour_np[past + [index], :]\n",
    "                    data_list.append(past_conditioning_data)\n",
    "\n",
    "                if time_idx > 1:\n",
    "                    last_hour_np = self.input_map[self.key_list[time_idx -2]]\n",
    "                    # if index==200:\n",
    "                    #     print(self.input_map[self.key_list[time_idx-6]])\n",
    "                    past_conditioning_data = last_hour_np[past + [index], :]\n",
    "                    data_list.append(past_conditioning_data)\n",
    "                \n",
    "                if data_list:\n",
    "                    conditioning_data = torch.vstack(data_list)\n",
    "                else:\n",
    "                    conditioning_data = torch.empty((0, current_row.shape[1]), dtype=torch.float32)\n",
    "\n",
    "                np_arr = torch.vstack((current_row, conditioning_data))\n",
    "                y_and_neighbors = np_arr[:, 2]\n",
    "                locs = np_arr[:, :2]\n",
    "\n",
    "                cov_matrix = covariance_function(params=params, y= np_arr, x= np_arr)\n",
    "                # print(f'Condition number: {torch.linalg.cond(cov_matrix)}')\n",
    "                cov_yx = cov_matrix[0, 1:]\n",
    "                        # Compute the log determinant of the covariance matrix\n",
    "                sign, log_det = torch.slogdet(cov_matrix)\n",
    "                # if sign <= 0:\n",
    "                #     raise ValueError(\"Covariance matrix is not positive definite\")\n",
    "            \n",
    "                y_arr = y_and_neighbors\n",
    "                # Compute beta\n",
    "                tmp1 = torch.matmul(locs.T, torch.linalg.solve(cov_matrix, locs))\n",
    "                tmp2 = torch.matmul(locs.T, torch.linalg.solve(cov_matrix, y_arr))\n",
    "                beta = torch.linalg.solve(tmp1, tmp2)\n",
    "\n",
    "                mu = torch.matmul(locs, beta)\n",
    "                mu_current = mu[0]\n",
    "                mu_neighbors = mu[1:]\n",
    "\n",
    "                # Mean and variance of y|x\n",
    "                sigma = cov_matrix[0, 0]\n",
    "                cov_xx = cov_matrix[1:, 1:]\n",
    "                cov_xx_inv = torch.linalg.inv(cov_xx)\n",
    "\n",
    "                cov_ygivenx = sigma - torch.matmul(cov_yx, torch.matmul(cov_xx_inv, cov_yx))\n",
    "                cond_mean_tmp = torch.matmul(cov_yx, cov_xx_inv)\n",
    "                cond_mean = mu_current + torch.matmul(cond_mean_tmp, (y_and_neighbors[1:] - mu_neighbors))\n",
    "                \n",
    "                alpha = current_y - cond_mean\n",
    "                quad_form = alpha**2 * (1 / cov_ygivenx)\n",
    "                log_det = torch.log(cov_ygivenx)\n",
    "                neg_log_lik += 0.5 * (log_det + quad_form)\n",
    " \n",
    "        return neg_log_lik\n",
    "    \n",
    "\n",
    "    def vecchia_interpolation_1to6(self, params: torch.Tensor, covariance_function, cut_line=200) -> torch.Tensor:\n",
    "        self.cov_map = defaultdict(list)\n",
    "        neg_log_lik = 0.0\n",
    "        key_list = sorted(analysis_data_map)\n",
    "        cut_line = cut_line\n",
    "        heads = analysis_data_map[key_list[0]][:cut_line,:]\n",
    "        for time_idx in range(1, len(analysis_data_map)):\n",
    "            tmp = analysis_data_map[key_list[time_idx]][:cut_line,:]\n",
    "            heads = torch.cat( (heads,tmp), dim=0)\n",
    "\n",
    "        neg_log_lik += self.full_likelihood(params, heads, heads[:, 2], covariance_function)          \n",
    "        \n",
    "        for time_idx in range(0,len(self.input_map)):\n",
    "            current_np = self.input_map[self.key_list[time_idx]]\n",
    "\n",
    "            # Use below when working on local computer to avoid singular matrix\n",
    "            for index in range(cut_line, self.size_per_hour):\n",
    "                current_row = current_np[index].reshape(1, -1)\n",
    "                current_y = current_row[0, 2]\n",
    "\n",
    "                # Construct conditioning set\n",
    "                mm_neighbors = self.nns_map[index]\n",
    "                past = list(mm_neighbors) \n",
    "                data_list = []\n",
    "\n",
    "                if past:\n",
    "                    data_list.append(current_np[past])\n",
    "\n",
    "                if time_idx > 0 and time_idx<7:\n",
    "                    last_hour_np = self.input_map[self.key_list[time_idx - 1]]\n",
    "                    past_conditioning_data = last_hour_np[past + [index], :]\n",
    "                    data_list.append(past_conditioning_data)\n",
    "\n",
    "                    last_hour_np = self.input_map[self.key_list[time_idx +1]]\n",
    "                    # if index==200:\n",
    "                    #     print(self.input_map[self.key_list[time_idx-6]])\n",
    "                    past_conditioning_data = last_hour_np[past + [index], :]\n",
    "                    data_list.append(past_conditioning_data)\n",
    "                \n",
    "                if data_list:\n",
    "                    conditioning_data = torch.vstack(data_list)\n",
    "                else:\n",
    "                    conditioning_data = torch.empty((0, current_row.shape[1]), dtype=torch.float32)\n",
    "\n",
    "                np_arr = torch.vstack((current_row, conditioning_data))\n",
    "                y_and_neighbors = np_arr[:, 2]\n",
    "                locs = np_arr[:, :2]\n",
    "\n",
    "                cov_matrix = covariance_function(params=params, y= np_arr, x= np_arr)\n",
    "                # print(f'Condition number: {torch.linalg.cond(cov_matrix)}')\n",
    "                cov_yx = cov_matrix[0, 1:]\n",
    "                        # Compute the log determinant of the covariance matrix\n",
    "                sign, log_det = torch.slogdet(cov_matrix)\n",
    "                # if sign <= 0:\n",
    "                #     raise ValueError(\"Covariance matrix is not positive definite\")\n",
    "            \n",
    "                y_arr = y_and_neighbors\n",
    "                # Compute beta\n",
    "                tmp1 = torch.matmul(locs.T, torch.linalg.solve(cov_matrix, locs))\n",
    "                tmp2 = torch.matmul(locs.T, torch.linalg.solve(cov_matrix, y_arr))\n",
    "                beta = torch.linalg.solve(tmp1, tmp2)\n",
    "\n",
    "                mu = torch.matmul(locs, beta)\n",
    "                mu_current = mu[0]\n",
    "                mu_neighbors = mu[1:]\n",
    "\n",
    "                # Mean and variance of y|x\n",
    "                sigma = cov_matrix[0, 0]\n",
    "                cov_xx = cov_matrix[1:, 1:]\n",
    "                cov_xx_inv = torch.linalg.inv(cov_xx)\n",
    "\n",
    "                cov_ygivenx = sigma - torch.matmul(cov_yx, torch.matmul(cov_xx_inv, cov_yx))\n",
    "                cond_mean_tmp = torch.matmul(cov_yx, cov_xx_inv)\n",
    "                cond_mean = mu_current + torch.matmul(cond_mean_tmp, (y_and_neighbors[1:] - mu_neighbors))\n",
    "                \n",
    "                alpha = current_y - cond_mean\n",
    "                quad_form = alpha**2 * (1 / cov_ygivenx)\n",
    "                log_det = torch.log(cov_ygivenx)\n",
    "                neg_log_lik += 0.5 * (log_det + quad_form)\n",
    " \n",
    "        return neg_log_lik\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Likelihood investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2547.2583, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "day 1 finished\n"
     ]
    }
   ],
   "source": [
    "lat_lon_resolution = [10,10]\n",
    "\n",
    "head100map = defaultdict(list)\n",
    "\n",
    "headn = 10\n",
    "b = [0]*7\n",
    "b1=b2=b3=b4=b5=b6=0\n",
    "for day in range(1,2):\n",
    "    mm_cond_number = 10\n",
    "\n",
    "    years = ['2024']\n",
    "    month_range =[7,8]\n",
    "    idx_for_datamap= [ 8*(day-1),8*day]\n",
    "\n",
    "    instance = load_data_local_computer()\n",
    "    map, ord_mm, nns_map= instance.load_mm20k_data_bymonthyear( lat_lon_resolution= lat_lon_resolution, mm_cond_number=mm_cond_number,years_=years, months_=month_range)\n",
    "    analysis_data_map, aggregated_data = instance.load_working_data_byday( map, ord_mm, nns_map, idx_for_datamap= idx_for_datamap)\n",
    "\n",
    "    params = [ 24.793444,\t1.5845289,\t1.7182478,\t0.009088504,\t-0.10729945,\t0.13103764,\t2.7172387]  #1250\n",
    "    params = [ 27.25, 2.18, 2.294, 4.099e-4, -0.07915, 0.0999, 3.65]   #200\n",
    "    # params = [24.42, 1.92, 1.92, 0.001, -0.045, 0.237, 3.34]\n",
    "    params = torch.tensor(params, requires_grad=True)\n",
    "    instance = matern_advec_beta_torch_vecchia(analysis_data_map, params, nns_map, mm_cond_number)\n",
    "    \n",
    "    out = instance.full_likelihood(params, aggregated_data[:,:4].to(torch.float64),aggregated_data[:,2].to(torch.float64), instance.matern_cov_ani)\n",
    "    print(out)  # 15105\n",
    "\n",
    "\n",
    "   \n",
    "    print(f'day {day} finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradients and hessians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input parameters: tensor([25.8229,  1.0230,  1.1314,  0.0733, -0.0958,  0.1777,  1.5697],\n",
      "       dtype=torch.float64, requires_grad=True)\n",
      " the gradient: (tensor([  0.9324, -43.9643, -35.9081,  59.9936, -17.1093, -76.0930,  -0.6668],\n",
      "       dtype=torch.float64),)\n",
      " the gradient: tensor([  0.9324, -43.9643, -35.9081,  59.9936, -17.1093, -76.0930,  -0.6668],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert parameters to a tensor with requires_grad=True\n",
    "params = torch.tensor(df.iloc[0, :-1].values, dtype=torch.float64, requires_grad=True)\n",
    "print(f'input parameters: {params}')\n",
    "\n",
    "# Define the function to compute the loss\n",
    "def compute_loss(params):\n",
    "    return instance.full_likelihood(params, aggregated_data[:, :4].to(torch.float64), aggregated_data[:, 2].to(torch.float64), instance.matern_cov_ani)\n",
    "    # return instance.vecchia_interpolation_1to6(params, instance.matern_cov_ani, 35)\n",
    "    \n",
    "# Compute the first derivative using torch.func.grad\n",
    "grad_f = torch.autograd.grad(compute_loss(params), params)\n",
    "\n",
    "print(f' the gradient: {grad_f}')\n",
    "\n",
    "grad_function = torch.func.grad(compute_loss)\n",
    "gradient = grad_function(params)\n",
    "print(f' the gradient: {gradient}')\n",
    "\n",
    "#[  0.9324, -43.9642, -35.9082,  59.9937, -17.1091, -76.0932,  -0.6668]\n",
    "torch.autograd.gradcheck(compute_loss, params, atol=1e-9, rtol=1e-6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vecchia interpolation, conditioning on both past and future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full likelihood 2547.258276245673\n",
      "Gradient: tensor([-0.6224, -0.2272, -0.0769, -1.2766,  2.0406,  2.8008,  0.0732],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "full likelihood 2547.258276245673\n",
      "full statistic is 5.100717330882949\n",
      "likelihood 2505.8255159564155\n",
      "likelihood 2505.8255159564155\n",
      "vecc statistic is 4.490207541744903\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(4.4902, dtype=torch.float64, grad_fn=<DotBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# params = [24.42, 1.92, 1.92, 0.001, -0.045, 0.237, 3.34]\n",
    "\n",
    "\n",
    "# Convert parameters to a tensor with requires_grad=True\n",
    "params = torch.tensor(df.iloc[0, :-1].values, dtype=torch.float64, requires_grad=True)\n",
    "\n",
    "params = [ 27.25, 2.18, 2.294, 4.099e-4, -0.07915, 0.0999, 3.65]   #200\n",
    "params = torch.tensor(params, dtype=torch.float64, requires_grad=True)\n",
    "  \n",
    "\n",
    "def compute_statistic_full(params, data,y):\n",
    "    instance = matern_advec_beta_torch_vecchia(analysis_data_map, params, nns_map, mm_cond_number)\n",
    "    \n",
    "    # Define the function to compute the loss\n",
    "    def compute_loss(params):\n",
    "        ll = instance.full_likelihood(params,data , y, instance.matern_cov_ani)\n",
    "        print(f'full likelihood {ll}')\n",
    "        return ll\n",
    "        # return instance.vecchia_interpolation_1to6(params, instance.matern_cov_ani, 35)\n",
    "    grad_function = torch.func.grad(compute_loss)\n",
    "    gradient = grad_function(params)\n",
    "\n",
    "    print(f'Gradient: {gradient}')\n",
    "\n",
    "    # Compute the Hessian matrix using torch.func.hessian\n",
    "    try:\n",
    "        hessian_matrix =  torch.func.hessian(compute_loss)(params)\n",
    "        # print(hessian_matrix)\n",
    "    except Exception as e:\n",
    "        print(f'Error computing Hessian: {e}')\n",
    "\n",
    "    statistic  = torch.matmul(gradient, torch.linalg.solve(hessian_matrix, gradient))\n",
    "    # print(f' statistic is {statistic}')\n",
    "    print(f'full statistic is {statistic}')\n",
    "    return statistic\n",
    "\n",
    "def compute_statistic_vecc(params, mm_cond_number):\n",
    "    instance = load_data_local_computer()\n",
    "    map, ord_mm, nns_map= instance.load_mm20k_data_bymonthyear( lat_lon_resolution= lat_lon_resolution, mm_cond_number=mm_cond_number,years_=years, months_=month_range)\n",
    "    analysis_data_map, aggregated_data = instance.load_working_data_byday( map, ord_mm, nns_map, idx_for_datamap= idx_for_datamap)\n",
    "    instance = matern_advec_beta_torch_vecchia(analysis_data_map, params, nns_map, mm_cond_number)\n",
    "    \n",
    "    # Define the function to compute the loss\n",
    "    def compute_loss(params):\n",
    "        # return instance.vecchia_like_local_computer(params, instance.matern_cov_ani)\n",
    "        ll = instance.vecchia_interpolation_1to6(params, instance.matern_cov_ani, 35)\n",
    "        print(f'likelihood {ll}')\n",
    "        return ll\n",
    "\n",
    "    grad_function = torch.func.grad(compute_loss)\n",
    "    gradient = grad_function(params)\n",
    "    try:\n",
    "        hessian_matrix =  torch.func.hessian(compute_loss)(params)\n",
    "        # print(hessian_matrix)\n",
    "    except Exception as e:\n",
    "        print(f'Error computing Hessian: {e}')\n",
    "\n",
    "    statistic  = torch.matmul(gradient, torch.linalg.solve(hessian_matrix, gradient))\n",
    "    # print(f' statistic is {statistic}')\n",
    "    print(f'vecc statistic is {statistic}')\n",
    "    return statistic\n",
    "\n",
    "compute_statistic_full(params,aggregated_data[:, :4].to(torch.float64),aggregated_data[:, 2].to(torch.float64))\n",
    "compute_statistic_vecc(params, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now compare statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "likelihood 2507.000597851662\n",
      "likelihood 2507.000597851662\n",
      "vecc statistic is 4.648368261380997\n",
      "likelihood 2507.7412012081904\n",
      "likelihood 2507.7412012081904\n",
      "vecc statistic is 4.963277645222633\n",
      "likelihood 2507.274915903053\n",
      "likelihood 2507.274915903053\n",
      "vecc statistic is 4.934515341837704\n",
      "likelihood 2507.0920177422545\n",
      "likelihood 2507.0920177422545\n",
      "vecc statistic is 5.09900386943201\n",
      "likelihood 2507.168987461403\n",
      "likelihood 2507.168987461403\n",
      "vecc statistic is 5.32417886417015\n",
      "likelihood 2507.003368575228\n",
      "likelihood 2507.003368575228\n",
      "vecc statistic is 5.409555477662674\n",
      "likelihood 2507.2581959007302\n",
      "likelihood 2507.2581959007302\n",
      "vecc statistic is 5.296278515140054\n",
      "likelihood 2507.768033104974\n",
      "likelihood 2507.768033104974\n",
      "vecc statistic is 5.4752822606873774\n",
      "likelihood 2507.6583166714668\n",
      "likelihood 2507.6583166714668\n",
      "vecc statistic is 5.4529586855481975\n"
     ]
    }
   ],
   "source": [
    "for i in range(11,20):\n",
    "    compute_statistic_vecc(params, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vecchia condition on two lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full likelihood 2547.258276245673\n",
      "Gradient: tensor([-0.6224, -0.2272, -0.0769, -1.2766,  2.0406,  2.8008,  0.0732],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "full likelihood 2547.258276245673\n",
      "full statistic is 5.100717330882949\n",
      "vecc_b2 likelihood 2561.9232868312483\n",
      "vecc_b2 likelihood 2561.9232868312483\n",
      "vecc statistic is 7.17562895976746\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(7.1756, dtype=torch.float64, grad_fn=<DotBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = [ 27.25, 2.18, 2.294, 4.099e-4, -0.07915, 0.0999, 3.65]   #200\n",
    "params = torch.tensor(params, dtype=torch.float64, requires_grad=True)\n",
    "\n",
    "def compute_statistic_vecc(params, mm_cond_number):\n",
    "    instance = load_data_local_computer()\n",
    "    map, ord_mm, nns_map= instance.load_mm20k_data_bymonthyear( lat_lon_resolution= lat_lon_resolution, mm_cond_number=mm_cond_number,years_=years, months_=month_range)\n",
    "    analysis_data_map, aggregated_data = instance.load_working_data_byday( map, ord_mm, nns_map, idx_for_datamap= idx_for_datamap)\n",
    "    instance = matern_advec_beta_torch_vecchia(analysis_data_map, params, nns_map, mm_cond_number)\n",
    "    \n",
    "    # Define the function to compute the loss\n",
    "    def compute_loss(params):\n",
    "        # return instance.vecchia_like_local_computer(params, instance.matern_cov_ani)\n",
    "        ll = instance.vecchia_b2(params, instance.matern_cov_ani, 35)\n",
    "        print(f'vecc_b2 likelihood {ll}')\n",
    "        return ll\n",
    "\n",
    "    grad_function = torch.func.grad(compute_loss)\n",
    "    gradient = grad_function(params)\n",
    "    try:\n",
    "        hessian_matrix =  torch.func.hessian(compute_loss)(params)\n",
    "        # print(hessian_matrix)\n",
    "    except Exception as e:\n",
    "        print(f'Error computing Hessian: {e}')\n",
    "\n",
    "    statistic  = torch.matmul(gradient, torch.linalg.solve(hessian_matrix, gradient))\n",
    "    # print(f' statistic is {statistic}')\n",
    "    print(f'vecc statistic is {statistic}')\n",
    "    return statistic\n",
    "\n",
    "compute_statistic_full(params,aggregated_data[:, :4].to(torch.float64),aggregated_data[:, 2].to(torch.float64))\n",
    "compute_statistic_vecc(params, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vecc_b2 likelihood 2567.9938103573804\n",
      "vecc_b2 likelihood 2567.9938103573804\n",
      "vecc statistic is 8.095305048640391\n",
      "vecc_b2 likelihood 2567.724168564479\n",
      "vecc_b2 likelihood 2567.724168564479\n",
      "vecc statistic is 5.7202865316076785\n",
      "vecc_b2 likelihood 2566.1323226707896\n",
      "vecc_b2 likelihood 2566.1323226707896\n",
      "vecc statistic is 4.295006659870506\n",
      "vecc_b2 likelihood 2563.7262156730662\n",
      "vecc_b2 likelihood 2563.7262156730662\n",
      "vecc statistic is 4.92789794545219\n",
      "vecc_b2 likelihood 2563.624953626223\n",
      "vecc_b2 likelihood 2563.624953626223\n",
      "vecc statistic is 5.242287801146139\n",
      "vecc_b2 likelihood 2563.532784455573\n",
      "vecc_b2 likelihood 2563.532784455573\n",
      "vecc statistic is -1.8559311918389358\n",
      "vecc_b2 likelihood 2561.9232868312483\n",
      "vecc_b2 likelihood 2561.9232868312483\n",
      "vecc statistic is 7.17562895976746\n",
      "vecc_b2 likelihood 2562.294788225645\n",
      "vecc_b2 likelihood 2562.294788225645\n",
      "vecc statistic is 5.441139626193181\n",
      "vecc_b2 likelihood 2563.4818904439358\n",
      "vecc_b2 likelihood 2563.4818904439358\n",
      "vecc statistic is 4.767300390127459\n",
      "vecc_b2 likelihood 2563.5303642035256\n",
      "vecc_b2 likelihood 2563.5303642035256\n",
      "vecc statistic is 4.483158723677631\n",
      "vecc_b2 likelihood 2562.98582460322\n",
      "vecc_b2 likelihood 2562.98582460322\n",
      "vecc statistic is 4.460494968756281\n",
      "vecc_b2 likelihood 2563.295364363586\n",
      "vecc_b2 likelihood 2563.295364363586\n",
      "vecc statistic is 4.543040652599179\n",
      "vecc_b2 likelihood 2563.509228232044\n",
      "vecc_b2 likelihood 2563.509228232044\n",
      "vecc statistic is 4.371419465444818\n",
      "vecc_b2 likelihood 2563.8020556556767\n",
      "vecc_b2 likelihood 2563.8020556556767\n",
      "vecc statistic is 4.233463863056291\n",
      "vecc_b2 likelihood 2564.17753447088\n",
      "vecc_b2 likelihood 2564.17753447088\n",
      "vecc statistic is 4.221028772003769\n",
      "vecc_b2 likelihood 2564.5453838298404\n",
      "vecc_b2 likelihood 2564.5453838298404\n",
      "vecc statistic is 4.466741747742357\n"
     ]
    }
   ],
   "source": [
    "for i in range(4,20):\n",
    "    compute_statistic_vecc(params, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vecchia_local_extra_base (condition on past with some base conditioning set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(tensor(110.0250, dtype=torch.float64), tensor(5.0250, dtype=torch.float64)), (tensor(110.0250, dtype=torch.float64), tensor(9.5250, dtype=torch.float64)), (tensor(114.5250, dtype=torch.float64), tensor(5.0250, dtype=torch.float64)), (tensor(114.5250, dtype=torch.float64), tensor(9.5250, dtype=torch.float64)), (tensor(119.5250, dtype=torch.float64), tensor(5.0250, dtype=torch.float64)), (tensor(119.5250, dtype=torch.float64), tensor(9.5250, dtype=torch.float64))]\n",
      "Indices in Tensor Frame:\n",
      "tensor([  1, 145, 160,  50,   2,   4])\n",
      "grad*hessian*grad from <bound method matern_advec_beta_torch_vecchia.vecchia_local_extra_base of <__main__.matern_advec_beta_torch_vecchia object at 0x30823ca40>> is 53.17959587711484\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 71\u001b[39m\n\u001b[32m     68\u001b[39m params = torch.tensor(params, dtype=torch.float64, requires_grad=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m4\u001b[39m,\u001b[32m10\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m     \u001b[43mcompute_statistic_vecc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstance\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvecchia_local_extra_base\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 56\u001b[39m, in \u001b[36mcompute_statistic_vecc\u001b[39m\u001b[34m(params, mm_cond_number, like_function)\u001b[39m\n\u001b[32m     54\u001b[39m gradient = grad_function(params)\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m     hessian_matrix =  \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhessian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompute_loss\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     57\u001b[39m     \u001b[38;5;66;03m# print(hessian_matrix)\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/faiss_env/lib/python3.12/site-packages/torch/_functorch/eager_transforms.py:1310\u001b[39m, in \u001b[36mjacfwd.<locals>.wrapper_fn\u001b[39m\u001b[34m(*args)\u001b[39m\n\u001b[32m   1307\u001b[39m     _, jvp_out = output\n\u001b[32m   1308\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m jvp_out\n\u001b[32m-> \u001b[39m\u001b[32m1310\u001b[39m results = \u001b[43mvmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpush_jvp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbasis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1311\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_aux:\n\u001b[32m   1312\u001b[39m     results, aux = results\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/faiss_env/lib/python3.12/site-packages/torch/_functorch/apis.py:203\u001b[39m, in \u001b[36mvmap.<locals>.wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(*args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvmap_impl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/faiss_env/lib/python3.12/site-packages/torch/_functorch/vmap.py:331\u001b[39m, in \u001b[36mvmap_impl\u001b[39m\u001b[34m(func, in_dims, out_dims, randomness, chunk_size, *args, **kwargs)\u001b[39m\n\u001b[32m    320\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _chunked_vmap(\n\u001b[32m    321\u001b[39m         func,\n\u001b[32m    322\u001b[39m         flat_in_dims,\n\u001b[32m   (...)\u001b[39m\u001b[32m    327\u001b[39m         **kwargs,\n\u001b[32m    328\u001b[39m     )\n\u001b[32m    330\u001b[39m \u001b[38;5;66;03m# If chunk_size is not specified.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_flat_vmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_in_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs_spec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    337\u001b[39m \u001b[43m    \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    338\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    339\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    340\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/faiss_env/lib/python3.12/site-packages/torch/_functorch/vmap.py:479\u001b[39m, in \u001b[36m_flat_vmap\u001b[39m\u001b[34m(func, batch_size, flat_in_dims, flat_args, args_spec, out_dims, randomness, **kwargs)\u001b[39m\n\u001b[32m    475\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m vmap_increment_nesting(batch_size, randomness) \u001b[38;5;28;01mas\u001b[39;00m vmap_level:\n\u001b[32m    476\u001b[39m     batched_inputs = _create_batched_inputs(\n\u001b[32m    477\u001b[39m         flat_in_dims, flat_args, vmap_level, args_spec\n\u001b[32m    478\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m479\u001b[39m     batched_outputs = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mbatched_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    480\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _unwrap_batched(batched_outputs, out_dims, vmap_level, batch_size, func)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/faiss_env/lib/python3.12/site-packages/torch/_functorch/eager_transforms.py:1299\u001b[39m, in \u001b[36mjacfwd.<locals>.wrapper_fn.<locals>.push_jvp\u001b[39m\u001b[34m(basis)\u001b[39m\n\u001b[32m   1298\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpush_jvp\u001b[39m(basis):\n\u001b[32m-> \u001b[39m\u001b[32m1299\u001b[39m     output = \u001b[43m_jvp_with_argnums\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1300\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbasis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margnums\u001b[49m\u001b[43m=\u001b[49m\u001b[43margnums\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhas_aux\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_aux\u001b[49m\n\u001b[32m   1301\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1302\u001b[39m     \u001b[38;5;66;03m# output[0] is the output of `func(*args)`\u001b[39;00m\n\u001b[32m   1303\u001b[39m     error_if_complex(\u001b[33m\"\u001b[39m\u001b[33mjacfwd\u001b[39m\u001b[33m\"\u001b[39m, output[\u001b[32m0\u001b[39m], is_input=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/faiss_env/lib/python3.12/site-packages/torch/_functorch/eager_transforms.py:1139\u001b[39m, in \u001b[36m_jvp_with_argnums\u001b[39m\u001b[34m(func, primals, tangents, argnums, strict, has_aux)\u001b[39m\n\u001b[32m   1137\u001b[39m     primals = _wrap_all_tensors(primals, level)\n\u001b[32m   1138\u001b[39m     duals = _replace_args(primals, duals, argnums)\n\u001b[32m-> \u001b[39m\u001b[32m1139\u001b[39m result_duals = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mduals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1140\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_aux:\n\u001b[32m   1141\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(result_duals, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(result_duals) == \u001b[32m2\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/faiss_env/lib/python3.12/site-packages/torch/_functorch/eager_transforms.py:604\u001b[39m, in \u001b[36mjacrev.<locals>.wrapper_fn\u001b[39m\u001b[34m(*args)\u001b[39m\n\u001b[32m    602\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper_fn\u001b[39m(*args):\n\u001b[32m    603\u001b[39m     error_if_complex(\u001b[33m\"\u001b[39m\u001b[33mjacrev\u001b[39m\u001b[33m\"\u001b[39m, args, is_input=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m604\u001b[39m     vjp_out = \u001b[43m_vjp_with_argnums\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margnums\u001b[49m\u001b[43m=\u001b[49m\u001b[43margnums\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhas_aux\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_aux\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    605\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m has_aux:\n\u001b[32m    606\u001b[39m         output, vjp_fn, aux = vjp_out\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/faiss_env/lib/python3.12/site-packages/torch/_functorch/vmap.py:48\u001b[39m, in \u001b[36mdoesnt_support_saved_tensors_hooks.<locals>.fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(f)\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfn\u001b[39m(*args, **kwargs):\n\u001b[32m     47\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.autograd.graph.disable_saved_tensors_hooks(message):\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/faiss_env/lib/python3.12/site-packages/torch/_functorch/eager_transforms.py:399\u001b[39m, in \u001b[36m_vjp_with_argnums\u001b[39m\u001b[34m(func, argnums, has_aux, *primals)\u001b[39m\n\u001b[32m    397\u001b[39m     diff_primals = _slice_argnums(primals, argnums, as_tuple=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    398\u001b[39m     tree_map_(partial(_create_differentiable, level=level), diff_primals)\n\u001b[32m--> \u001b[39m\u001b[32m399\u001b[39m primals_out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mprimals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_aux:\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(primals_out, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(primals_out) == \u001b[32m2\u001b[39m):\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 49\u001b[39m, in \u001b[36mcompute_statistic_vecc.<locals>.compute_loss\u001b[39m\u001b[34m(params)\u001b[39m\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_loss\u001b[39m(params):\n\u001b[32m     48\u001b[39m     \u001b[38;5;66;03m# return instance.vecchia_like_local_computer(params, instance.matern_cov_ani)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m     ll = \u001b[43mlike_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstance\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmatern_cov_ani\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m     \u001b[38;5;66;03m# print(f'likelihood {ll}')\u001b[39;00m\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ll\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 336\u001b[39m, in \u001b[36mmatern_advec_beta_torch_vecchia.vecchia_local_extra_base\u001b[39m\u001b[34m(self, params, covariance_function)\u001b[39m\n\u001b[32m    334\u001b[39m sigma = cov_matrix[\u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m]\n\u001b[32m    335\u001b[39m cov_xx = cov_matrix[\u001b[32m1\u001b[39m:, \u001b[32m1\u001b[39m:]\n\u001b[32m--> \u001b[39m\u001b[32m336\u001b[39m cov_xx_inv = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinalg\u001b[49m\u001b[43m.\u001b[49m\u001b[43minv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcov_xx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    338\u001b[39m cov_ygivenx = sigma - torch.matmul(cov_yx, torch.matmul(cov_xx_inv, cov_yx))\n\u001b[32m    339\u001b[39m cond_mean_tmp = torch.matmul(cov_yx, cov_xx_inv)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "sd = analysis_data_map['2024_07_y24m07day01_hm01:00']\n",
    "# Compute the required statistics\n",
    "# Compute the required statistics\n",
    "max_lat = torch.max(sd[:, 0])\n",
    "min_lat = torch.min(sd[:, 0])\n",
    "median_lat = torch.median(sd[:, 0])\n",
    "\n",
    "max_lon = torch.max(sd[:, 1])\n",
    "min_lon = torch.min(sd[:, 1])\n",
    "median_lon = torch.median(sd[:, 1])\n",
    "\n",
    "# Extract the 9 points along with their locations (indices)\n",
    "points = [\n",
    "    (min_lon, min_lat),\n",
    "    #(min_lon, median_lat),\n",
    "    (min_lon, max_lat),\n",
    "    (median_lon, min_lat),\n",
    "    #(median_lon, median_lat),\n",
    "    (median_lon, max_lat),\n",
    "    (max_lon, min_lat),\n",
    "    #(max_lon, median_lat),\n",
    "    (max_lon, max_lat)\n",
    "]\n",
    "print(points)\n",
    "\n",
    "indices = []\n",
    "for lon, lat in points:\n",
    "    condition = (sd[:, 0] == lat) & (sd[:, 1] == lon)\n",
    "    indices.append(torch.where(condition)[0])\n",
    "\n",
    "# Create the indices tensor\n",
    "indices_tensor = torch.cat(indices)\n",
    "\n",
    "print(\"Indices in Tensor Frame:\")\n",
    "print(indices_tensor)\n",
    "\n",
    "base_list = indices_tensor.clone().detach().tolist()\n",
    "\n",
    "def compute_statistic_vecc(params, mm_cond_number):\n",
    "    instance = load_data_local_computer()\n",
    "    map, ord_mm, nns_map= instance.load_mm20k_data_bymonthyear( lat_lon_resolution= lat_lon_resolution, mm_cond_number=mm_cond_number,years_=years, months_=month_range)\n",
    "    analysis_data_map, aggregated_data = instance.load_working_data_byday( map, ord_mm, nns_map, idx_for_datamap= idx_for_datamap)\n",
    "    instance = matern_advec_beta_torch_vecchia(analysis_data_map, params, nns_map, mm_cond_number)\n",
    "    \n",
    "    # Define the function to compute the loss\n",
    "    def compute_loss(params):\n",
    "        # return instance.vecchia_like_local_computer(params, instance.matern_cov_ani)\n",
    "        ll = instance.vecchia_local_extra_base(params, instance.matern_cov_ani)\n",
    "        print(f'likelihood {ll}')\n",
    "        return ll\n",
    "\n",
    "    grad_function = torch.func.grad(compute_loss)\n",
    "    gradient = grad_function(params)\n",
    "    try:\n",
    "        hessian_matrix =  torch.func.hessian(compute_loss)(params)\n",
    "        # print(hessian_matrix)\n",
    "    except Exception as e:\n",
    "        print(f'Error computing Hessian: {e}')\n",
    "\n",
    "    statistic  = torch.matmul(gradient, torch.linalg.solve(hessian_matrix, gradient))\n",
    "    # statistic  = torch.linalg.solve(hessian_matrix, gradient)\n",
    "    # print(f' statistic is {statistic}')\n",
    "    print(f'vecc statistic is {statistic}')\n",
    "    return statistic\n",
    "\n",
    "params = [ 27.25, 2.18, 2.294, 4.099e-4, -0.07915, 0.0999, 3.65]   #200\n",
    "params = torch.tensor(params, dtype=torch.float64, requires_grad=True)\n",
    "\n",
    "for i in range(4,10):\n",
    "    compute_statistic_vecc(params, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[(tensor(110.0250, dtype=torch.float64), tensor(5.0250, dtype=torch.float64)), (tensor(110.0250, dtype=torch.float64), tensor(9.5250, dtype=torch.float64)), (tensor(114.5250, dtype=torch.float64), tensor(5.0250, dtype=torch.float64)), (tensor(114.5250, dtype=torch.float64), tensor(9.5250, dtype=torch.float64)), (tensor(119.5250, dtype=torch.float64), tensor(5.0250, dtype=torch.float64)), (tensor(119.5250, dtype=torch.float64), tensor(9.5250, dtype=torch.float64))]\n",
    "Indices in Tensor Frame:\n",
    "tensor([  1, 145, 160,  50,   2,   4])\n",
    "vecc statistic is 59.01199704244943\n",
    "vecc statistic is 59.449997640819724\n",
    "vecc statistic is 52.416180825260284\n",
    "vecc statistic is 52.62143386846466\n",
    "vecc statistic is 52.21418603035472\n",
    "vecc statistic is 55.220113253939715"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor(110.0250), tensor(5.0250)),\n",
       " (tensor(112.2750), tensor(5.0250)),\n",
       " (tensor(114.5250), tensor(5.0250)),\n",
       " (tensor(116.7750), tensor(5.0250)),\n",
       " (tensor(119.0250), tensor(5.0250)),\n",
       " (tensor(110.0250), tensor(6.0250)),\n",
       " (tensor(112.2750), tensor(6.0250)),\n",
       " (tensor(114.5250), tensor(6.0250)),\n",
       " (tensor(116.7750), tensor(6.0250)),\n",
       " (tensor(119.0250), tensor(6.0250)),\n",
       " (tensor(110.0250), tensor(7.0250)),\n",
       " (tensor(112.2750), tensor(7.0250)),\n",
       " (tensor(114.5250), tensor(7.0250)),\n",
       " (tensor(116.7750), tensor(7.0250)),\n",
       " (tensor(119.0250), tensor(7.0250)),\n",
       " (tensor(110.0250), tensor(8.0250)),\n",
       " (tensor(112.2750), tensor(8.0250)),\n",
       " (tensor(114.5250), tensor(8.0250)),\n",
       " (tensor(116.7750), tensor(8.0250)),\n",
       " (tensor(119.0250), tensor(8.0250)),\n",
       " (tensor(110.0250), tensor(9.0250)),\n",
       " (tensor(112.2750), tensor(9.0250)),\n",
       " (tensor(114.5250), tensor(9.0250)),\n",
       " (tensor(116.7750), tensor(9.0250)),\n",
       " (tensor(119.0250), tensor(9.0250))]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_points =5\n",
    "max_lat, min_lat, median_lat, max_lon, min_lon, median_lon = compute_statistics(sd)\n",
    "\n",
    "lat_points = torch.linspace(min_lat, max_lat, num_points)\n",
    "lon_points = torch.linspace(min_lon, max_lon, num_points)\n",
    "\n",
    "points = [(lon, lat) for lat in lat_points for lon in lon_points]\n",
    "\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([], dtype=torch.int64)\n",
      "tensor([], dtype=torch.int64)\n",
      "tensor([], dtype=torch.int64)\n",
      "tensor([], dtype=torch.int64)\n",
      "tensor([], dtype=torch.int64)\n",
      "tensor([], dtype=torch.int64)\n",
      "tensor([], dtype=torch.int64)\n",
      "tensor([], dtype=torch.int64)\n",
      "tensor([], dtype=torch.int64)\n",
      "tensor([], dtype=torch.int64)\n",
      "tensor([], dtype=torch.int64)\n",
      "tensor([], dtype=torch.int64)\n",
      "tensor([], dtype=torch.int64)\n",
      "tensor([], dtype=torch.int64)\n",
      "tensor([], dtype=torch.int64)\n",
      "tensor([], dtype=torch.int64)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sd = analysis_data_map['2024_07_y24m07day01_hm01:00']\n",
    "num_points = 4\n",
    "indices_tensor = get_indices(sd, num_points)\n",
    "base_list = indices_tensor.clone().detach().tolist()\n",
    "\n",
    "\n",
    "for i in range(4,20):\n",
    "    num_points = i\n",
    "    indices_tensor = get_indices(sd, num_points)\n",
    "    print(indices_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vecc statistic is 61.74867066606819\n",
      "vecc statistic is 61.74867066606819\n",
      "vecc statistic is 61.74867066606819\n",
      "vecc statistic is 61.74867066606819\n",
      "vecc statistic is 61.74867066606819\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[50]\u001b[39m\u001b[32m, line 42\u001b[39m\n\u001b[32m     39\u001b[39m indices_tensor = get_indices(sd, num_points)\n\u001b[32m     40\u001b[39m base_list = indices_tensor.clone().detach().tolist()\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m \u001b[43mcompute_statistic_vecc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[48]\u001b[39m\u001b[32m, line 51\u001b[39m, in \u001b[36mcompute_statistic_vecc\u001b[39m\u001b[34m(params, mm_cond_number)\u001b[39m\n\u001b[32m     48\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m instance.vecchia_local_extra_base(params, instance.matern_cov_ani)\n\u001b[32m     50\u001b[39m grad_function = torch.func.grad(compute_loss)\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m gradient = \u001b[43mgrad_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     53\u001b[39m     hessian_matrix =  torch.func.hessian(compute_loss)(params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/faiss_env/lib/python3.12/site-packages/torch/_functorch/apis.py:399\u001b[39m, in \u001b[36mgrad.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    398\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m399\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43meager_transforms\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgrad_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margnums\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhas_aux\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/faiss_env/lib/python3.12/site-packages/torch/_functorch/eager_transforms.py:1449\u001b[39m, in \u001b[36mgrad_impl\u001b[39m\u001b[34m(func, argnums, has_aux, args, kwargs)\u001b[39m\n\u001b[32m   1448\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgrad_impl\u001b[39m(func: Callable, argnums: argnums_t, has_aux: \u001b[38;5;28mbool\u001b[39m, args, kwargs):\n\u001b[32m-> \u001b[39m\u001b[32m1449\u001b[39m     results = \u001b[43mgrad_and_value_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margnums\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhas_aux\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1450\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m has_aux:\n\u001b[32m   1451\u001b[39m         grad, (_, aux) = results\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/faiss_env/lib/python3.12/site-packages/torch/_functorch/vmap.py:48\u001b[39m, in \u001b[36mdoesnt_support_saved_tensors_hooks.<locals>.fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(f)\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfn\u001b[39m(*args, **kwargs):\n\u001b[32m     47\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.autograd.graph.disable_saved_tensors_hooks(message):\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/faiss_env/lib/python3.12/site-packages/torch/_functorch/eager_transforms.py:1407\u001b[39m, in \u001b[36mgrad_and_value_impl\u001b[39m\u001b[34m(func, argnums, has_aux, args, kwargs)\u001b[39m\n\u001b[32m   1404\u001b[39m diff_args = _slice_argnums(args, argnums, as_tuple=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1405\u001b[39m tree_map_(partial(_create_differentiable, level=level), diff_args)\n\u001b[32m-> \u001b[39m\u001b[32m1407\u001b[39m output = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1408\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_aux:\n\u001b[32m   1409\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(output, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(output) == \u001b[32m2\u001b[39m):\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[48]\u001b[39m\u001b[32m, line 48\u001b[39m, in \u001b[36mcompute_statistic_vecc.<locals>.compute_loss\u001b[39m\u001b[34m(params)\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_loss\u001b[39m(params):\n\u001b[32m     47\u001b[39m     \u001b[38;5;66;03m# return instance.vecchia_like_local_computer(params, instance.matern_cov_ani)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minstance\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvecchia_local_extra_base\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstance\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmatern_cov_ani\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 286\u001b[39m, in \u001b[36mmatern_advec_beta_torch_vecchia.vecchia_local_extra_base\u001b[39m\u001b[34m(self, params, covariance_function)\u001b[39m\n\u001b[32m    284\u001b[39m y_arr = y_and_neighbors\n\u001b[32m    285\u001b[39m tmp1 = tmp_for_beta\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m tmp2 = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinalg\u001b[49m\u001b[43m.\u001b[49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcov_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_arr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    287\u001b[39m beta = torch.linalg.solve(tmp1, tmp2)\n\u001b[32m    289\u001b[39m mu = torch.matmul(locs, beta)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def compute_statistics(sd):\n",
    "    max_lat = torch.max(sd[:, 0])\n",
    "    min_lat = torch.min(sd[:, 0])\n",
    "    median_lat = torch.median(sd[:, 0])\n",
    "\n",
    "    max_lon = torch.max(sd[:, 1])\n",
    "    min_lon = torch.min(sd[:, 1])\n",
    "    median_lon = torch.median(sd[:, 1])\n",
    "\n",
    "    return max_lat, min_lat, median_lat, max_lon, min_lon, median_lon\n",
    "\n",
    "\n",
    "def get_indices(sd, num_points):\n",
    "    max_lat, min_lat, median_lat, max_lon, min_lon, median_lon = compute_statistics(sd)\n",
    "    \n",
    "    lat_points = torch.linspace(min_lat, max_lat, num_points)\n",
    "    lon_points = torch.linspace(min_lon, max_lon, num_points)\n",
    "    \n",
    "    points = [(lon, lat) for lat in lat_points for lon in lon_points]\n",
    "    \n",
    "    indices = []\n",
    "    for lon, lat in points:\n",
    "        condition = (sd[:, 0] == lat) & (sd[:, 1] == lon)\n",
    "        indices.append(torch.where(condition)[0])\n",
    "    \n",
    "    indices_tensor = torch.cat(indices)\n",
    "    \n",
    "    return indices_tensor\n",
    "\n",
    "# Example usage\n",
    "sd = analysis_data_map['2024_07_y24m07day01_hm01:00']\n",
    "num_points = 4\n",
    "indices_tensor = get_indices(sd, num_points)\n",
    "base_list = indices_tensor.clone().detach().tolist()\n",
    "\n",
    "\n",
    "for i in range(4,20):\n",
    "    num_points = i\n",
    "    indices_tensor = get_indices(sd, num_points)\n",
    "    base_list = indices_tensor.clone().detach().tolist()\n",
    "\n",
    "    compute_statistic_vecc(params, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "faiss_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
