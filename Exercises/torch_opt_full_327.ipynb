{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "gems_tco_path = \"/Users/joonwonlee/Documents/GEMS_TCO-1/src\"\n",
    "sys.path.append(gems_tco_path)\n",
    "\n",
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle \n",
    "\n",
    "import GEMS_TCO\n",
    "from GEMS_TCO import kernels \n",
    "from GEMS_TCO import orderings as _orderings\n",
    "from GEMS_TCO import load_data\n",
    "\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import copy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_lon_resolution = [20,20]\n",
    "mm_cond_number = 10\n",
    "params= [20, 8.25, 5.25, 0.2, 0.5, 5]\n",
    "idx_for_datamap= [0,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the one dictionary to set spaital coordinates\n",
    "# filepath = \"C:/Users/joonw/TCO/GEMS_data/data_2023/sparse_cen_map23_01.pkl\"\n",
    "filepath = \"/Users/joonwonlee/Documents/GEMS_DATA/pickle_2023/coarse_cen_map23_01.pkl\"\n",
    "with open(filepath, 'rb') as pickle_file:\n",
    "    coarse_dict_24_1 = pickle.load(pickle_file)\n",
    "\n",
    "sample_df = coarse_dict_24_1['y23m01day01_hm02:12']\n",
    "sample_key = coarse_dict_24_1.get('y23m01day01_hm02:12')\n",
    "if sample_key is None:\n",
    "    print(\"Key 'y23m01day01_hm02:12' not found in the dictionary.\")\n",
    "\n",
    "# { (20,20):(5,1), (5,5):(20,40) }\n",
    "rho_lat = lat_lon_resolution[0]          \n",
    "rho_lon = lat_lon_resolution[1]\n",
    "lat_n = sample_df['Latitude'].unique()[::rho_lat]\n",
    "lon_n = sample_df['Longitude'].unique()[::rho_lon]\n",
    "\n",
    "lat_number = len(lat_n)\n",
    "lon_number = len(lon_n)\n",
    "\n",
    "# Set spatial coordinates for each dataset\n",
    "coarse_dicts = {}\n",
    "\n",
    "years = ['2024']\n",
    "for year in years:\n",
    "    for month in range(7, 8):  # Iterate over all months\n",
    "        # filepath = f\"C:/Users/joonw/TCO/GEMS_data/data_{year}/sparse_cen_map{year[2:]}_{month:02d}.pkl\"\n",
    "        filepath = f\"/Users/joonwonlee/Documents/GEMS_DATA/pickle_{year}/coarse_cen_map{year[2:]}_{month:02d}.pkl\"\n",
    "        with open(filepath, 'rb') as pickle_file:\n",
    "            loaded_map = pickle.load(pickle_file)\n",
    "            for key in loaded_map:\n",
    "                tmp_df = loaded_map[key]\n",
    "                coarse_filter = (tmp_df['Latitude'].isin(lat_n)) & (tmp_df['Longitude'].isin(lon_n))\n",
    "                coarse_dicts[f\"{year}_{month:02d}_{key}\"] = tmp_df[coarse_filter].reset_index(drop=True)\n",
    "\n",
    "key_idx = list( coarse_dicts.keys() )\n",
    "if not key_idx:\n",
    "    raise ValueError(\"coarse_dicts is empty\")\n",
    "\n",
    "# extract first hour data because all data shares the same spatial grid\n",
    "data_for_coord = coarse_dicts[key_idx[0]]\n",
    "x1 = data_for_coord['Longitude'].values\n",
    "y1 = data_for_coord['Latitude'].values \n",
    "coords1 = np.stack((x1, y1), axis=-1)\n",
    "\n",
    "\n",
    "# instance = orbitmap.MakeOrbitdata(data_for_coord, lat_s=5, lat_e=10, lon_s=110, lon_e=120)\n",
    "# s_dist = cdist(coords1, coords1, 'euclidean')\n",
    "# ord_mm, _ = instance.maxmin_naive(s_dist, 0)\n",
    "\n",
    "ord_mm = _orderings.maxmin_cpp(coords1)\n",
    "data_for_coord = data_for_coord.iloc[ord_mm].reset_index(drop=True)\n",
    "coords1_reordered = np.stack((data_for_coord['Longitude'].values, data_for_coord['Latitude'].values), axis=-1)\n",
    "# nns_map = instance.find_nns_naive(locs=coords1_reordered, dist_fun='euclidean', max_nn=mm_cond_number)\n",
    "nns_map=_orderings.find_nns_l2(locs= coords1_reordered  ,max_nn = mm_cond_number)\n",
    "\n",
    "\n",
    "analysis_data_map = {}\n",
    "for i in range(idx_for_datamap[0],idx_for_datamap[1]):\n",
    "    tmp = coarse_dicts[key_idx[i]].copy()\n",
    "    tmp['Hours_elapsed'] = np.round(tmp['Hours_elapsed']-477700)\n",
    "\n",
    "    tmp = tmp.iloc[ord_mm, :4].to_numpy()\n",
    "    tmp = torch.from_numpy(tmp).double()  # Convert NumPy to Tensor\n",
    "    # tmp = tmp.clone().detach().requires_grad_(True)  # Enable gradients\n",
    "    \n",
    "    analysis_data_map[key_idx[i]] = tmp\n",
    "\n",
    "aggregated_data = pd.DataFrame()\n",
    "for i in range(idx_for_datamap[0],idx_for_datamap[1]):\n",
    "    tmp = coarse_dicts[key_idx[i]].copy()\n",
    "    tmp['Hours_elapsed'] = np.round(tmp['Hours_elapsed']-477700)\n",
    "    tmp = tmp.iloc[ord_mm].reset_index(drop=True)  \n",
    "    aggregated_data = pd.concat((aggregated_data, tmp), axis=0)\n",
    "\n",
    "aggregated_data = aggregated_data.iloc[:, :4].to_numpy()\n",
    "\n",
    "\n",
    "aggregated_data = torch.from_numpy(aggregated_data).double()  # Convert NumPy to Tensor\n",
    "# aggregated_np = aggregated_np.clone().detach().requires_grad_(True)  # Enable gradients\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Gradients: [   -7.12808734  -422.33365962  -633.95397821   223.63099248\n",
      " -1242.94883333  4342.84355591  -168.82206927]\n",
      " Loss: 876.6676864038084, Parameters: [23.09    2.24    3.2927 -0.107   0.1659  0.1612  1.6049]\n",
      "Epoch 11, Gradients: [-7.50180789e+00 -1.93382965e+03 -2.87630169e+03  4.70085275e+05\n",
      "  1.19224082e+05  1.60005008e+04 -6.46036130e+02]\n",
      " Loss: 1812.9022785826803, Parameters: [2.33916678e+01 2.52331985e+00 3.49616626e+00 9.03205155e-03\n",
      " 4.20710422e-01 4.26896121e-05 1.90835434e+00]\n",
      "Epoch 21, Gradients: [-5.79605970e+00 -1.39373063e+02 -1.30209721e+03  8.04208382e+04\n",
      "  1.79567481e+05 -9.41801690e+05 -3.94618846e+02]\n",
      " Loss: 1440.1109794636309, Parameters: [ 2.36918819e+01  2.72822235e+00  3.75605044e+00  2.99442658e-03\n",
      "  3.52090921e-01 -4.18449028e-03  2.22190710e+00]\n",
      "Epoch 31, Gradients: [-4.26444857e+00 -2.19147552e+02 -1.66695563e+02  9.85280900e+02\n",
      " -5.61437546e+03  2.16664800e+04 -1.17243597e+02]\n",
      " Loss: 858.2621456524253, Parameters: [2.39557869e+01 2.83659460e+00 3.96155601e+00 2.08477003e-02\n",
      " 2.44483631e-01 6.57466205e-02 2.49404094e+00]\n",
      "Epoch 41, Gradients: [-3.83153682e+00 -2.51615007e+02 -2.10170518e+02  2.00892889e+02\n",
      " -2.90477622e+03  5.53592597e+03 -9.00014589e+01]\n",
      " Loss: 813.8416459796108, Parameters: [24.18666263  2.91850807  4.06859483  0.02906201  0.22764149  0.08936603\n",
      "  2.67577348]\n",
      "Epoch 51, Gradients: [   -3.57390592  -252.90154896  -197.82734171    92.01181066\n",
      " -2435.11958238  2828.65556577   -79.59153795]\n",
      " Loss: 800.0315884045044, Parameters: [24.40152474  3.00203437  4.15093728  0.03193004  0.23507961  0.09706311\n",
      "  2.80976738]\n",
      "Epoch 61, Gradients: [   -3.38246792  -248.75243689  -176.43803783    92.59335674\n",
      " -2349.24940094  2126.82924083   -73.49712111]\n",
      " Loss: 793.3321488747636, Parameters: [24.61003246  3.09214231  4.22541154  0.03285011  0.25127261  0.09912532\n",
      "  2.92345694]\n",
      "Epoch 71, Gradients: [   -3.22193847  -243.10869708  -152.05919199   129.71146037\n",
      " -2370.19894885  2051.41962717   -68.98016243]\n",
      " Loss: 789.1686386443243, Parameters: [24.81663745  3.18927309  4.29595382  0.03297141  0.27182167  0.09911122\n",
      "  3.02988435]\n",
      "Epoch 81, Gradients: [   -3.07965845  -236.54978895  -126.03925793   186.66752193\n",
      " -2425.12888699  2296.84824249   -65.19770057]\n",
      " Loss: 786.2357523834387, Parameters: [25.02309373  3.29288649  4.36241936  0.03265458  0.2955893   0.09822934\n",
      "  3.1347281 ]\n",
      "Epoch 91, Gradients: [   -2.95158062  -228.98194498   -98.63538035   259.603783\n",
      " -2492.49801076  2801.88286036   -61.87276153]\n",
      " Loss: 784.1686283107827, Parameters: [25.2299457   3.40218463  4.42323615  0.03196498  0.32241362  0.09681053\n",
      "  3.24026729]\n",
      "Epoch 101, Gradients: [-2.83744499e+00 -2.20114712e+02 -6.96702442e+01  3.49222408e+02\n",
      " -2.56798010e+03  3.59518363e+03 -5.89266818e+01]\n",
      " Loss: 782.960796127298, Parameters: [25.43731205  3.51622281  4.47621847  0.03084744  0.35241988  0.09482904\n",
      "  3.34733742]\n",
      "Epoch 111, Gradients: [-2.74842052e+00 -2.10608969e+02 -4.16565942e+01  4.48285626e+02\n",
      " -2.64684357e+03  4.64684452e+03 -5.66066789e+01]\n",
      " Loss: 782.8027968099004, Parameters: [25.62456856  3.62217177  4.51467544  0.0293566   0.38248732  0.0923566\n",
      "  3.44541182]\n",
      "Epoch 121, Gradients: [-2.67600882e+00 -1.99056924e+02 -1.08935113e+01  5.72452301e+02\n",
      " -2.74250437e+03  6.18236452e+03 -5.46533451e+01]\n",
      " Loss: 783.9054780147142, Parameters: [25.81295582  3.73044873  4.54181066  0.0272548   0.41586341  0.08890462\n",
      "  3.5455731 ]\n",
      "Epoch 131, Gradients: [-2.62741787e+00 -1.84549303e+02  2.38158701e+01  7.35747451e+02\n",
      " -2.86258133e+03  8.51017062e+03 -5.31946051e+01]\n",
      " Loss: 786.9996425250029, Parameters: [2.60030812e+01 3.83966924e+00 4.55464572e+00 2.43509150e-02\n",
      " 4.52921189e-01 8.39897664e-02 3.64818262e+00]\n",
      "Epoch 141, Gradients: [-2.61802218e+00 -1.65424940e+02  6.43270740e+01  9.68839866e+02\n",
      " -3.01593486e+03  1.23386103e+04 -5.25389145e+01]\n",
      " Loss: 793.7277101474858, Parameters: [2.61959556e+01 3.94780476e+00 4.54900698e+00 2.03422273e-02\n",
      " 4.94201179e-01 7.67739960e-02 3.75381851e+00]\n",
      "Epoch 151, Gradients: [-2.68704641e+00 -1.38498420e+02  1.12571108e+02  1.34650980e+03\n",
      " -3.19741095e+03  1.96482790e+04 -5.35320454e+01]\n",
      " Loss: 808.495192786994, Parameters: [2.63935940e+01 4.05170758e+00 4.51917782e+00 1.47021114e-02\n",
      " 5.40435941e-01 6.56320086e-02 3.86371758e+00]\n",
      "Epoch 161, Gradients: [-3.03436123e+00 -9.77515689e+01  1.60550232e+02  2.06099884e+03\n",
      " -3.28175213e+03  3.86490041e+04 -5.91492271e+01]\n",
      " Loss: 848.551066580638, Parameters: [2.66007779e+01 4.14606919e+00 4.45807291e+00 6.36445974e-03\n",
      " 5.92309438e-01 4.66547326e-02 3.98098044e+00]\n",
      "Epoch 171, Gradients: [-6.58777662e+00 -2.19755943e+02 -4.19424755e+02 -5.26189413e+04\n",
      " -8.74466911e+04 -4.79649411e+05 -1.54910988e+02]\n",
      " Loss: 1344.6410538285013, Parameters: [ 2.68472946e+01  4.21880996e+00  4.36304245e+00 -5.17457173e-03\n",
      "  6.51732153e-01 -2.55394950e-03  4.11729339e+00]\n",
      "Epoch 181, Gradients: [-7.97401025e+00 -1.48638541e+02 -6.59618121e+02 -6.66788985e+03\n",
      " -1.49816490e+05  5.79276630e+05 -1.65999330e+02]\n",
      " Loss: 1481.0459614239467, Parameters: [2.72171113e+01 4.29357663e+00 4.38338293e+00 2.07694707e-04\n",
      " 7.89141015e-01 1.33173497e-03 4.35436390e+00]\n",
      "Epoch 191, Gradients: [-7.31653675e+00 -1.68190981e+02 -2.32297115e+02  5.52250916e+04\n",
      " -8.23092867e+04 -9.86732684e+05 -1.48922987e+02]\n",
      " Loss: 1445.4205716080078, Parameters: [ 2.76484912e+01  4.35650339e+00  4.43769693e+00  2.98689738e-03\n",
      "  7.94250139e-01 -2.18054591e-03  4.63814697e+00]\n",
      "Epoch 201, Gradients: [-5.60847167e+00 -2.48036928e+02 -2.95649568e+02  7.25694430e+04\n",
      " -7.33034855e+04  5.38623069e+05 -1.33428024e+02]\n",
      " Loss: 1375.7372249078467, Parameters: [2.80549936e+01 4.42306670e+00 4.46702820e+00 7.43546463e-03\n",
      " 7.39156184e-01 2.16889685e-03 4.91696638e+00]\n",
      "Epoch 211, Gradients: [-5.74517702e+00 -1.16311495e+02 -2.08982623e+02 -2.66717371e+04\n",
      " -2.20255590e+04  3.91644209e+05 -1.03770363e+02]\n",
      " Loss: 1268.601645109369, Parameters: [ 2.83661779e+01  4.50639370e+00  4.53736739e+00 -4.37287709e-03\n",
      "  7.25835329e-01  3.34033675e-03  5.15696407e+00]\n",
      "Epoch 221, Gradients: [-5.13388834e+00 -8.56237443e+01 -1.79005034e+02  3.66821667e+03\n",
      " -1.48094194e+04  4.29143681e+05 -9.99806441e+01]\n",
      " Loss: 1262.8356687890778, Parameters: [2.86314233e+01 4.60313249e+00 4.68763142e+00 2.32757988e-03\n",
      " 7.20391645e-01 3.45420571e-03 5.38448972e+00]\n",
      "Epoch 231, Gradients: [-5.78769474e+00 -2.53430631e+01  2.03366411e+02  8.58882681e+03\n",
      " -6.87864603e+03 -4.59550218e+05 -8.17793624e+01]\n",
      " Loss: 1209.4755111047145, Parameters: [ 2.88730622e+01  4.71478135e+00  4.84198979e+00  6.57702946e-03\n",
      "  7.43640218e-01 -6.65721202e-03  5.60066177e+00]\n",
      "Epoch 241, Gradients: [-4.59645670e+00 -1.29250288e+02 -5.74009688e+01  9.76945841e+04\n",
      " -2.93819730e+04  1.73411733e+06 -9.35136031e+01]\n",
      " Loss: 1266.2313481465217, Parameters: [2.91110952e+01 4.81195541e+00 4.91679069e+00 1.39511628e-03\n",
      " 7.49624265e-01 9.71272426e-04 5.80052872e+00]\n",
      "Epoch 251, Gradients: [-5.27891635e+00 -7.69725603e+01  9.61515613e+01  1.71708718e+04\n",
      "  7.41961209e+02 -6.31366541e+05 -8.60378494e+01]\n",
      " Loss: 1265.9874943087477, Parameters: [ 2.93494996e+01  4.89328847e+00  4.94060587e+00  4.49503809e-03\n",
      "  7.97131626e-01 -3.90998278e-03  5.98557901e+00]\n",
      "Epoch 261, Gradients: [-4.58693581e+00 -1.64081188e+02 -2.13134892e+02 -6.14074778e+04\n",
      "  6.29349382e+04  2.63221844e+05 -7.76748454e+01]\n",
      " Loss: 1216.0151749538568, Parameters: [ 2.95891770e+01  4.98492569e+00  4.96126019e+00 -6.27790078e-03\n",
      "  7.61700534e-01  1.09132628e-03  6.16971954e+00]\n",
      "Epoch 271, Gradients: [-1.33465204e+00 -7.39326986e+01  7.54613022e+01  4.34435189e+02\n",
      " -1.29760599e+03  4.04189981e+03 -1.18172077e+01]\n",
      " Loss: 729.8925283717217, Parameters: [29.79386152  5.07267956  4.98164754  0.1191452   0.59500321  0.07748845\n",
      "  6.31662204]\n",
      "Epoch 281, Gradients: [  -1.05026132  -89.12303388   29.0148363    28.73533099 -786.48047224\n",
      " -555.95550196   -9.57458793]\n",
      " Loss: 714.080091732786, Parameters: [29.9153076   5.15151606  4.94665491  0.16941837  0.52931406  0.10897366\n",
      "  6.39082887]\n",
      "Epoch 291, Gradients: [-9.79448495e-01 -9.11787371e+01  1.85626325e+01 -3.92733404e+01\n",
      " -6.41816087e+02 -1.19165465e+03 -9.07872315e+00]\n",
      " Loss: 711.7193909708426, Parameters: [29.99485502  5.24280488  4.91637807  0.18779672  0.50642444  0.12070178\n",
      "  6.43379662]\n",
      "Epoch 301, Gradients: [-9.52280977e-01 -9.17795620e+01  1.64576730e+01 -5.27234981e+01\n",
      " -5.91160617e+02 -1.36247321e+03 -8.90313519e+00]\n",
      " Loss: 711.3587493608734, Parameters: [30.05827082  5.34315031  4.89363826  0.19468202  0.49909813  0.12540809\n",
      "  6.46522371]\n",
      "Epoch 311, Gradients: [-9.39263811e-01 -9.20815729e+01  1.67705087e+01 -5.22122355e+01\n",
      " -5.71224844e+02 -1.42501969e+03 -8.82868615e+00]\n",
      " Loss: 711.4970014660121, Parameters: [30.11070843  5.4394581   4.87636157  0.19712482  0.49762759  0.12739382\n",
      "  6.49015725]\n",
      "Epoch 321, Gradients: [-9.29832693e-01 -9.22898354e+01  1.78419264e+01 -4.77482350e+01\n",
      " -5.59697308e+02 -1.46068623e+03 -8.78123328e+00]\n",
      " Loss: 711.7926906798295, Parameters: [30.16258794  5.54082427  4.85954664  0.19819499  0.49805723  0.12859677\n",
      "  6.51450202]\n",
      "Epoch 331, Gradients: [-9.21354789e-01 -9.24231384e+01  1.92111999e+01 -4.19565936e+01\n",
      " -5.50912357e+02 -1.48659837e+03 -8.74182424e+00]\n",
      " Loss: 712.1547427039761, Parameters: [30.21556601  5.64687758  4.84164126  0.19875416  0.49921661  0.12954979\n",
      "  6.53934794]\n",
      "Epoch 341, Gradients: [-9.12868892e-01 -9.24800316e+01  2.07224229e+01 -3.57391294e+01\n",
      " -5.42910376e+02 -1.50792816e+03 -8.70352098e+00]\n",
      " Loss: 712.5521798474, Parameters: [30.27031948  5.75745997  4.82177017  0.19911296  0.50068102  0.13044772\n",
      "  6.56513978]\n",
      "Epoch 351, Gradients: [-9.03999730e-01 -9.24546560e+01  2.23224401e+01 -2.94337236e+01\n",
      " -5.35008818e+02 -1.52613334e+03 -8.66361510e+00]\n",
      " Loss: 712.9738457441936, Parameters: [30.32713259  5.87247732  4.79938117  0.19938205  0.5022968   0.13136276\n",
      "  6.59207491]\n",
      "Epoch 361, Gradients: [-8.94582433e-01 -9.23402401e+01  2.39938316e+01 -2.31856283e+01\n",
      " -5.26975611e+02 -1.54143560e+03 -8.62092253e+00]\n",
      " Loss: 713.4154127330623, Parameters: [30.38612987  5.99184115  4.77405735  0.1995996   0.50400877  0.13232246\n",
      "  6.6202558 ]\n",
      "Epoch 371, Gradients: [-8.84528070e-01 -9.21300674e+01  2.57319693e+01 -1.70727775e+01\n",
      " -5.18740139e+02 -1.55363395e+03 -8.57481023e+00]\n",
      " Loss: 713.8749096519164, Parameters: [30.44736775  6.1154462   4.74542638  0.19977752  0.50579748  0.13333801\n",
      "  6.64974822]\n",
      "Epoch 381, Gradients: [-8.73775054e-01 -9.18178027e+01  2.75371496e+01 -1.11484729e+01\n",
      " -5.10291264e+02 -1.56238280e+03 -8.52484440e+00]\n",
      " Loss: 714.3511630422435, Parameters: [30.51086989  6.24316214  4.71311849  0.19991827  0.50765642  0.13441443\n",
      "  6.68060341]\n",
      "Epoch 391, Gradients: [-8.62271659e-01 -9.13976269e+01  2.94119793e+01 -5.45555846e+00\n",
      " -5.01641183e+02 -1.56729066e+03 -8.47066591e+00]\n",
      " Loss: 714.8432750038213, Parameters: [30.57664044  6.37483101  4.67674693  0.20002103  0.50958374  0.13555425\n",
      "  6.71286627]\n",
      "Epoch 401, Gradients: [-8.49969884e-01 -9.08642978e+01  3.13606113e+01 -3.07106265e-02\n",
      " -4.92812501e+02 -1.56795760e+03 -8.41194988e+00]\n",
      " Loss: 715.3504810592317, Parameters: [30.64466837  6.51026715  4.6358985   0.20008391  0.51157928  0.13675872\n",
      "  6.74657825]\n",
      "Epoch 411, Gradients: [-8.38143868e-01 -9.02822469e+01  3.31877488e+01  4.60755996e+00\n",
      " -4.84724678e+02 -1.56452258e+03 -8.35468335e+00]\n",
      " Loss: 715.8197332912059, Parameters: [30.70791547  6.63537082  4.59474227  0.20010319  0.51343752  0.13790135\n",
      "  6.77826144]\n",
      "Epoch 421, Gradients: [-8.25532758e-01 -8.95979342e+01  3.50943250e+01  9.00060284e+00\n",
      " -4.76508247e+02 -1.55689822e+03 -8.29268914e+00]\n",
      " Loss: 716.3012421360396, Parameters: [30.77319927  6.76352075  4.54890215  0.20008513  0.51536033  0.13910257\n",
      "  6.81133221]\n",
      "Epoch 431, Gradients: [-8.12100485e-01 -8.88075982e+01  3.70861998e+01  1.31268722e+01\n",
      " -4.68185445e+02 -1.54480273e+03 -8.22574919e+00]\n",
      " Loss: 716.7949572641951, Parameters: [30.84050633  6.8945251   4.49800825  0.20002891  0.5173495   0.14036194\n",
      "  6.84582975]\n",
      "Epoch 441, Gradients: [-7.97810257e-01 -8.79079812e+01  3.91717210e+01  1.69703434e+01\n",
      " -4.59782306e+02 -1.52795107e+03 -8.15367349e+00]\n",
      " Loss: 717.3010968071978, Parameters: [30.90979684  7.0281661   4.44162122  0.19993323  0.51940638  0.14167843\n",
      "  6.88178771]\n",
      "Epoch 451, Gradients: [-7.82625640e-01 -8.68961788e+01  4.13614740e+01  2.05196981e+01\n",
      " -4.51325969e+02 -1.50607064e+03 -8.07631471e+00]\n",
      " Loss: 717.8203027642444, Parameters: [30.98101187  7.16420764  4.37925596  0.19979676  0.52153217  0.14305034\n",
      "  6.91923591]\n",
      "Epoch 461, Gradients: [-7.66510965e-01 -8.57695350e+01  4.36684290e+01  2.37679933e+01\n",
      " -4.42842819e+02 -1.47890784e+03 -7.99358046e+00]\n",
      " Loss: 718.353798909472, Parameters: [31.05407533  7.30239935  4.31039031  0.19961832  0.52372807  0.14447517\n",
      "  6.95820078]\n",
      "Epoch 471, Gradients: [-7.49431441e-01 -8.45255427e+01  4.61082622e+01  2.67123677e+01\n",
      " -4.34356588e+02 -1.44623147e+03 -7.90544533e+00]\n",
      " Loss: 718.9035721365028, Parameters: [31.12889394  7.44247924  4.23446922  0.19939687  0.5259953   0.14594952\n",
      "  6.99870539]\n",
      "Epoch 481, Gradients: [-7.31353086e-01 -8.31617354e+01  4.86997693e+01  2.93536281e+01\n",
      " -4.25886068e+02 -1.40783472e+03 -7.81196417e+00]\n",
      " Loss: 719.4725905665327, Parameters: [31.20535657  7.58417556  4.15090824  0.19913162  0.52833516  0.14746897\n",
      "  7.0407694 ]\n",
      "Epoch 491, Gradients: [-7.12242535e-01 -8.16755698e+01  5.14653393e+01  3.16956603e+01\n",
      " -4.17442178e+02 -1.36353735e+03 -7.71328699e+00]\n",
      " Loss: 720.0650713729372, Parameters: [31.28333328  7.72720816  4.05909822  0.19882195  0.53074899  0.14902801\n",
      "  7.08440905]\n",
      "Epoch 501, Gradients: [-6.92066739e-01 -8.00642960e+01  5.44314587e+01  3.37446349e+01\n",
      " -4.09024172e+02 -1.31318874e+03 -7.60967651e+00]\n",
      " Loss: 720.6868141677876, Parameters: [31.36267417  7.87128929  3.95841232  0.19846745  0.53323819  0.15061989\n",
      "  7.1296373 ]\n",
      "Epoch 511, Gradients: [-6.72928544e-01 -7.85016733e+01  5.73086892e+01  3.53500058e+01\n",
      " -4.01455710e+02 -1.26240137e+03 -7.51215253e+00]\n",
      " Loss: 721.2783889536936, Parameters: [31.43518411  8.0016761   3.85931267  0.19810814  0.53554817  0.15207568\n",
      "  7.17178941]\n",
      "Epoch 521, Gradients: [-6.52792415e-01 -7.68259021e+01  6.04166981e+01  3.67355279e+01\n",
      " -3.93848161e+02 -1.20623326e+03 -7.41061148e+00]\n",
      " Loss: 721.9089225177206, Parameters: [31.50873537  8.13263827  3.75145589  0.19770937  0.53793143  0.15354937\n",
      "  7.21542507]\n",
      "Epoch 531, Gradients: [-6.31632793e-01 -7.50331483e+01  6.37824803e+01  3.79005417e+01\n",
      " -3.86140534e+02 -1.14472054e+03 -7.30560368e+00]\n",
      " Loss: 722.5884520242599, Parameters: [31.58320927  8.26398192  3.63449052  0.1972715   0.5403904   0.15503377\n",
      "  7.26056871]\n",
      "Epoch 541, Gradients: [-6.09424797e-01 -7.31193748e+01  6.74384154e+01  3.88440082e+01\n",
      " -3.78252300e+02 -1.07792569e+03 -7.19783048e+00]\n",
      " Loss: 723.3296868997477, Parameters: [31.65843662  8.39546766  3.50803187  0.19679464  0.54292643  0.15651971\n",
      "  7.30723534]\n",
      "Epoch 551, Gradients: [-5.86146193e-01 -7.10801968e+01  7.14199717e+01  3.95619564e+01\n",
      " -3.70070281e+02 -1.00599107e+03 -7.08817517e+00]\n",
      " Loss: 724.1487207228797, Parameters: [31.73421583  8.52683365  3.37173499  0.19627902  0.54553996  0.15799644\n",
      "  7.35543704]\n",
      "Epoch 561, Gradients: [-5.61780348e-01 -6.89108573e+01  7.57635957e+01  4.00454126e+01\n",
      " -3.61437567e+02 -9.29184099e+02 -6.97772937e+00]\n",
      " Loss: 725.0658969213993, Parameters: [31.81031867  8.65780247  3.22533704  0.19572515  0.5482304   0.1594518\n",
      "  7.40518656]\n",
      "Epoch 571, Gradients: [-5.36321435e-01 -6.66063042e+01  8.05037553e+01  4.02783884e+01\n",
      " -3.52142139e+02 -8.47948415e+02 -6.86781637e+00]\n",
      " Loss: 726.1069142841166, Parameters: [31.88649171  8.78808195  3.06869008  0.19513393  0.55099568  0.16087231\n",
      "  7.45650005]\n",
      "Epoch 581, Gradients: [-5.09783548e-01 -6.41613996e+01  8.56684138e+01  4.02359539e+01\n",
      " -3.41904742e+02 -7.62966022e+02 -6.76000862e+00]\n",
      " Loss: 727.3042707254491, Parameters: [31.96245653  8.9173635   2.9017905   0.19450683  0.55383162  0.16224338\n",
      "  7.50939998]\n",
      "Epoch 591, Gradients: [-4.82216255e-01 -6.15713420e+01  9.12723480e+01  3.98827406e+01\n",
      " -3.30366817e+02 -6.75230206e+02 -6.65613311e+00]\n",
      " Loss: 728.6991825426702, Parameters: [32.03791033  9.04531932  2.72480589  0.19384613  0.55673104  0.16354959\n",
      "  7.56391851]\n",
      "Epoch 601, Gradients: [-4.53730505e-01 -5.88324435e+01  9.73080119e+01  3.91725827e+01\n",
      " -3.17081312e+02 -5.86122961e+02 -6.55825650e+00]\n",
      " Loss: 730.3441872580639, Parameters: [32.11252832  9.17159928  2.53809802  0.19315523  0.5596826   0.16477525\n",
      "  7.62010138]\n",
      "Epoch 611, Gradients: [-4.27460440e-01 -5.62358945e+01  1.03087243e+02  3.81842421e+01\n",
      " -3.03181365e+02 -5.06136691e+02 -6.47686591e+00]\n",
      " Loss: 732.0958111786524, Parameters: [32.17868146  9.28347452  2.36196135  0.19251032  0.56237239  0.16579418\n",
      "  7.67223068]\n",
      "Epoch 621, Gradients: [-4.00865143e-01 -5.35154443e+01  1.09127167e+02  3.68182318e+01\n",
      " -2.86976222e+02 -4.28147243e+02 -6.40321742e+00]\n",
      " Loss: 734.1686525209808, Parameters: [32.2437313   9.39347116  2.17888145  0.191847    0.5650814   0.16672393\n",
      "  7.7260324 ]\n",
      "Epoch 631, Gradients: [  -0.3744137   -50.68081872  115.32273092   35.0348634  -268.05782477\n",
      " -354.25050006   -6.33893527]\n",
      " Loss: 736.6401105750457, Parameters: [32.30751693  9.50137402  1.98990021  0.19117147  0.56778749  0.16755885\n",
      "  7.78161286]\n",
      "Epoch 641, Gradients: [  -0.34884362  -47.74903345  121.55708826   32.81148811 -246.186782\n",
      " -286.57268495   -6.28563211]\n",
      " Loss: 739.6120024712413, Parameters: [32.3698609   9.60688408  1.79601107  0.19049177  0.57045968  0.16829425\n",
      "  7.83908484]\n",
      "Epoch 651, Gradients: [  -0.32532279  -44.74611202  127.72633618   30.1511604  -221.59456566\n",
      " -227.05124621   -6.24500833]\n",
      " Loss: 743.2215996475588, Parameters: [32.43065491  9.70967585  1.59822557  0.18981777  0.57305924  0.16892869\n",
      "  7.89857811]\n",
      "Epoch 661, Gradients: [  -0.30575566  -41.70550083  133.79434519   27.08723661 -195.66279965\n",
      " -177.00558689   -6.21921127]\n",
      " Loss: 747.6623870657854, Parameters: [32.48995664  9.80942801  1.39753984  0.18916092  0.57554338  0.16946507\n",
      "  7.96024562]\n",
      "Epoch 671, Gradients: [  -0.29346293  -38.66013349  139.91078761   23.67026366 -172.43581148\n",
      " -136.36398177   -6.21148848]\n",
      " Loss: 753.2249336844916, Parameters: [32.54814475  9.90584326  1.19483831  0.18853385  0.57787631  0.16991071\n",
      "  8.02427064]\n",
      "Epoch 681, Gradients: [  -0.29478821  -35.62672606  146.80590366   19.91447384 -161.87372466\n",
      " -101.90427554   -6.22699561]\n",
      " Loss: 760.3846856471189, Parameters: [32.60621481  9.99865395  0.99070051  0.18795006  0.58005877  0.17027541\n",
      "  8.09087939]\n",
      "Epoch 691, Gradients: [  -0.32286075  -32.57395221  157.20619396   15.67341245 -185.8647358\n",
      "  -63.22331111   -6.27458853]\n",
      " Loss: 770.0263241423017, Parameters: [32.66640466 10.08759764  0.78487799  0.18742453  0.58219943  0.17056516\n",
      "  8.16036297]\n",
      "Epoch 701, Gradients: [  -0.40758137  -29.29661111  179.17369214   10.42958632 -284.0956569\n",
      "    1.80545531   -6.37515921]\n",
      " Loss: 784.1777639685232, Parameters: [32.73359104 10.17231238  0.5747626   0.18697723  0.584668    0.17076576\n",
      "  8.23312349]\n",
      "Epoch 711, Gradients: [  -0.60143135  -25.4719507   221.18517735    4.12882548 -464.21623729\n",
      "  102.0208654    -6.55525174]\n",
      " Loss: 805.6777502822886, Parameters: [32.80964035 10.24408696  0.37534496  0.18667288  0.58793079  0.17081377\n",
      "  8.3021107 ]\n",
      "Epoch 721, Gradients: [  -1.19448821  -18.12284809  252.33678031   -2.27073771 -683.28931891\n",
      "  260.74352017   -7.01311714]\n",
      " Loss: 852.2901169028205, Parameters: [32.92095154 10.30946628  0.15762289  0.18650333  0.59323554  0.17063497\n",
      "  8.37556542]\n",
      "Epoch 731, Gradients: [-1.79909994e+00 -1.55809178e+01  3.85657225e+02 -5.51693931e-01\n",
      "  1.45447880e+03  1.41362827e+01 -6.92365948e+00]\n",
      " Loss: 886.1336728076778, Parameters: [ 3.31137158e+01  1.03617646e+01 -1.51487355e-02  1.86474528e-01\n",
      "  6.04017330e-01  1.70142747e-01  8.45574966e+00]\n",
      "Epoch 741, Gradients: [  -1.48110963  -13.6325351  -206.36792748   -3.03100498  129.57779488\n",
      "  344.21738131   -6.78814577]\n",
      " Loss: 869.6313294995277, Parameters: [33.34855403 10.40491469 -0.11268693  0.18650217  0.60248331  0.16963578\n",
      "  8.54005264]\n",
      "Epoch 751, Gradients: [  -2.03181498   -9.45778695  -72.82514921   -3.71193082 -608.96945579\n",
      "  378.97059857   -6.77742959]\n",
      " Loss: 893.8642915854241, Parameters: [33.56734215 10.44430319 -0.04740729  0.18657276  0.59940776  0.16879969\n",
      "  8.62580358]\n",
      "Epoch 761, Gradients: [-1.89986087e+00 -9.82955813e+00  3.49773114e+01 -3.16664096e+00\n",
      "  1.98485817e+03  2.87576200e+02 -6.43036746e+00]\n",
      " Loss: 889.5875030360194, Parameters: [33.79319261 10.47822113 -0.05277588  0.18666738  0.60330039  0.16780957\n",
      "  8.71284569]\n",
      "Epoch 771, Gradients: [  -1.40532739  -11.51479779 -219.56693167   -3.16925125 -421.22496999\n",
      "  356.77956968   -6.00860401]\n",
      " Loss: 868.1273933373316, Parameters: [34.00124933 10.51170955 -0.10947259  0.18676764  0.5986961   0.1668075\n",
      "  8.79936541]\n",
      "Epoch 781, Gradients: [  -1.63013491   -9.08644628 -175.44510334   -3.51114417   30.36522796\n",
      "  392.48930101   -5.92048033]\n",
      " Loss: 879.3812593850602, Parameters: [34.18075231 10.54723164 -0.08090855  0.1868777   0.60042399  0.16562334\n",
      "  8.88463822]\n",
      "Epoch 791, Gradients: [   -1.98938887    -6.2285324     -7.14541928    -3.81830666\n",
      " -1093.21749603   403.75817779    -5.83033702]\n",
      " Loss: 894.2996369603404, Parameters: [ 3.43617194e+01  1.05796081e+01 -3.34183153e-02  1.87001985e-01\n",
      "  5.99504519e-01  1.64268967e-01  8.97027333e+00]\n",
      "Epoch 801, Gradients: [-1.98008835e+00 -5.46962707e+00  8.61321755e+01 -3.83949630e+00\n",
      " -4.28593463e+03  4.07487425e+02 -5.60758333e+00]\n",
      " Loss: 894.4356163152381, Parameters: [ 3.45545628e+01  1.06060494e+01 -1.17392114e-02  1.87142763e-01\n",
      "  5.99764079e-01  1.62763904e-01  9.05680710e+00]\n",
      "Epoch 811, Gradients: [  -1.96412293   -4.7081636     0.71446786   -3.9492715  -379.74861986\n",
      "  434.53951745   -5.42344558]\n",
      " Loss: 894.3005117426949, Parameters: [ 3.47274509e+01  1.06265645e+01 -1.71192409e-02  1.87280582e-01\n",
      "  5.99958691e-01  1.61296313e-01  9.13481693e+00]\n",
      "Epoch 821, Gradients: [  -1.94238666   -4.06762829   -1.60033906   -4.0008109  -107.11201695\n",
      "  448.67949655   -5.23548494]\n",
      " Loss: 893.9261153032278, Parameters: [ 3.48952129e+01  1.06448432e+01 -2.17202887e-02  1.87429128e-01\n",
      "  5.99982041e-01  1.59688286e-01  9.21278830e+00]\n",
      "Epoch 831, Gradients: [  -1.92266512   -3.4198953    -1.94043159   -4.05936143 -347.67621138\n",
      "  464.65961509   -5.05467839]\n",
      " Loss: 893.6156733880514, Parameters: [ 3.50572080e+01  1.06612618e+01 -2.33706013e-02  1.87588224e-01\n",
      "  5.99935508e-01  1.57931931e-01  9.29065391e+00]\n",
      "Epoch 841, Gradients: [  -1.90624147   -2.74832754   -2.68755291   -4.13090006 -140.12000324\n",
      "  484.01023738   -4.8820733 ]\n",
      " Loss: 893.4232025838567, Parameters: [ 3.52139566e+01  1.06758276e+01 -2.33208771e-02  1.87758293e-01\n",
      "  5.99975485e-01  1.56014920e-01  9.36839286e+00]\n",
      "Epoch 851, Gradients: [ -1.89228983  -2.05775757  -2.13963152  -4.21291034 -94.79083393\n",
      " 506.45916489  -4.71698035]\n",
      " Loss: 893.3221823552964, Parameters: [ 3.53662553e+01  1.06883539e+01 -2.25439797e-02  1.87940222e-01\n",
      "  5.99985392e-01  1.53917485e-01  9.44601430e+00]\n",
      "Converged at epoch 857\n",
      "Epoch 858, : Loss: 893.3039524819374, \n",
      " vecc Parameters: [ 3.54854026e+01  1.06967153e+01 -2.17980246e-02  1.88095089e-01\n",
      "  6.00010441e-01  1.52092032e-01  9.50804231e+00]\n",
      "FINAL STATE: Epoch 858, Loss: 893.3039524819374, \n",
      " vecc Parameters: [ 3.54854026e+01  1.06967153e+01 -2.17980246e-02  1.88095089e-01\n",
      "  6.00010441e-01  1.52092032e-01  9.50804231e+00]\n"
     ]
    }
   ],
   "source": [
    "result = {}\n",
    "nheads= 100\n",
    "\n",
    "for day in range(1):\n",
    "    idx_for_datamap= [8*day,8*(day+1)]\n",
    "    analysis_data_map = {}\n",
    "    for i in range(idx_for_datamap[0],idx_for_datamap[1]):\n",
    "        tmp = coarse_dicts[key_idx[i]].copy()\n",
    "        tmp['Hours_elapsed'] = np.round(tmp['Hours_elapsed']-477700)\n",
    "\n",
    "        tmp = tmp.iloc[ord_mm, :4].to_numpy()\n",
    "        tmp = torch.from_numpy(tmp).double()  # Convert NumPy to Tensor\n",
    "        # tmp = tmp.clone().detach().requires_grad_(True)  # Enable gradients\n",
    "        \n",
    "        analysis_data_map[key_idx[i]] = tmp\n",
    "    aggregated_data = pd.DataFrame()\n",
    "    for i in range(idx_for_datamap[0],idx_for_datamap[1]):\n",
    "        tmp = coarse_dicts[key_idx[i]].copy()\n",
    "        tmp['Hours_elapsed'] = np.round(tmp['Hours_elapsed']-477700)\n",
    "        tmp = tmp.iloc[ord_mm].reset_index(drop=True)  \n",
    "        aggregated_data = pd.concat((aggregated_data, tmp), axis=0)\n",
    "    \n",
    "    aggregated_data = aggregated_data.iloc[:, :4].to_numpy()\n",
    "\n",
    "    aggregated_data = torch.from_numpy(aggregated_data).double()  # Convert NumPy to Tensor\n",
    "\n",
    "    params = [24.42, 1.92, 1.92, 0.001, -0.045, 0.237, 3.34]\n",
    "    # params = [24.42, 10, 10, 0.001, -0.045, 0.4, 3.34]\n",
    "    params = torch.tensor(params, requires_grad=True)\n",
    "\n",
    "    params = [23.09, 2.24, 3.2927, -0.107, 0.1659, 0.1612, 1.6049]\n",
    "    params = torch.tensor(params, dtype=torch.float64, requires_grad=True)\n",
    "\n",
    "    torch_smooth = torch.tensor(0.5, dtype=torch.float32)\n",
    "\n",
    "\n",
    "    instance = kernels.model_fitting(\n",
    "        smooth= 1.0,\n",
    "        input_map=analysis_data_map,\n",
    "        aggregated_data=aggregated_data,\n",
    "        nns_map=nns_map,\n",
    "        mm_cond_number=mm_cond_number,\n",
    "        nheads= nheads\n",
    "    )\n",
    "\n",
    "    # optimizer = optim.Adam([params], lr=0.01)  # For Adam\n",
    "    optimizer, scheduler = instance.optimizer_fun(params, lr=0.03, betas=(0.9, 0.99), eps=1e-8, step_size=100, gamma=0.9)    \n",
    "    out = instance.run_full(params, optimizer,scheduler, instance.matern_cov_anisotropy_kv, epochs=1000)\n",
    "    result[day+1] = out\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save estimates in to pickle fime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28misinstance\u001b[39m(\u001b[43mresult\u001b[49m, \u001b[38;5;28mdict\u001b[39m)\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Save pickle\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'result' is not defined"
     ]
    }
   ],
   "source": [
    "isinstance(result, dict)\n",
    "import os\n",
    "# Save pickle\n",
    "output_filename = f\"estimation_1250_july24.pkl\"\n",
    "\n",
    "# base_path = \"/home/jl2815/tco/data/pickle_data\"\n",
    "output_path = \"/Users/joonwonlee/Documents/\"\n",
    "output_filepath = os.path.join(output_path, output_filename)\n",
    "with open(output_filepath, 'wb') as pickle_file:\n",
    "    pickle.dump(result, pickle_file)\n",
    "\n",
    "input_filepath = output_filepath\n",
    "# Load pickle\n",
    "with open(input_filepath, 'rb') as pickle_file:\n",
    "    loaded_map = pickle.load(pickle_file)\n",
    "\n",
    "loaded_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load estimates from amarel and make it into pd data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10x10 full     takes 22 seconds (epochs 444)\n",
    "\n",
    "vecchia log\n",
    "10 by 10 fix 300 epochs (2m 7.2)  \n",
    "original 2m 7.2  25 3 2.8 -0.04 -0.04 0.0066 4.3\n",
    "\n",
    "if dont use cache   300 epochs fixed 5m 35.3\n",
    "25 3 2.84 -0.04 -0.04 0.0066 4.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sigmasq</th>\n",
       "      <th>range_lat</th>\n",
       "      <th>range_lon</th>\n",
       "      <th>advec_lat</th>\n",
       "      <th>advec_lon</th>\n",
       "      <th>beta</th>\n",
       "      <th>nugget</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-07-01</th>\n",
       "      <td>24.793444</td>\n",
       "      <td>1.584529</td>\n",
       "      <td>1.718248</td>\n",
       "      <td>0.009089</td>\n",
       "      <td>-0.107299</td>\n",
       "      <td>0.131038</td>\n",
       "      <td>2.717239</td>\n",
       "      <td>14068.529297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-02</th>\n",
       "      <td>24.424301</td>\n",
       "      <td>1.997055</td>\n",
       "      <td>1.942683</td>\n",
       "      <td>0.043588</td>\n",
       "      <td>-0.072679</td>\n",
       "      <td>0.137124</td>\n",
       "      <td>1.513148</td>\n",
       "      <td>12357.715820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-03</th>\n",
       "      <td>26.009497</td>\n",
       "      <td>1.215236</td>\n",
       "      <td>1.558868</td>\n",
       "      <td>0.023392</td>\n",
       "      <td>-0.150548</td>\n",
       "      <td>0.199850</td>\n",
       "      <td>2.890678</td>\n",
       "      <td>14948.140625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-04</th>\n",
       "      <td>24.701347</td>\n",
       "      <td>1.612308</td>\n",
       "      <td>1.822960</td>\n",
       "      <td>-0.164069</td>\n",
       "      <td>-0.237443</td>\n",
       "      <td>0.131595</td>\n",
       "      <td>3.636499</td>\n",
       "      <td>14786.204102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-05</th>\n",
       "      <td>22.598671</td>\n",
       "      <td>2.901185</td>\n",
       "      <td>3.722327</td>\n",
       "      <td>-0.011729</td>\n",
       "      <td>-0.152072</td>\n",
       "      <td>0.072866</td>\n",
       "      <td>2.397249</td>\n",
       "      <td>12096.261719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-06</th>\n",
       "      <td>25.594908</td>\n",
       "      <td>1.702692</td>\n",
       "      <td>2.255174</td>\n",
       "      <td>0.017462</td>\n",
       "      <td>-0.158125</td>\n",
       "      <td>0.098684</td>\n",
       "      <td>3.850205</td>\n",
       "      <td>14690.248047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-07</th>\n",
       "      <td>26.030510</td>\n",
       "      <td>1.261084</td>\n",
       "      <td>2.831952</td>\n",
       "      <td>0.054831</td>\n",
       "      <td>-0.343255</td>\n",
       "      <td>0.103045</td>\n",
       "      <td>4.596346</td>\n",
       "      <td>15342.459961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-08</th>\n",
       "      <td>26.043682</td>\n",
       "      <td>0.995279</td>\n",
       "      <td>1.629503</td>\n",
       "      <td>-0.019824</td>\n",
       "      <td>-0.411626</td>\n",
       "      <td>0.164296</td>\n",
       "      <td>2.751402</td>\n",
       "      <td>14857.195312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-09</th>\n",
       "      <td>24.052071</td>\n",
       "      <td>1.377774</td>\n",
       "      <td>2.357721</td>\n",
       "      <td>0.021439</td>\n",
       "      <td>-0.220316</td>\n",
       "      <td>0.142847</td>\n",
       "      <td>1.675457</td>\n",
       "      <td>12666.991211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-10</th>\n",
       "      <td>25.766109</td>\n",
       "      <td>1.392051</td>\n",
       "      <td>2.358171</td>\n",
       "      <td>0.026684</td>\n",
       "      <td>-0.077366</td>\n",
       "      <td>0.150648</td>\n",
       "      <td>3.821218</td>\n",
       "      <td>14987.769531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-11</th>\n",
       "      <td>23.945438</td>\n",
       "      <td>1.490333</td>\n",
       "      <td>2.470762</td>\n",
       "      <td>-0.009915</td>\n",
       "      <td>0.027429</td>\n",
       "      <td>0.137959</td>\n",
       "      <td>2.066264</td>\n",
       "      <td>13000.419922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-12</th>\n",
       "      <td>23.036034</td>\n",
       "      <td>2.299998</td>\n",
       "      <td>3.346955</td>\n",
       "      <td>-0.054281</td>\n",
       "      <td>0.114976</td>\n",
       "      <td>0.110155</td>\n",
       "      <td>1.604898</td>\n",
       "      <td>11485.496094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-13</th>\n",
       "      <td>22.790960</td>\n",
       "      <td>2.072518</td>\n",
       "      <td>3.616723</td>\n",
       "      <td>-0.130206</td>\n",
       "      <td>0.076944</td>\n",
       "      <td>0.135628</td>\n",
       "      <td>1.441895</td>\n",
       "      <td>11315.873047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-14</th>\n",
       "      <td>24.079025</td>\n",
       "      <td>2.077914</td>\n",
       "      <td>2.578654</td>\n",
       "      <td>-0.035028</td>\n",
       "      <td>0.072091</td>\n",
       "      <td>0.144720</td>\n",
       "      <td>2.405799</td>\n",
       "      <td>13138.958984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-15</th>\n",
       "      <td>22.556171</td>\n",
       "      <td>3.047949</td>\n",
       "      <td>3.821722</td>\n",
       "      <td>-0.051073</td>\n",
       "      <td>0.067158</td>\n",
       "      <td>0.109084</td>\n",
       "      <td>1.462631</td>\n",
       "      <td>10808.830078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-16</th>\n",
       "      <td>23.403471</td>\n",
       "      <td>2.888016</td>\n",
       "      <td>3.056899</td>\n",
       "      <td>-0.004253</td>\n",
       "      <td>0.005845</td>\n",
       "      <td>0.104761</td>\n",
       "      <td>2.019670</td>\n",
       "      <td>12012.943359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-17</th>\n",
       "      <td>24.978308</td>\n",
       "      <td>1.371159</td>\n",
       "      <td>2.236580</td>\n",
       "      <td>-0.068871</td>\n",
       "      <td>-0.126589</td>\n",
       "      <td>0.137412</td>\n",
       "      <td>3.044259</td>\n",
       "      <td>14286.230469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-18</th>\n",
       "      <td>23.328363</td>\n",
       "      <td>1.295417</td>\n",
       "      <td>3.319158</td>\n",
       "      <td>-0.079007</td>\n",
       "      <td>-0.109866</td>\n",
       "      <td>0.131408</td>\n",
       "      <td>2.737964</td>\n",
       "      <td>13417.033203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-19</th>\n",
       "      <td>23.913704</td>\n",
       "      <td>1.824143</td>\n",
       "      <td>2.503119</td>\n",
       "      <td>0.020213</td>\n",
       "      <td>0.016007</td>\n",
       "      <td>0.142548</td>\n",
       "      <td>2.095682</td>\n",
       "      <td>12876.714844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-20</th>\n",
       "      <td>23.171667</td>\n",
       "      <td>2.521096</td>\n",
       "      <td>3.594732</td>\n",
       "      <td>0.032805</td>\n",
       "      <td>-0.026624</td>\n",
       "      <td>0.092923</td>\n",
       "      <td>2.846266</td>\n",
       "      <td>12944.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-21</th>\n",
       "      <td>23.972263</td>\n",
       "      <td>2.328973</td>\n",
       "      <td>3.350626</td>\n",
       "      <td>-0.002169</td>\n",
       "      <td>-0.070489</td>\n",
       "      <td>0.109454</td>\n",
       "      <td>2.806951</td>\n",
       "      <td>13142.653320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-22</th>\n",
       "      <td>23.484762</td>\n",
       "      <td>1.773483</td>\n",
       "      <td>3.144358</td>\n",
       "      <td>0.106800</td>\n",
       "      <td>-0.146150</td>\n",
       "      <td>0.170165</td>\n",
       "      <td>2.292179</td>\n",
       "      <td>12951.943359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-23</th>\n",
       "      <td>22.399940</td>\n",
       "      <td>2.525347</td>\n",
       "      <td>3.945889</td>\n",
       "      <td>-0.004455</td>\n",
       "      <td>0.073785</td>\n",
       "      <td>0.144858</td>\n",
       "      <td>1.340997</td>\n",
       "      <td>10006.291016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-24</th>\n",
       "      <td>22.485428</td>\n",
       "      <td>1.960177</td>\n",
       "      <td>3.856450</td>\n",
       "      <td>0.042581</td>\n",
       "      <td>-0.149502</td>\n",
       "      <td>0.134382</td>\n",
       "      <td>1.423066</td>\n",
       "      <td>11153.117188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-25</th>\n",
       "      <td>22.398106</td>\n",
       "      <td>3.968451</td>\n",
       "      <td>3.945307</td>\n",
       "      <td>0.006230</td>\n",
       "      <td>-0.013954</td>\n",
       "      <td>0.047208</td>\n",
       "      <td>1.345503</td>\n",
       "      <td>8595.869141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-26</th>\n",
       "      <td>22.393942</td>\n",
       "      <td>2.544035</td>\n",
       "      <td>3.943803</td>\n",
       "      <td>-0.004113</td>\n",
       "      <td>0.031536</td>\n",
       "      <td>0.084661</td>\n",
       "      <td>1.334278</td>\n",
       "      <td>10097.978516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-27</th>\n",
       "      <td>22.484076</td>\n",
       "      <td>2.263680</td>\n",
       "      <td>3.848698</td>\n",
       "      <td>-0.026536</td>\n",
       "      <td>-0.070513</td>\n",
       "      <td>0.085162</td>\n",
       "      <td>1.953647</td>\n",
       "      <td>11613.490234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-28</th>\n",
       "      <td>22.687857</td>\n",
       "      <td>1.915375</td>\n",
       "      <td>3.615973</td>\n",
       "      <td>-0.024074</td>\n",
       "      <td>-0.078118</td>\n",
       "      <td>0.091293</td>\n",
       "      <td>2.331802</td>\n",
       "      <td>12408.534180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-29</th>\n",
       "      <td>22.405510</td>\n",
       "      <td>2.753298</td>\n",
       "      <td>3.919266</td>\n",
       "      <td>0.003522</td>\n",
       "      <td>-0.051619</td>\n",
       "      <td>0.069307</td>\n",
       "      <td>3.181403</td>\n",
       "      <td>12968.927734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-30</th>\n",
       "      <td>23.821211</td>\n",
       "      <td>2.505870</td>\n",
       "      <td>3.378460</td>\n",
       "      <td>-0.030410</td>\n",
       "      <td>-0.199047</td>\n",
       "      <td>0.127340</td>\n",
       "      <td>2.945880</td>\n",
       "      <td>13282.449219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-31</th>\n",
       "      <td>24.262573</td>\n",
       "      <td>3.082172</td>\n",
       "      <td>2.880464</td>\n",
       "      <td>0.059405</td>\n",
       "      <td>-0.190543</td>\n",
       "      <td>0.197513</td>\n",
       "      <td>5.303008</td>\n",
       "      <td>15539.535156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              sigmasq  range_lat  range_lon  advec_lat  advec_lon      beta  \\\n",
       "2024-07-01  24.793444   1.584529   1.718248   0.009089  -0.107299  0.131038   \n",
       "2024-07-02  24.424301   1.997055   1.942683   0.043588  -0.072679  0.137124   \n",
       "2024-07-03  26.009497   1.215236   1.558868   0.023392  -0.150548  0.199850   \n",
       "2024-07-04  24.701347   1.612308   1.822960  -0.164069  -0.237443  0.131595   \n",
       "2024-07-05  22.598671   2.901185   3.722327  -0.011729  -0.152072  0.072866   \n",
       "2024-07-06  25.594908   1.702692   2.255174   0.017462  -0.158125  0.098684   \n",
       "2024-07-07  26.030510   1.261084   2.831952   0.054831  -0.343255  0.103045   \n",
       "2024-07-08  26.043682   0.995279   1.629503  -0.019824  -0.411626  0.164296   \n",
       "2024-07-09  24.052071   1.377774   2.357721   0.021439  -0.220316  0.142847   \n",
       "2024-07-10  25.766109   1.392051   2.358171   0.026684  -0.077366  0.150648   \n",
       "2024-07-11  23.945438   1.490333   2.470762  -0.009915   0.027429  0.137959   \n",
       "2024-07-12  23.036034   2.299998   3.346955  -0.054281   0.114976  0.110155   \n",
       "2024-07-13  22.790960   2.072518   3.616723  -0.130206   0.076944  0.135628   \n",
       "2024-07-14  24.079025   2.077914   2.578654  -0.035028   0.072091  0.144720   \n",
       "2024-07-15  22.556171   3.047949   3.821722  -0.051073   0.067158  0.109084   \n",
       "2024-07-16  23.403471   2.888016   3.056899  -0.004253   0.005845  0.104761   \n",
       "2024-07-17  24.978308   1.371159   2.236580  -0.068871  -0.126589  0.137412   \n",
       "2024-07-18  23.328363   1.295417   3.319158  -0.079007  -0.109866  0.131408   \n",
       "2024-07-19  23.913704   1.824143   2.503119   0.020213   0.016007  0.142548   \n",
       "2024-07-20  23.171667   2.521096   3.594732   0.032805  -0.026624  0.092923   \n",
       "2024-07-21  23.972263   2.328973   3.350626  -0.002169  -0.070489  0.109454   \n",
       "2024-07-22  23.484762   1.773483   3.144358   0.106800  -0.146150  0.170165   \n",
       "2024-07-23  22.399940   2.525347   3.945889  -0.004455   0.073785  0.144858   \n",
       "2024-07-24  22.485428   1.960177   3.856450   0.042581  -0.149502  0.134382   \n",
       "2024-07-25  22.398106   3.968451   3.945307   0.006230  -0.013954  0.047208   \n",
       "2024-07-26  22.393942   2.544035   3.943803  -0.004113   0.031536  0.084661   \n",
       "2024-07-27  22.484076   2.263680   3.848698  -0.026536  -0.070513  0.085162   \n",
       "2024-07-28  22.687857   1.915375   3.615973  -0.024074  -0.078118  0.091293   \n",
       "2024-07-29  22.405510   2.753298   3.919266   0.003522  -0.051619  0.069307   \n",
       "2024-07-30  23.821211   2.505870   3.378460  -0.030410  -0.199047  0.127340   \n",
       "2024-07-31  24.262573   3.082172   2.880464   0.059405  -0.190543  0.197513   \n",
       "\n",
       "              nugget          loss  \n",
       "2024-07-01  2.717239  14068.529297  \n",
       "2024-07-02  1.513148  12357.715820  \n",
       "2024-07-03  2.890678  14948.140625  \n",
       "2024-07-04  3.636499  14786.204102  \n",
       "2024-07-05  2.397249  12096.261719  \n",
       "2024-07-06  3.850205  14690.248047  \n",
       "2024-07-07  4.596346  15342.459961  \n",
       "2024-07-08  2.751402  14857.195312  \n",
       "2024-07-09  1.675457  12666.991211  \n",
       "2024-07-10  3.821218  14987.769531  \n",
       "2024-07-11  2.066264  13000.419922  \n",
       "2024-07-12  1.604898  11485.496094  \n",
       "2024-07-13  1.441895  11315.873047  \n",
       "2024-07-14  2.405799  13138.958984  \n",
       "2024-07-15  1.462631  10808.830078  \n",
       "2024-07-16  2.019670  12012.943359  \n",
       "2024-07-17  3.044259  14286.230469  \n",
       "2024-07-18  2.737964  13417.033203  \n",
       "2024-07-19  2.095682  12876.714844  \n",
       "2024-07-20  2.846266  12944.312500  \n",
       "2024-07-21  2.806951  13142.653320  \n",
       "2024-07-22  2.292179  12951.943359  \n",
       "2024-07-23  1.340997  10006.291016  \n",
       "2024-07-24  1.423066  11153.117188  \n",
       "2024-07-25  1.345503   8595.869141  \n",
       "2024-07-26  1.334278  10097.978516  \n",
       "2024-07-27  1.953647  11613.490234  \n",
       "2024-07-28  2.331802  12408.534180  \n",
       "2024-07-29  3.181403  12968.927734  \n",
       "2024-07-30  2.945880  13282.449219  \n",
       "2024-07-31  5.303008  15539.535156  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "input_path = \"/Users/joonwonlee/Documents/GEMS_TCO-1/Exercises/st_model/estimates\"\n",
    "\n",
    "# input_filename = \"estimation_50_july24.pkl\"\n",
    "# input_filename = \"estimation_200_july24.pkl\"\n",
    "input_filename = \"full_estimation_1250_july24.pkl\"\n",
    "input_filepath = os.path.join(input_path, input_filename)\n",
    "# Load pickle\n",
    "with open(input_filepath, 'rb') as pickle_file:\n",
    "    amarel_map1250= pickle.load(pickle_file)\n",
    "\n",
    "# Assuming df_1250 is your DataFrame\n",
    "df_1250 = pd.DataFrame()\n",
    "for key in amarel_map1250:\n",
    "    tmp = pd.DataFrame(amarel_map1250[key][0].reshape(1, -1), columns=['sigmasq', 'range_lat', 'range_lon', 'advec_lat', 'advec_lon', 'beta', 'nugget'])\n",
    "    tmp['loss'] = amarel_map1250[key][1]\n",
    "    df_1250 = pd.concat((df_1250, tmp), axis=0)\n",
    "\n",
    "# Generate date range\n",
    "date_range = pd.date_range(start='07-01-24', end='07-31-24')\n",
    "\n",
    "# Ensure the number of dates matches the number of rows in df_1250\n",
    "if len(date_range) == len(df_1250):\n",
    "    df_1250.index = date_range\n",
    "else:\n",
    "    print(\"The number of dates does not match the number of rows in the DataFrame.\")\n",
    "\n",
    "\n",
    "print(df_1250)\n",
    "df = df_1250\n",
    "# Save DataFrame to CSV\n",
    "output_filename = 'estimation_1250_july24.csv'\n",
    "output_csv_path = os.path.join(input_path, output_filename)\n",
    "df.to_csv(output_csv_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "faiss_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
