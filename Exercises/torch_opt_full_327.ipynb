{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for path in sys.path:\n",
    "#   print(path)\n",
    "\n",
    "import sys\n",
    "gems_tco_path = \"/Users/joonwonlee/Documents/GEMS_TCO-1/src\"\n",
    "sys.path.append(gems_tco_path)\n",
    "\n",
    "import logging\n",
    "import argparse # Argument parsing\n",
    "import math\n",
    "from collections import defaultdict\n",
    "import concurrent\n",
    "from concurrent.futures import ThreadPoolExecutor  # Importing specific executor for clarity\n",
    "import time\n",
    "\n",
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Nearest neighbor search\n",
    "import sklearn\n",
    "from sklearn.neighbors import BallTree\n",
    "\n",
    "# Special functions and optimizations\n",
    "from scipy.special import gamma, kv  # Bessel function and gamma function\n",
    "from scipy.stats import multivariate_normal  # Simulation\n",
    "from scipy.optimize import minimize\n",
    "from scipy.spatial.distance import cdist  # For space and time distance\n",
    "from scipy.spatial import distance  # Find closest spatial point\n",
    "from scipy.optimize import differential_evolution\n",
    "\n",
    "# Plotting and visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Type hints\n",
    "from typing import Callable, Union, Tuple\n",
    "\n",
    "# Add your custom path\n",
    "# sys.path.append(\"/cache/home/jl2815/tco\")\n",
    "\n",
    "# Custom imports\n",
    "\n",
    "from GEMS_TCO import orbitmap \n",
    "from GEMS_TCO import kernels \n",
    "from GEMS_TCO import evaluate\n",
    "from GEMS_TCO import orderings as _orderings\n",
    "\n",
    "import pickle\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import copy                    # clone tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_lon_resolution = [15,15]\n",
    "mm_cond_number = 10\n",
    "params= [20, 8.25, 5.25, 0.2, 0.5, 5]\n",
    "idx_for_datamap= [0,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the one dictionary to set spaital coordinates\n",
    "# filepath = \"C:/Users/joonw/TCO/GEMS_data/data_2023/sparse_cen_map23_01.pkl\"\n",
    "filepath = \"/Users/joonwonlee/Documents/GEMS_DATA/pickle_2023/coarse_cen_map23_01.pkl\"\n",
    "with open(filepath, 'rb') as pickle_file:\n",
    "    coarse_dict_24_1 = pickle.load(pickle_file)\n",
    "\n",
    "sample_df = coarse_dict_24_1['y23m01day01_hm02:12']\n",
    "\n",
    "sample_key = coarse_dict_24_1.get('y23m01day01_hm02:12')\n",
    "if sample_key is None:\n",
    "    print(\"Key 'y23m01day01_hm02:12' not found in the dictionary.\")\n",
    "\n",
    "# { (20,20):(5,1), (5,5):(20,40) }\n",
    "rho_lat = lat_lon_resolution[0]          \n",
    "rho_lon = lat_lon_resolution[1]\n",
    "lat_n = sample_df['Latitude'].unique()[::rho_lat]\n",
    "lon_n = sample_df['Longitude'].unique()[::rho_lon]\n",
    "\n",
    "lat_number = len(lat_n)\n",
    "lon_number = len(lon_n)\n",
    "\n",
    "# Set spatial coordinates for each dataset\n",
    "coarse_dicts = {}\n",
    "\n",
    "years = ['2024']\n",
    "for year in years:\n",
    "    for month in range(7, 8):  # Iterate over all months\n",
    "        # filepath = f\"C:/Users/joonw/TCO/GEMS_data/data_{year}/sparse_cen_map{year[2:]}_{month:02d}.pkl\"\n",
    "        filepath = f\"/Users/joonwonlee/Documents/GEMS_DATA/pickle_{year}/coarse_cen_map{year[2:]}_{month:02d}.pkl\"\n",
    "        with open(filepath, 'rb') as pickle_file:\n",
    "            loaded_map = pickle.load(pickle_file)\n",
    "            for key in loaded_map:\n",
    "                tmp_df = loaded_map[key]\n",
    "                coarse_filter = (tmp_df['Latitude'].isin(lat_n)) & (tmp_df['Longitude'].isin(lon_n))\n",
    "                coarse_dicts[f\"{year}_{month:02d}_{key}\"] = tmp_df[coarse_filter].reset_index(drop=True)\n",
    "\n",
    "\n",
    "key_idx = sorted(coarse_dicts)\n",
    "if not key_idx:\n",
    "    raise ValueError(\"coarse_dicts is empty\")\n",
    "\n",
    "# extract first hour data because all data shares the same spatial grid\n",
    "data_for_coord = coarse_dicts[key_idx[0]]\n",
    "x1 = data_for_coord['Longitude'].values\n",
    "y1 = data_for_coord['Latitude'].values \n",
    "coords1 = np.stack((x1, y1), axis=-1)\n",
    "\n",
    "\n",
    "# instance = orbitmap.MakeOrbitdata(data_for_coord, lat_s=5, lat_e=10, lon_s=110, lon_e=120)\n",
    "# s_dist = cdist(coords1, coords1, 'euclidean')\n",
    "# ord_mm, _ = instance.maxmin_naive(s_dist, 0)\n",
    "\n",
    "ord_mm = _orderings.maxmin_cpp(coords1)\n",
    "data_for_coord = data_for_coord.iloc[ord_mm].reset_index(drop=True)\n",
    "coords1_reordered = np.stack((data_for_coord['Longitude'].values, data_for_coord['Latitude'].values), axis=-1)\n",
    "# nns_map = instance.find_nns_naive(locs=coords1_reordered, dist_fun='euclidean', max_nn=mm_cond_number)\n",
    "nns_map=_orderings.find_nns_l2(locs= coords1_reordered  ,max_nn = mm_cond_number)\n",
    "\n",
    "\n",
    "analysis_data_map = {}\n",
    "for i in range(idx_for_datamap[0],idx_for_datamap[1]):\n",
    "    tmp = coarse_dicts[key_idx[i]].copy()\n",
    "    tmp['Hours_elapsed'] = np.round(tmp['Hours_elapsed']-477700)\n",
    "\n",
    "    tmp = tmp.iloc[ord_mm, :4].to_numpy()\n",
    "    tmp = torch.from_numpy(tmp).float()  # Convert NumPy to Tensor\n",
    "    # tmp = tmp.clone().detach().requires_grad_(True)  # Enable gradients\n",
    "    \n",
    "    analysis_data_map[key_idx[i]] = tmp\n",
    "\n",
    "aggregated_data = pd.DataFrame()\n",
    "for i in range(idx_for_datamap[0],idx_for_datamap[1]):\n",
    "    tmp = coarse_dicts[key_idx[i]].copy()\n",
    "    tmp['Hours_elapsed'] = np.round(tmp['Hours_elapsed']-477700)\n",
    "    tmp = tmp.iloc[ord_mm].reset_index(drop=True)  \n",
    "    aggregated_data = pd.concat((aggregated_data, tmp), axis=0)\n",
    "\n",
    "aggregated_data = aggregated_data.iloc[:, :4].to_numpy()\n",
    "\n",
    "aggregated_data = torch.from_numpy(aggregated_data).float()  # Convert NumPy to Tensor\n",
    "# aggregated_np = aggregated_np.clone().detach().requires_grad_(True)  # Enable gradients\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Gradients: [ -1.3326397   8.336441    8.247559    1.1887207 -22.827812  156.88403\n",
      "  -4.3982744]\n",
      " Loss: 1392.27001953125, Parameters: [ 2.442e+01  1.920e+00  1.920e+00  1.000e-03 -4.500e-02  2.370e-01\n",
      "  3.340e+00]\n",
      "Epoch 101, Gradients: [-1.0859816   0.16093826 -0.13684082 -0.5060425   0.31221008 -2.2960205\n",
      " -4.613434  ]\n",
      " Loss: 1378.829833984375, Parameters: [ 2.5250835e+01  2.0382962e+00  2.0210776e+00  2.7965151e-02\n",
      " -9.0995645e-03  1.4091690e-01  4.1661091e+00]\n",
      "Epoch 201, Gradients: [-0.9023218  -0.01376152 -0.01701355 -0.07843018  0.14977264 -0.69732666\n",
      " -3.442699  ]\n",
      " Loss: 1376.39404296875, Parameters: [ 2.5738956e+01  2.2357175e+00  2.2231426e+00  2.7480897e-02\n",
      " -1.6363824e-02  1.2432123e-01  4.6563659e+00]\n",
      "Epoch 301, Gradients: [-8.1594217e-01  1.2187958e-03 -7.5073242e-03  3.0197144e-02\n",
      " -4.5982361e-02  1.1151123e-01 -2.7896533e+00]\n",
      " Loss: 1375.2481689453125, Parameters: [ 2.60260925e+01  2.36984658e+00  2.35182714e+00  2.70866435e-02\n",
      " -2.03116890e-02  1.15547456e-01  4.94511795e+00]\n",
      "Epoch 401, Gradients: [-0.7712016   0.00345421  0.00497437  0.07624817 -0.11353302  0.3630371\n",
      " -2.4141498 ]\n",
      " Loss: 1374.6708984375, Parameters: [ 2.6195265e+01  2.4527707e+00  2.4323447e+00  2.7087886e-02\n",
      " -2.2223696e-02  1.1071177e-01  5.1150675e+00]\n",
      "Epoch 501, Gradients: [-0.7468314  -0.00426483 -0.00575256  0.0141449   0.02223206 -0.18518066\n",
      " -2.1983926 ]\n",
      " Loss: 1374.3641357421875, Parameters: [ 2.6295019e+01  2.5025582e+00  2.4803092e+00  2.7084846e-02\n",
      " -2.2968637e-02  1.0791723e-01  5.2151613e+00]\n",
      "Epoch 601, Gradients: [-7.3276103e-01 -3.0097961e-03 -1.6937256e-03 -2.1835327e-02\n",
      "  1.1215210e-02 -1.0260010e-01 -2.0691595e+00]\n",
      " Loss: 1374.19482421875, Parameters: [ 2.6353880e+01  2.5327067e+00  2.5094814e+00  2.6987966e-02\n",
      " -2.3568794e-02  1.0636067e-01  5.2741547e+00]\n",
      "Epoch 701, Gradients: [-7.2463965e-01 -1.7566681e-03  1.5258789e-05 -5.9814453e-03\n",
      "  1.2023926e-02 -7.0312500e-02 -1.9934492e+00]\n",
      " Loss: 1374.098876953125, Parameters: [ 2.6388594e+01  2.5506577e+00  2.5268247e+00  2.7057832e-02\n",
      " -2.3866497e-02  1.0545261e-01  5.3089414e+00]\n",
      "Epoch 801, Gradients: [-7.1963179e-01  8.0299377e-04 -1.0833740e-03  1.4801025e-03\n",
      " -6.9351196e-03  5.8349609e-02 -1.9470890e+00]\n",
      " Loss: 1374.04345703125, Parameters: [ 2.64090786e+01  2.56130958e+00  2.53687358e+00  2.70729661e-02\n",
      " -2.40770876e-02  1.04939215e-01  5.32947397e+00]\n",
      "Converged at epoch 823\n",
      "Epoch 824, Gradients: [-7.1896935e-01 -6.8473816e-04  1.6021729e-03 -4.8675537e-03\n",
      " -2.0904541e-03  4.4433594e-02 -1.9402325e+00]\n",
      " Loss: 1374.03466796875, full Parameters: [ 2.6412588e+01  2.5630600e+00  2.5388060e+00  2.7070900e-02\n",
      " -2.4097290e-02  1.0483751e-01  5.3329625e+00]\n",
      "FINAL STATE: Epoch 824, Gradients: [-7.1896935e-01 -6.8473816e-04  1.6021729e-03 -4.8675537e-03\n",
      " -2.0904541e-03  4.4433594e-02 -1.9402325e+00]\n",
      " Loss: 1374.03466796875, full Parameters: [ 2.6412588e+01  2.5630600e+00  2.5388060e+00  2.7070900e-02\n",
      " -2.4097290e-02  1.0483751e-01  5.3329625e+00]\n",
      "Epoch 1, Gradients: [  3.3606777  -8.22665   -13.9674225 -12.822662   -5.536743  262.3305\n",
      "  16.230236 ]\n",
      " Loss: 1208.759765625, Parameters: [ 2.442e+01  1.920e+00  1.920e+00  1.000e-03 -4.500e-02  2.370e-01\n",
      "  3.340e+00]\n",
      "Epoch 101, Gradients: [-0.14350635  0.6205344  -5.474762    2.1922607  -0.5506592  -8.562256\n",
      " -1.08791   ]\n",
      " Loss: 1152.17919921875, Parameters: [23.544601    2.7492425   2.766716    0.14238359 -0.03704865  0.07484961\n",
      "  2.496973  ]\n",
      "Epoch 201, Gradients: [-0.23721725 -0.03257799 -2.7520752  -0.01287842  0.1798706  -0.9053955\n",
      " -0.03097931]\n",
      " Loss: 1150.031494140625, Parameters: [23.97532     2.970203    3.2705495   0.13657825 -0.03483355  0.06748167\n",
      "  2.737083  ]\n",
      "Epoch 301, Gradients: [-0.33228517 -0.00856543 -1.6596375  -0.27368164  0.07867432 -0.9243164\n",
      " -0.02462345]\n",
      " Loss: 1149.30908203125, Parameters: [24.25511     3.1355276   3.5640361   0.1352288  -0.03472001  0.06368028\n",
      "  2.8340142 ]\n",
      "Epoch 401, Gradients: [-0.38233733 -0.00377131 -1.1314392  -0.11462402  0.07467651 -0.7937012\n",
      " -0.02130088]\n",
      " Loss: 1149.010009765625, Parameters: [24.422384    3.2320886   3.7361827   0.13492431 -0.03453809  0.06160567\n",
      "  2.8870409 ]\n",
      "Epoch 501, Gradients: [-0.40794623 -0.00199318 -0.85665894  0.06378174 -0.0524292   0.11816406\n",
      "  0.00303304]\n",
      " Loss: 1148.87060546875, Parameters: [24.521555    3.2896364   3.8372602   0.13474339 -0.03463617  0.06048835\n",
      "  2.918259  ]\n",
      "Epoch 601, Gradients: [-0.4241535  -0.00190449 -0.70599365 -0.0579834   0.03256226 -0.22839355\n",
      " -0.00488856]\n",
      " Loss: 1148.7996826171875, Parameters: [24.580229    3.3233974   3.8966768   0.13451383 -0.03448692  0.0598097\n",
      "  2.9355571 ]\n",
      "Converged at epoch 619\n",
      "Epoch 620, Gradients: [-4.2656863e-01  5.1307678e-04 -6.8873596e-01 -3.0334473e-02\n",
      " -1.2634277e-02 -3.5180664e-01 -7.5689554e-03]\n",
      " Loss: 1148.790771484375, full Parameters: [24.588697    3.3285947   3.9052231   0.13455719 -0.03456095  0.0597389\n",
      "  2.938084  ]\n",
      "FINAL STATE: Epoch 620, Gradients: [-4.2656863e-01  5.1307678e-04 -6.8873596e-01 -3.0334473e-02\n",
      " -1.2634277e-02 -3.5180664e-01 -7.5689554e-03]\n",
      " Loss: 1148.790771484375, full Parameters: [24.588697    3.3285947   3.9052231   0.13455719 -0.03456095  0.0597389\n",
      "  2.938084  ]\n"
     ]
    }
   ],
   "source": [
    "result = {}\n",
    "\n",
    "for day in range(2):\n",
    "    idx_for_datamap= [8*day,8*(day+1)]\n",
    "    analysis_data_map = {}\n",
    "    for i in range(idx_for_datamap[0],idx_for_datamap[1]):\n",
    "        tmp = coarse_dicts[key_idx[i]].copy()\n",
    "        tmp['Hours_elapsed'] = np.round(tmp['Hours_elapsed']-477700)\n",
    "\n",
    "        tmp = tmp.iloc[ord_mm, :4].to_numpy()\n",
    "        tmp = torch.from_numpy(tmp).float()  # Convert NumPy to Tensor\n",
    "        # tmp = tmp.clone().detach().requires_grad_(True)  # Enable gradients\n",
    "        \n",
    "        analysis_data_map[key_idx[i]] = tmp\n",
    "    aggregated_data = pd.DataFrame()\n",
    "    for i in range(idx_for_datamap[0],idx_for_datamap[1]):\n",
    "        tmp = coarse_dicts[key_idx[i]].copy()\n",
    "        tmp['Hours_elapsed'] = np.round(tmp['Hours_elapsed']-477700)\n",
    "        tmp = tmp.iloc[ord_mm].reset_index(drop=True)  \n",
    "        aggregated_data = pd.concat((aggregated_data, tmp), axis=0)\n",
    "    \n",
    "    aggregated_data = aggregated_data.iloc[:, :4].to_numpy()\n",
    "\n",
    "    aggregated_data = torch.from_numpy(aggregated_data).float()  # Convert NumPy to Tensor\n",
    "\n",
    "    params = [24.42, 1.92, 1.92, 0.001, -0.045, 0.237, 3.34]\n",
    "    params = torch.tensor(params, requires_grad=True)\n",
    "\n",
    "    torch_smooth = torch.tensor(0.5, dtype=torch.float32)\n",
    "\n",
    "\n",
    "    instance = kernels.model_fitting(\n",
    "        smooth=0.5,\n",
    "        input_map=analysis_data_map,\n",
    "        aggregated_data=aggregated_data,\n",
    "        nns_map=nns_map,\n",
    "        mm_cond_number=mm_cond_number\n",
    "    )\n",
    "\n",
    "    # optimizer = optim.Adam([params], lr=0.01)  # For Adam\n",
    "    optimizer, scheduler = instance.optimizer_fun(params, lr=0.01, betas=(0.9, 0.8), eps=1e-8, step_size=20, gamma=0.9)    \n",
    "    out = instance.run_full(params, optimizer,scheduler, epochs=3000)\n",
    "    result[day+1] = out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: [array([ 2.6412588e+01,  2.5630600e+00,  2.5388060e+00,  2.7070900e-02,\n",
       "         -2.4097290e-02,  1.0483751e-01,  5.3329625e+00], dtype=float32),\n",
       "  1374.03466796875],\n",
       " 2: [array([24.588697  ,  3.3285947 ,  3.9052231 ,  0.13455719, -0.03456095,\n",
       "          0.0597389 ,  2.938084  ], dtype=float32),\n",
       "  1148.790771484375]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(result, dict)\n",
    "import os\n",
    "# Save pickle\n",
    "output_filename = f\"estimation_1250_july24.pkl\"\n",
    "\n",
    "# base_path = \"/home/jl2815/tco/data/pickle_data\"\n",
    "output_path = \"/Users/joonwonlee/Documents/\"\n",
    "output_filepath = os.path.join(output_path, output_filename)\n",
    "with open(output_filepath, 'wb') as pickle_file:\n",
    "    pickle.dump(result, pickle_file)\n",
    "\n",
    "input_filepath = output_filepath\n",
    "# Load pickle\n",
    "with open(input_filepath, 'rb') as pickle_file:\n",
    "    loaded_map = pickle.load(pickle_file)\n",
    "\n",
    "loaded_map"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "faiss_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
