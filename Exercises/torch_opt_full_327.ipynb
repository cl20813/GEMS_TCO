{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for path in sys.path:\n",
    "#   print(path)\n",
    "\n",
    "import sys\n",
    "gems_tco_path = \"/Users/joonwonlee/Documents/GEMS_TCO-1/src\"\n",
    "sys.path.append(gems_tco_path)\n",
    "\n",
    "import logging\n",
    "import argparse # Argument parsing\n",
    "import math\n",
    "from collections import defaultdict\n",
    "import concurrent\n",
    "from concurrent.futures import ThreadPoolExecutor  # Importing specific executor for clarity\n",
    "import time\n",
    "\n",
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Nearest neighbor search\n",
    "import sklearn\n",
    "from sklearn.neighbors import BallTree\n",
    "\n",
    "# Special functions and optimizations\n",
    "from scipy.special import gamma, kv  # Bessel function and gamma function\n",
    "from scipy.stats import multivariate_normal  # Simulation\n",
    "from scipy.optimize import minimize\n",
    "from scipy.spatial.distance import cdist  # For space and time distance\n",
    "from scipy.spatial import distance  # Find closest spatial point\n",
    "from scipy.optimize import differential_evolution\n",
    "\n",
    "# Plotting and visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Type hints\n",
    "from typing import Callable, Union, Tuple\n",
    "\n",
    "# Add your custom path\n",
    "# sys.path.append(\"/cache/home/jl2815/tco\")\n",
    "\n",
    "# Custom imports\n",
    "\n",
    "from GEMS_TCO import orbitmap \n",
    "from GEMS_TCO import kernels \n",
    "from GEMS_TCO import evaluate\n",
    "from GEMS_TCO import orderings as _orderings\n",
    "\n",
    "import pickle\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import copy                    # clone tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_lon_resolution = [15,15]\n",
    "mm_cond_number = 10\n",
    "params= [20, 8.25, 5.25, 0.2, 0.5, 5]\n",
    "idx_for_datamap= [0,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the one dictionary to set spaital coordinates\n",
    "# filepath = \"C:/Users/joonw/TCO/GEMS_data/data_2023/sparse_cen_map23_01.pkl\"\n",
    "filepath = \"/Users/joonwonlee/Documents/GEMS_DATA/pickle_2023/coarse_cen_map23_01.pkl\"\n",
    "with open(filepath, 'rb') as pickle_file:\n",
    "    coarse_dict_24_1 = pickle.load(pickle_file)\n",
    "\n",
    "sample_df = coarse_dict_24_1['y23m01day01_hm02:12']\n",
    "\n",
    "sample_key = coarse_dict_24_1.get('y23m01day01_hm02:12')\n",
    "if sample_key is None:\n",
    "    print(\"Key 'y23m01day01_hm02:12' not found in the dictionary.\")\n",
    "\n",
    "# { (20,20):(5,1), (5,5):(20,40) }\n",
    "rho_lat = lat_lon_resolution[0]          \n",
    "rho_lon = lat_lon_resolution[1]\n",
    "lat_n = sample_df['Latitude'].unique()[::rho_lat]\n",
    "lon_n = sample_df['Longitude'].unique()[::rho_lon]\n",
    "\n",
    "lat_number = len(lat_n)\n",
    "lon_number = len(lon_n)\n",
    "\n",
    "# Set spatial coordinates for each dataset\n",
    "coarse_dicts = {}\n",
    "\n",
    "years = ['2024']\n",
    "for year in years:\n",
    "    for month in range(7, 8):  # Iterate over all months\n",
    "        # filepath = f\"C:/Users/joonw/TCO/GEMS_data/data_{year}/sparse_cen_map{year[2:]}_{month:02d}.pkl\"\n",
    "        filepath = f\"/Users/joonwonlee/Documents/GEMS_DATA/pickle_{year}/coarse_cen_map{year[2:]}_{month:02d}.pkl\"\n",
    "        with open(filepath, 'rb') as pickle_file:\n",
    "            loaded_map = pickle.load(pickle_file)\n",
    "            for key in loaded_map:\n",
    "                tmp_df = loaded_map[key]\n",
    "                coarse_filter = (tmp_df['Latitude'].isin(lat_n)) & (tmp_df['Longitude'].isin(lon_n))\n",
    "                coarse_dicts[f\"{year}_{month:02d}_{key}\"] = tmp_df[coarse_filter].reset_index(drop=True)\n",
    "\n",
    "\n",
    "key_idx = sorted(coarse_dicts)\n",
    "if not key_idx:\n",
    "    raise ValueError(\"coarse_dicts is empty\")\n",
    "\n",
    "# extract first hour data because all data shares the same spatial grid\n",
    "data_for_coord = coarse_dicts[key_idx[0]]\n",
    "x1 = data_for_coord['Longitude'].values\n",
    "y1 = data_for_coord['Latitude'].values \n",
    "coords1 = np.stack((x1, y1), axis=-1)\n",
    "\n",
    "\n",
    "# instance = orbitmap.MakeOrbitdata(data_for_coord, lat_s=5, lat_e=10, lon_s=110, lon_e=120)\n",
    "# s_dist = cdist(coords1, coords1, 'euclidean')\n",
    "# ord_mm, _ = instance.maxmin_naive(s_dist, 0)\n",
    "\n",
    "ord_mm = _orderings.maxmin_cpp(coords1)\n",
    "data_for_coord = data_for_coord.iloc[ord_mm].reset_index(drop=True)\n",
    "coords1_reordered = np.stack((data_for_coord['Longitude'].values, data_for_coord['Latitude'].values), axis=-1)\n",
    "# nns_map = instance.find_nns_naive(locs=coords1_reordered, dist_fun='euclidean', max_nn=mm_cond_number)\n",
    "nns_map=_orderings.find_nns_l2(locs= coords1_reordered  ,max_nn = mm_cond_number)\n",
    "\n",
    "\n",
    "analysis_data_map = {}\n",
    "for i in range(idx_for_datamap[0],idx_for_datamap[1]):\n",
    "    tmp = coarse_dicts[key_idx[i]].copy()\n",
    "    tmp['Hours_elapsed'] = np.round(tmp['Hours_elapsed']-477700)\n",
    "\n",
    "    tmp = tmp.iloc[ord_mm, :4].to_numpy()\n",
    "    tmp = torch.from_numpy(tmp).float()  # Convert NumPy to Tensor\n",
    "    # tmp = tmp.clone().detach().requires_grad_(True)  # Enable gradients\n",
    "    \n",
    "    analysis_data_map[key_idx[i]] = tmp\n",
    "\n",
    "aggregated_data = pd.DataFrame()\n",
    "for i in range(idx_for_datamap[0],idx_for_datamap[1]):\n",
    "    tmp = coarse_dicts[key_idx[i]].copy()\n",
    "    tmp['Hours_elapsed'] = np.round(tmp['Hours_elapsed']-477700)\n",
    "    tmp = tmp.iloc[ord_mm].reset_index(drop=True)  \n",
    "    aggregated_data = pd.concat((aggregated_data, tmp), axis=0)\n",
    "\n",
    "aggregated_data = aggregated_data.iloc[:, :4].to_numpy()\n",
    "\n",
    "aggregated_data = torch.from_numpy(aggregated_data).float()  # Convert NumPy to Tensor\n",
    "# aggregated_np = aggregated_np.clone().detach().requires_grad_(True)  # Enable gradients\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {}\n",
    "\n",
    "for day in range(2):\n",
    "    idx_for_datamap= [8*day,8*(day+1)]\n",
    "    analysis_data_map = {}\n",
    "    for i in range(idx_for_datamap[0],idx_for_datamap[1]):\n",
    "        tmp = coarse_dicts[key_idx[i]].copy()\n",
    "        tmp['Hours_elapsed'] = np.round(tmp['Hours_elapsed']-477700)\n",
    "\n",
    "        tmp = tmp.iloc[ord_mm, :4].to_numpy()\n",
    "        tmp = torch.from_numpy(tmp).float()  # Convert NumPy to Tensor\n",
    "        # tmp = tmp.clone().detach().requires_grad_(True)  # Enable gradients\n",
    "        \n",
    "        analysis_data_map[key_idx[i]] = tmp\n",
    "    aggregated_data = pd.DataFrame()\n",
    "    for i in range(idx_for_datamap[0],idx_for_datamap[1]):\n",
    "        tmp = coarse_dicts[key_idx[i]].copy()\n",
    "        tmp['Hours_elapsed'] = np.round(tmp['Hours_elapsed']-477700)\n",
    "        tmp = tmp.iloc[ord_mm].reset_index(drop=True)  \n",
    "        aggregated_data = pd.concat((aggregated_data, tmp), axis=0)\n",
    "    \n",
    "    aggregated_data = aggregated_data.iloc[:, :4].to_numpy()\n",
    "\n",
    "    aggregated_data = torch.from_numpy(aggregated_data).float()  # Convert NumPy to Tensor\n",
    "\n",
    "    params = [24.42, 1.92, 1.92, 0.001, -0.045, 0.237, 3.34]\n",
    "    params = torch.tensor(params, requires_grad=True)\n",
    "\n",
    "    torch_smooth = torch.tensor(0.5, dtype=torch.float32)\n",
    "\n",
    "\n",
    "    instance = kernels.model_fitting(\n",
    "        smooth=0.5,\n",
    "        input_map=analysis_data_map,\n",
    "        aggregated_data=aggregated_data,\n",
    "        nns_map=nns_map,\n",
    "        mm_cond_number=mm_cond_number\n",
    "    )\n",
    "\n",
    "    # optimizer = optim.Adam([params], lr=0.01)  # For Adam\n",
    "    optimizer, scheduler = instance.optimizer_fun(params, lr=0.01, betas=(0.9, 0.8), eps=1e-8, step_size=20, gamma=0.9)    \n",
    "    out = instance.run_full(params, optimizer,scheduler, epochs=3000)\n",
    "    result[day+1] = out\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save estimates in to pickle fime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: [array([ 2.6412588e+01,  2.5630600e+00,  2.5388060e+00,  2.7070900e-02,\n",
       "         -2.4097290e-02,  1.0483751e-01,  5.3329625e+00], dtype=float32),\n",
       "  1374.03466796875],\n",
       " 2: [array([24.588697  ,  3.3285947 ,  3.9052231 ,  0.13455719, -0.03456095,\n",
       "          0.0597389 ,  2.938084  ], dtype=float32),\n",
       "  1148.790771484375]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(result, dict)\n",
    "import os\n",
    "# Save pickle\n",
    "output_filename = f\"estimation_1250_july24.pkl\"\n",
    "\n",
    "# base_path = \"/home/jl2815/tco/data/pickle_data\"\n",
    "output_path = \"/Users/joonwonlee/Documents/\"\n",
    "output_filepath = os.path.join(output_path, output_filename)\n",
    "with open(output_filepath, 'wb') as pickle_file:\n",
    "    pickle.dump(result, pickle_file)\n",
    "\n",
    "input_filepath = output_filepath\n",
    "# Load pickle\n",
    "with open(input_filepath, 'rb') as pickle_file:\n",
    "    loaded_map = pickle.load(pickle_file)\n",
    "\n",
    "loaded_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load estimates from amarel and make it into pd data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              sigmasq  range_lat  range_lon  advec_lat  advec_lon      beta  \\\n",
      "2024-07-01  25.964643   2.120772   2.225752   0.001676  -0.079428  0.102517   \n",
      "2024-07-02  23.878902   3.283870   3.612040   0.048285   0.019385  0.079440   \n",
      "2024-07-03  26.226320   1.905852   2.220417  -0.010698  -0.116340  0.119043   \n",
      "2024-07-04  24.515753   2.836888   3.613807  -0.132429  -0.165947  0.072058   \n",
      "2024-07-05  23.338093   3.692467   3.726604  -0.060823  -0.136659  0.059121   \n",
      "2024-07-06  25.878857   2.543730   2.867047   0.003362  -0.137558  0.094139   \n",
      "2024-07-07  26.262951   2.129691   3.281083   0.050776  -0.301583  0.087698   \n",
      "2024-07-08  26.109503   1.798699   2.407871   0.027176  -0.394423  0.111374   \n",
      "2024-07-09  24.766806   2.113744   2.775355  -0.026761  -0.209648  0.105213   \n",
      "2024-07-10  26.156773   1.482763   2.269531  -0.007672  -0.005897  0.145461   \n",
      "2024-07-11  24.291435   2.281666   3.302899  -0.030417   0.053161  0.104988   \n",
      "2024-07-12  22.386654   3.815042   3.928914  -0.062528   0.159238  0.076979   \n",
      "2024-07-13  22.917402   2.735535   3.899667  -0.104938   0.132803  0.121394   \n",
      "2024-07-14  24.864378   3.260484   3.543547  -0.074905   0.034255  0.073319   \n",
      "2024-07-15  23.076466   3.884366   3.873738  -0.054133   0.108314  0.089375   \n",
      "2024-07-16  23.346285   3.926090   3.921465   0.011103   0.065652  0.079134   \n",
      "2024-07-17  25.911747   2.580064   3.107688   0.027860  -0.000408  0.099810   \n",
      "2024-07-18  24.480814   1.825127   3.754235  -0.088562  -0.095518  0.111794   \n",
      "2024-07-19  24.378695   2.507041   3.100781   0.007149   0.048302  0.099982   \n",
      "2024-07-20  23.147820   3.911249   3.904751  -0.020627  -0.054073  0.070223   \n",
      "2024-07-21  24.418201   2.759092   3.867206   0.014986   0.056871  0.080973   \n",
      "2024-07-22  22.390326   2.571582   3.939111   0.134928  -0.068969  0.123937   \n",
      "2024-07-23  22.399338   2.669678   3.937241   0.008763   0.059057  0.148871   \n",
      "2024-07-24  22.417767   2.177945   3.914591   0.003907  -0.177548  0.125145   \n",
      "2024-07-25  22.394796   3.948420   3.942043   0.007408   0.011317  0.052068   \n",
      "2024-07-26  22.389885   3.291999   3.937298  -0.009092  -0.005122  0.062825   \n",
      "2024-07-27  22.399857   3.549847   3.923941  -0.029935  -0.034940  0.074750   \n",
      "2024-07-28  22.954805   2.599295   3.851918  -0.025230  -0.081615  0.073113   \n",
      "2024-07-29  22.873333   3.748235   3.905550   0.016063  -0.013811  0.084632   \n",
      "2024-07-30  24.341864   3.526408   3.627585   0.008980  -0.059477  0.103370   \n",
      "2024-07-31  26.423981   2.752865   1.676864   0.070382  -0.171220  0.363480   \n",
      "\n",
      "              nugget         loss  \n",
      "2024-07-01  3.707680  2548.166016  \n",
      "2024-07-02  2.616611  2219.603516  \n",
      "2024-07-03  4.240125  2643.212402  \n",
      "2024-07-04  5.272248  2566.220703  \n",
      "2024-07-05  2.632560  2159.469727  \n",
      "2024-07-06  4.370037  2560.985352  \n",
      "2024-07-07  5.234130  2656.939453  \n",
      "2024-07-08  4.156657  2633.276855  \n",
      "2024-07-09  2.587406  2367.951660  \n",
      "2024-07-10  3.231116  2588.455566  \n",
      "2024-07-11  2.612787  2321.147461  \n",
      "2024-07-12  2.230500  2082.785156  \n",
      "2024-07-13  1.721124  2117.546875  \n",
      "2024-07-14  3.607270  2376.107178  \n",
      "2024-07-15  1.863936  2057.168457  \n",
      "2024-07-16  2.464011  2151.342285  \n",
      "2024-07-17  4.605767  2576.915039  \n",
      "2024-07-18  3.445045  2442.541992  \n",
      "2024-07-19  2.481662  2297.325195  \n",
      "2024-07-20  3.677322  2319.570312  \n",
      "2024-07-21  3.237239  2336.404297  \n",
      "2024-07-22  3.060043  2316.452148  \n",
      "2024-07-23  1.339313  2024.808838  \n",
      "2024-07-24  1.560534  2086.808594  \n",
      "2024-07-25  1.350342  1569.753784  \n",
      "2024-07-26  1.332333  1826.958984  \n",
      "2024-07-27  1.353114  1889.706055  \n",
      "2024-07-28  2.870943  2240.815918  \n",
      "2024-07-29  2.151556  2098.814941  \n",
      "2024-07-30  3.184013  2335.119141  \n",
      "2024-07-31  5.334742  2922.947266  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_path = \"/Users/joonwonlee/Documents/GEMS_TCO-1/Exercises/st_model/estimates\"\n",
    "input_filename = \"estimation_200_july24.pkl\"\n",
    "input_filename = \"estimation_1250_july24.pkl\"\n",
    "input_filepath = os.path.join(input_path, input_filename)\n",
    "# Load pickle\n",
    "with open(input_filepath, 'rb') as pickle_file:\n",
    "    amarel_map1250= pickle.load(pickle_file)\n",
    "\n",
    "# Assuming df_1250 is your DataFrame\n",
    "df_1250 = pd.DataFrame()\n",
    "for key in amarel_map1250:\n",
    "    tmp = pd.DataFrame(amarel_map1250[key][0].reshape(1, -1), columns=['sigmasq', 'range_lat', 'range_lon', 'advec_lat', 'advec_lon', 'beta', 'nugget'])\n",
    "    tmp['loss'] = amarel_map1250[key][1]\n",
    "    df_1250 = pd.concat((df_1250, tmp), axis=0)\n",
    "\n",
    "# Generate date range\n",
    "date_range = pd.date_range(start='07-01-24', end='07-31-24')\n",
    "\n",
    "# Ensure the number of dates matches the number of rows in df_1250\n",
    "if len(date_range) == len(df_1250):\n",
    "    df_1250.index = date_range\n",
    "else:\n",
    "    print(\"The number of dates does not match the number of rows in the DataFrame.\")\n",
    "\n",
    "print(df_1250)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              sigmasq  range_lat  range_lon  advec_lat  advec_lon      beta  \\\n",
      "2024-07-01  24.793444   1.584529   1.718248   0.009089  -0.107299  0.131038   \n",
      "2024-07-02  24.424301   1.997055   1.942683   0.043588  -0.072679  0.137124   \n",
      "2024-07-03  26.009497   1.215236   1.558868   0.023392  -0.150548  0.199850   \n",
      "2024-07-04  24.701347   1.612308   1.822960  -0.164069  -0.237443  0.131595   \n",
      "2024-07-05  22.598671   2.901185   3.722327  -0.011729  -0.152072  0.072866   \n",
      "2024-07-06  25.594908   1.702692   2.255174   0.017462  -0.158125  0.098684   \n",
      "2024-07-07  26.030510   1.261084   2.831952   0.054831  -0.343255  0.103045   \n",
      "2024-07-08  26.043682   0.995279   1.629503  -0.019824  -0.411626  0.164296   \n",
      "2024-07-09  24.052071   1.377774   2.357721   0.021439  -0.220316  0.142847   \n",
      "2024-07-10  25.766109   1.392051   2.358171   0.026684  -0.077366  0.150648   \n",
      "2024-07-11  23.945438   1.490333   2.470762  -0.009915   0.027429  0.137959   \n",
      "2024-07-12  23.036034   2.299998   3.346955  -0.054281   0.114976  0.110155   \n",
      "2024-07-13  22.790960   2.072518   3.616723  -0.130206   0.076944  0.135628   \n",
      "2024-07-14  24.079025   2.077914   2.578654  -0.035028   0.072091  0.144720   \n",
      "2024-07-15  22.556171   3.047949   3.821722  -0.051073   0.067158  0.109084   \n",
      "2024-07-16  23.403471   2.888016   3.056899  -0.004253   0.005845  0.104761   \n",
      "2024-07-17  24.978308   1.371159   2.236580  -0.068871  -0.126589  0.137412   \n",
      "2024-07-18  23.328363   1.295417   3.319158  -0.079007  -0.109866  0.131408   \n",
      "2024-07-19  23.913704   1.824143   2.503119   0.020213   0.016007  0.142548   \n",
      "2024-07-20  23.171667   2.521096   3.594732   0.032805  -0.026624  0.092923   \n",
      "2024-07-21  23.972263   2.328973   3.350626  -0.002169  -0.070489  0.109454   \n",
      "2024-07-22  23.484762   1.773483   3.144358   0.106800  -0.146150  0.170165   \n",
      "2024-07-23  22.399940   2.525347   3.945889  -0.004455   0.073785  0.144858   \n",
      "2024-07-24  22.485428   1.960177   3.856450   0.042581  -0.149502  0.134382   \n",
      "2024-07-25  22.398106   3.968451   3.945307   0.006230  -0.013954  0.047208   \n",
      "2024-07-26  22.393942   2.544035   3.943803  -0.004113   0.031536  0.084661   \n",
      "2024-07-27  22.484076   2.263680   3.848698  -0.026536  -0.070513  0.085162   \n",
      "2024-07-28  22.687857   1.915375   3.615973  -0.024074  -0.078118  0.091293   \n",
      "2024-07-29  22.405510   2.753298   3.919266   0.003522  -0.051619  0.069307   \n",
      "2024-07-30  23.821211   2.505870   3.378460  -0.030410  -0.199047  0.127340   \n",
      "2024-07-31  24.262573   3.082172   2.880464   0.059405  -0.190543  0.197513   \n",
      "\n",
      "              nugget          loss  \n",
      "2024-07-01  2.717239  14068.529297  \n",
      "2024-07-02  1.513148  12357.715820  \n",
      "2024-07-03  2.890678  14948.140625  \n",
      "2024-07-04  3.636499  14786.204102  \n",
      "2024-07-05  2.397249  12096.261719  \n",
      "2024-07-06  3.850205  14690.248047  \n",
      "2024-07-07  4.596346  15342.459961  \n",
      "2024-07-08  2.751402  14857.195312  \n",
      "2024-07-09  1.675457  12666.991211  \n",
      "2024-07-10  3.821218  14987.769531  \n",
      "2024-07-11  2.066264  13000.419922  \n",
      "2024-07-12  1.604898  11485.496094  \n",
      "2024-07-13  1.441895  11315.873047  \n",
      "2024-07-14  2.405799  13138.958984  \n",
      "2024-07-15  1.462631  10808.830078  \n",
      "2024-07-16  2.019670  12012.943359  \n",
      "2024-07-17  3.044259  14286.230469  \n",
      "2024-07-18  2.737964  13417.033203  \n",
      "2024-07-19  2.095682  12876.714844  \n",
      "2024-07-20  2.846266  12944.312500  \n",
      "2024-07-21  2.806951  13142.653320  \n",
      "2024-07-22  2.292179  12951.943359  \n",
      "2024-07-23  1.340997  10006.291016  \n",
      "2024-07-24  1.423066  11153.117188  \n",
      "2024-07-25  1.345503   8595.869141  \n",
      "2024-07-26  1.334278  10097.978516  \n",
      "2024-07-27  1.953647  11613.490234  \n",
      "2024-07-28  2.331802  12408.534180  \n",
      "2024-07-29  3.181403  12968.927734  \n",
      "2024-07-30  2.945880  13282.449219  \n",
      "2024-07-31  5.303008  15539.535156  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "faiss_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
