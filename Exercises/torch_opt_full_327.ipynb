{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "gems_tco_path = \"/Users/joonwonlee/Documents/GEMS_TCO-1/src\"\n",
    "sys.path.append(gems_tco_path)\n",
    "\n",
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle \n",
    "\n",
    "import GEMS_TCO\n",
    "from GEMS_TCO import kernels \n",
    "from GEMS_TCO import orderings as _orderings\n",
    "from GEMS_TCO import load_data\n",
    "\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import copy\n",
    "from GEMS_TCO import configuration as config\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Day 12 data size per day: 50.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "lat_lon_resolution = [20,20]\n",
    "years = ['2024']\n",
    "month_range =[7,8]\n",
    "nheads = 200\n",
    "mm_cond_number = 10 \n",
    "\n",
    "data_load_instance = load_data(config.mac_data_load_path)\n",
    "df = data_load_instance.read_pickle(config.mac_estimates_day_path,config.mac_full_day_v05_pickle)\n",
    "\n",
    "df.head()\n",
    "\n",
    "for day in range(12,13):\n",
    "    print(f'\\n Day {day} data size per day: { (200/lat_lon_resolution[0])*(100/lat_lon_resolution[0])  } \\n')\n",
    "\n",
    "    idx_for_datamap= [ 8*(day),8*(day+1)]\n",
    "\n",
    "    params = list(df.iloc[day-1][:-1])\n",
    "    params = torch.tensor(params, dtype=torch.float64, requires_grad=True)\n",
    "\n",
    "    input_path = Path(config.mac_data_load_path)\n",
    "   \n",
    "    map, ord_mm, nns_map= data_load_instance.load_mm20k_data_bymonthyear( lat_lon_resolution= lat_lon_resolution, mm_cond_number=mm_cond_number,years_=years, months_=month_range)\n",
    "    analysis_data_map, aggregated_data = data_load_instance.load_working_data_byday( map, ord_mm, nns_map, idx_for_datamap= idx_for_datamap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {}\n",
    "\n",
    "for day in range(12,13):\n",
    "    print(f'\\n Day {day} data size per day: { (200/lat_lon_resolution[0])*(100/lat_lon_resolution[0])  } \\n')\n",
    "\n",
    "    idx_for_datamap= [ 8*(day),8*(day+1)]\n",
    "\n",
    "    params = list(df.iloc[day-1][:-1])\n",
    "    params = torch.tensor(params, dtype=torch.float64, requires_grad=True)\n",
    "\n",
    "    input_path = Path(config.mac_data_load_path)\n",
    "   \n",
    "    map, ord_mm, nns_map= data_load_instance.load_mm20k_data_bymonthyear( lat_lon_resolution= lat_lon_resolution, mm_cond_number=mm_cond_number,years_=years, months_=month_range)\n",
    "    analysis_data_map, aggregated_data = data_load_instance.load_working_data_byday( map, ord_mm, nns_map, idx_for_datamap= idx_for_datamap)\n",
    "\n",
    "    instance = kernels.model_fitting(\n",
    "        smooth= 1.0,\n",
    "        input_map=analysis_data_map,\n",
    "        aggregated_data=aggregated_data,\n",
    "        nns_map=nns_map,\n",
    "        mm_cond_number=mm_cond_number,\n",
    "        nheads= nheads\n",
    "    )\n",
    "\n",
    "    # optimizer = optim.Adam([params], lr=0.01)  # For Adam\n",
    "    optimizer, scheduler = instance.optimizer_fun(params, lr=0.03, betas=(0.9, 0.99), eps=1e-8, step_size=100, gamma=0.9)    \n",
    "    out = instance.run_full(params, optimizer,scheduler, instance.matern_cov_anisotropy_kv, epochs=500)\n",
    "    result[day+1] = out\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save estimates in to pickle fime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(result, dict)\n",
    "import os\n",
    "# Save pickle\n",
    "output_filename = f\"estimation_1250_july24.pkl\"\n",
    "\n",
    "# base_path = \"/home/jl2815/tco/data/pickle_data\"\n",
    "output_path = \"/Users/joonwonlee/Documents/\"\n",
    "output_filepath = os.path.join(output_path, output_filename)\n",
    "with open(output_filepath, 'wb') as pickle_file:\n",
    "    pickle.dump(result, pickle_file)\n",
    "\n",
    "input_filepath = output_filepath\n",
    "# Load pickle\n",
    "with open(input_filepath, 'rb') as pickle_file:\n",
    "    loaded_map = pickle.load(pickle_file)\n",
    "\n",
    "loaded_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load estimates from amarel and make it into pd data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10x10 full     takes 22 seconds (epochs 444)\n",
    "\n",
    "vecchia log\n",
    "10 by 10 fix 300 epochs (2m 7.2)  \n",
    "original 2m 7.2  25 3 2.8 -0.04 -0.04 0.0066 4.3\n",
    "\n",
    "if dont use cache   300 epochs fixed 5m 35.3\n",
    "25 3 2.84 -0.04 -0.04 0.0066 4.3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "faiss_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
